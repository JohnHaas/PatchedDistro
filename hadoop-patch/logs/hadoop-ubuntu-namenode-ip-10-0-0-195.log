2014-05-05 11:17:43,950 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-patch/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-05-04T05:58Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 11:17:43,962 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 11:17:44,398 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 11:17:44,597 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 11:17:44,597 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 11:17:44,907 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-05-05 11:17:45,251 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 11:17:45,376 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 11:17:45,378 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 11:17:45,378 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 11:17:45,378 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 11:17:45,423 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 11:17:45,469 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 11:17:45,469 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 11:17:45,914 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 11:17:45,914 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 11:17:45,961 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 11:17:45,961 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 11:17:46,038 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 11:17:46,038 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 11:17:46,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 11:17:46,043 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 11:17:46,043 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 11:17:46,044 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2014-05-05 11:17:46,044 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2014-05-05 11:17:46,048 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 11:17:46,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 11:17:46,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 11:17:46,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 11:17:46,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 11:17:46,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 11:17:46,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 11:17:46,049 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 11:17:46,056 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 11:17:46,056 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 11:17:46,056 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 11:17:46,056 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 11:17:46,058 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 11:17:46,153 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 11:17:46,153 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 11:17:46,153 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2014-05-05 11:17:46,153 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2014-05-05 11:17:46,176 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 11:17:46,180 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 11:17:46,180 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 11:17:46,180 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 11:17:46,181 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 11:17:46,181 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 11:17:46,183 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 11:17:46,183 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 11:17:46,183 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2014-05-05 11:17:46,183 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2014-05-05 11:17:46,214 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 2874@ip-10-0-0-195
2014-05-05 11:17:46,419 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 11:17:46,580 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000002218 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000002218-0000000000000002462
2014-05-05 11:17:46,608 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000002217 using no compression
2014-05-05 11:17:46,608 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 101
2014-05-05 11:17:46,632 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2014-05-05 11:17:46,633 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000002217 of size 14656 bytes loaded in 0 seconds.
2014-05-05 11:17:46,633 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2217 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000002217
2014-05-05 11:17:46,633 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7891135e expecting start txid #2218
2014-05-05 11:17:46,633 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000002218-0000000000000002462
2014-05-05 11:17:46,635 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000002218-0000000000000002462' to transaction ID 2218
2014-05-05 11:17:46,705 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000002218-0000000000000002462 of size 1048576 edits # 245 loaded in 0 seconds
2014-05-05 11:17:46,710 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Saving image file /var/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000002462 using no compression
2014-05-05 11:17:46,723 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage.ckpt_0000000000000002462 of size 15500 bytes saved in 0 seconds.
2014-05-05 11:17:46,764 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2217
2014-05-05 11:17:46,764 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/var/hadoop/tmp/dfs/name/current/fsimage_0000000000000001732, cpktTxId=0000000000000001732)
2014-05-05 11:17:46,784 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 2463
2014-05-05 11:17:46,899 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 11:17:46,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 714 msecs
2014-05-05 11:17:47,289 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 11:17:47,311 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 11:17:47,620 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 11:17:47,638 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 11:17:47,638 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 11:17:47,640 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 89 blocks to reach the threshold 0.9990 of total blocks 89.
Safe mode will be turned off automatically
2014-05-05 11:17:47,693 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 11:17:47,695 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 11:17:47,707 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 11:17:47,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 11:17:48,686 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:48,689 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:17:48,690 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:48,690 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.193, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:48,690 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:17:48,691 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 11:17:48,741 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.193:50010 is expected to serve this storage.
2014-05-05 11:17:48,816 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:48,816 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.193:50010 is replaced by DatanodeRegistration(10.0.0.200, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:48,816 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.193:50010
2014-05-05 11:17:48,816 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 11:17:48,867 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:48,867 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.200:50010
2014-05-05 11:17:48,867 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:17:48,875 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.193, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:17:48,876 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:org.apache.hadoop.hdfs.protocol.UnregisteredNodeException: Data node DatanodeRegistration(10.0.0.193, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:17:48,877 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 54310, call org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReport from 10.0.0.193:57251 Call#4 Retry#0: error: org.apache.hadoop.hdfs.protocol.UnregisteredNodeException: Data node DatanodeRegistration(10.0.0.193, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
org.apache.hadoop.hdfs.protocol.UnregisteredNodeException: Data node DatanodeRegistration(10.0.0.193, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanode(DatanodeManager.java:417)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processReport(BlockManager.java:1603)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReport(NameNodeRpcServer.java:974)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.blockReport(DatanodeProtocolServerSideTranslatorPB.java:149)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:24083)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2014-05-05 11:17:48,888 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 88 has reached the threshold 0.9990 of total blocks 89. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2014-05-05 11:17:48,892 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2014-05-05 11:17:48,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 89
2014-05-05 11:17:48,905 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2014-05-05 11:17:48,905 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 89
2014-05-05 11:17:48,905 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2014-05-05 11:17:48,905 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2014-05-05 11:17:48,905 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2014-05-05 11:17:48,905 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:17:48,905 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 23 msecs
2014-05-05 11:17:48,913 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.200, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:17:48,914 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:org.apache.hadoop.hdfs.protocol.UnregisteredNodeException: Data node DatanodeRegistration(10.0.0.200, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:17:48,914 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 54310, call org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReport from 10.0.0.200:50249 Call#4 Retry#0: error: org.apache.hadoop.hdfs.protocol.UnregisteredNodeException: Data node DatanodeRegistration(10.0.0.200, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
org.apache.hadoop.hdfs.protocol.UnregisteredNodeException: Data node DatanodeRegistration(10.0.0.200, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanode(DatanodeManager.java:417)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processReport(BlockManager.java:1603)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReport(NameNodeRpcServer.java:974)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.blockReport(DatanodeProtocolServerSideTranslatorPB.java:149)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:24083)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
2014-05-05 11:17:51,260 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:51,261 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:51,261 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:17:51,261 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:17:51,303 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:17:51,721 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:17:51,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:51,724 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:17:51,724 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:17:51,728 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:17:54,265 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:17:54,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:54,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:54,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:17:54,268 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:17:54,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:17:54,721 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:17:54,723 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:54,724 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:17:54,724 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:17:54,727 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:17:57,265 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:17:57,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:57,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:57,267 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:17:57,267 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:17:57,271 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:17:57,722 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:17:57,725 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:17:57,725 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:17:57,725 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:17:57,728 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:00,265 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:00,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:00,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:00,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:00,268 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:00,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:00,722 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:00,725 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:00,725 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:00,725 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:00,729 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:03,265 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:03,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:03,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:03,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:03,268 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:03,271 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:18:03,722 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:03,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:03,724 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:03,725 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:03,728 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:06,265 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:06,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:06,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:06,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:06,268 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:06,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:06,722 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:06,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:06,724 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:06,724 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:06,728 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:08,918 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 89 has reached the threshold 0.9990 of total blocks 89. The number of live datanodes 1 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2014-05-05 11:18:09,266 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:09,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:09,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:09,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:09,268 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:09,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:09,721 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:09,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:09,724 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:09,724 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:09,727 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:12,266 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:12,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:12,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:12,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:12,268 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:12,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:12,722 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:12,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:12,725 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:12,725 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:12,728 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:15,266 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:15,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:15,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:15,269 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:15,269 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:15,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:15,722 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:15,725 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:15,725 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:15,725 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:15,728 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:18,265 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:18,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:18,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:18,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:18,268 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:18,271 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:18,722 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:18,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:18,724 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:18,725 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:18,728 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:18,920 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 32 secs
2014-05-05 11:18:18,920 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2014-05-05 11:18:18,920 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
2014-05-05 11:18:18,920 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 89 blocks
2014-05-05 11:18:21,266 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:21,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:21,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:21,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:21,268 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:21,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:21,722 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:21,725 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:21,725 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:21,725 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:21,728 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:24,265 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:24,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:24,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:24,267 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:24,267 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:24,270 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:24,723 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:24,725 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:24,725 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:24,725 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:24,728 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:27,266 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:27,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:27,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:27,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:27,268 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:27,273 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:27,722 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:27,739 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:27,739 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:27,739 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:27,744 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:30,266 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:30,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:30,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:30,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:30,269 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:30,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:30,723 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:30,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:30,726 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:30,726 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:30,730 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:33,266 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:33,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:33,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:33,269 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:33,269 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:33,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:33,723 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:33,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:33,726 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:33,726 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:33,730 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:36,267 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:36,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:36,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:36,271 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:36,271 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:36,274 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:36,723 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:36,725 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:36,726 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:36,726 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:36,729 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:39,266 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:39,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:39,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:39,269 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:39,269 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:39,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:39,724 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:39,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:39,726 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:39,726 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:39,729 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:42,266 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:42,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:42,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:42,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:42,268 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:42,274 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:42,724 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:42,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:42,726 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:42,726 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:42,729 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:45,266 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:45,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:45,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:45,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:45,268 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:45,271 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:18:45,724 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:45,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:45,726 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:45,726 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:45,729 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:48,266 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:48,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:48,268 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:48,268 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:48,269 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:48,271 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:48,724 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:48,727 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:48,727 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:48,727 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:48,729 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:51,267 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:51,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:51,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:51,269 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:51,269 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:51,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:51,725 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:51,727 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:51,727 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:51,727 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:51,730 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:54,267 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:54,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:54,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:54,270 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:54,270 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:54,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:18:54,725 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:54,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:54,728 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:54,728 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:54,730 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:18:57,267 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:18:57,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:57,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:57,269 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:57,269 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:57,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:18:57,726 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:18:57,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:18:57,728 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:18:57,728 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:18:57,731 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:00,267 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:00,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:00,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:00,270 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:00,270 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:00,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:00,726 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:00,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:00,728 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:00,728 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:00,731 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:03,267 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:03,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:03,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:03,270 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:03,270 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:03,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:03,725 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:03,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:03,728 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:03,728 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:03,730 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:06,267 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:06,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:06,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:06,269 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:06,269 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:06,271 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:06,726 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:06,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:06,728 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:06,728 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:06,730 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:09,267 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:09,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:09,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:09,270 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:09,270 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:09,273 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:09,725 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:09,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:09,728 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:09,728 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:09,731 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:12,267 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:12,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:12,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:12,270 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:12,270 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:12,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:12,726 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:12,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:12,728 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:12,728 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:12,730 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:15,267 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:15,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:15,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:15,269 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:15,269 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:15,271 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:15,725 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:15,727 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:15,727 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:15,727 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:15,729 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:18,267 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:18,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:18,269 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:18,269 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:18,269 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:18,271 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:18,726 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:18,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:18,728 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:18,728 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:18,731 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:21,268 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:21,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:21,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:21,270 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:21,270 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:21,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:21,726 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:21,728 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:21,728 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:21,729 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:21,731 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:24,268 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:24,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:24,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:24,270 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:24,270 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:24,273 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:24,726 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:24,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:24,729 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:24,729 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:24,731 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:27,268 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:27,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:27,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:27,270 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:27,271 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:27,273 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:27,726 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:27,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:27,729 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:27,729 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:27,731 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:30,268 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:30,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:30,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:30,271 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:30,271 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:30,273 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:30,726 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:30,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:30,729 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:30,729 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:30,731 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:33,268 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:33,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:33,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:33,271 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:33,271 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:33,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:33,727 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:33,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:33,729 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:33,729 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:33,732 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:36,268 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:36,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:36,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:36,270 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:36,271 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:36,273 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:36,726 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:36,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:36,729 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:36,729 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:36,731 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:39,268 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:39,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:39,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:39,271 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:39,271 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:39,274 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:39,727 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:39,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:39,729 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:39,729 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:39,731 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:42,269 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:42,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:42,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:42,271 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:42,271 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:42,274 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:42,727 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:42,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:42,729 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:42,730 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:42,732 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:45,269 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:45,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:45,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:45,271 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:45,271 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:45,273 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:45,727 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:45,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:45,729 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:45,729 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:45,731 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:48,269 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:48,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:48,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:48,271 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:48,271 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:48,273 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:48,728 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:48,730 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:48,730 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:48,730 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:48,732 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:51,270 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:51,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:51,272 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:51,272 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:51,272 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:51,274 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:19:51,729 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:51,731 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:51,731 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:51,731 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:51,733 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:54,270 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:54,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:54,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:54,273 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:54,273 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:54,275 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:54,728 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:54,731 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:54,731 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:54,731 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:54,733 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:57,271 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:19:57,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:57,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:57,273 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:57,274 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:57,275 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:19:57,728 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:19:57,730 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:19:57,730 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:19:57,731 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:19:57,732 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:00,271 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:00,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:00,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:00,273 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:00,273 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:00,275 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:00,728 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:00,731 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:00,731 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:00,731 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:00,733 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:03,271 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:03,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:03,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:03,273 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:03,273 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:03,275 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:03,728 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:03,730 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:03,730 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:03,731 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:03,732 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:06,271 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:06,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:06,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:06,273 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:06,273 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:06,276 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:06,728 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:06,731 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:06,731 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:06,731 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:06,733 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:09,272 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:09,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:09,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:09,274 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:09,274 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:09,278 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:09,729 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:09,732 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:09,732 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:09,732 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:09,739 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:12,272 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:12,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:12,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:12,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:12,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:12,278 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:12,730 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:12,732 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:12,732 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:12,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:12,735 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:15,272 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:15,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:15,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:15,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:15,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:15,281 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:15,730 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:15,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:15,733 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:15,734 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:15,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:18,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:18,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:18,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:18,277 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:18,277 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:18,280 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:18,730 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:18,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:18,733 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:18,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:18,735 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:21,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:21,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:21,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:21,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:21,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:21,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:21,730 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:21,732 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:21,732 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:21,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:21,734 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:24,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:24,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:24,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:24,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:24,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:24,278 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:24,730 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:24,732 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:24,732 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:24,732 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:24,734 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:27,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:27,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:27,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:27,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:27,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:27,278 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:27,730 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:27,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:27,733 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:27,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:27,735 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:30,274 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:30,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:30,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:30,277 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:30,277 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:30,279 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:30,731 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:30,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:30,733 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:30,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:30,735 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:33,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:33,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:33,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:33,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:33,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:33,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:33,731 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:33,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:33,733 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:33,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:33,735 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:36,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:36,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:36,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:36,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:36,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:36,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:36,730 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:36,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:36,733 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:36,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:36,736 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 2 msecs
2014-05-05 11:20:39,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:39,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:39,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:39,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:39,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:39,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:20:39,730 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:39,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:39,733 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:39,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:39,734 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:42,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:42,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:42,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:42,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:42,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:42,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:42,731 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:42,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:42,733 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:42,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:42,734 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:45,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:45,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:45,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:45,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:45,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:45,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:45,731 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:45,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:45,733 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:45,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:45,734 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:48,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:48,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:48,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:48,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:48,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:48,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:48,731 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:48,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:48,733 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:48,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:48,734 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:51,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:51,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:51,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:51,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:51,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:51,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:51,732 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:51,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:51,734 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:51,734 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:51,735 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:54,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:54,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:54,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:54,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:54,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:54,276 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:54,731 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:54,733 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:54,733 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:54,733 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:54,734 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:57,272 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:20:57,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:57,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:57,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:57,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:57,276 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:20:57,732 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:20:57,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:20:57,734 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:20:57,734 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:20:57,735 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:00,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:00,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:00,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:00,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:00,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:00,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:00,732 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:00,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:00,734 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:00,734 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:00,736 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:03,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:03,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:03,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:03,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:03,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:03,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:03,731 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:03,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:03,734 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:03,734 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:03,735 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:06,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:06,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:06,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:06,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:06,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:06,278 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:06,732 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:06,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:06,735 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:06,735 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:06,736 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:09,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:09,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:09,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:09,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:09,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:09,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:21:09,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:09,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:09,735 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:09,735 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:09,736 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:12,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:12,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:12,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:12,277 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:12,277 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:12,278 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:12,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:12,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:12,735 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:12,735 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:12,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:15,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:15,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:15,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:15,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:15,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:15,276 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:15,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:15,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:15,735 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:15,735 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:15,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:18,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:18,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:18,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:18,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:18,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:18,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:18,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:18,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:18,736 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:18,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:18,738 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:21,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:21,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:21,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:21,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:21,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:21,278 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:21,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:21,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:21,736 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:21,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:21,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:24,272 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:24,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:24,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:24,275 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:24,275 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:24,276 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:24,734 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:24,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:24,736 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:24,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:24,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:27,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:27,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:27,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:27,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:27,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:27,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:27,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:27,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:27,736 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:27,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:27,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:30,274 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:30,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:30,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:30,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:30,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:30,278 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:30,734 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:30,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:30,736 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:30,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:30,738 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:33,275 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:33,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:33,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:33,277 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:33,277 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:33,278 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:33,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:33,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:33,735 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:33,735 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:33,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:36,274 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:36,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:36,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:36,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:36,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:36,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:36,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:36,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:36,735 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:36,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:36,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:39,274 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:39,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:39,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:39,277 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:39,277 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:39,278 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:39,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:39,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:39,735 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:39,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:39,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:42,274 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:42,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:42,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:42,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:42,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:42,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:42,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:42,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:42,736 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:42,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:42,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:45,274 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:45,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:45,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:45,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:45,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:45,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:45,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:45,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:45,735 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:45,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:45,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:48,273 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:48,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:48,276 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:48,276 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:48,276 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:48,277 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:48,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:48,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:48,735 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:48,735 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:48,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:51,275 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:51,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:51,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:51,277 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:51,277 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:51,280 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 1 msecs
2014-05-05 11:21:51,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:51,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:51,736 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:51,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:51,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:54,275 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:54,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:54,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:54,277 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:54,278 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:54,279 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:54,734 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:54,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:54,736 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:54,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:54,738 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:57,275 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:21:57,278 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:57,278 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:57,278 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:57,278 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:57,279 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:21:57,734 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:21:57,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:21:57,736 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:21:57,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:21:57,738 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:22:00,276 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:22:00,278 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:22:00,279 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:22:00,279 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:22:00,279 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:22:00,281 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:22:00,733 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.195:50010 is expected to serve this storage.
2014-05-05 11:22:00,736 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:22:00,736 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.195:50010
2014-05-05 11:22:00,736 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:22:00,737 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:22:03,277 FATAL org.apache.hadoop.hdfs.StateChange: BLOCK* NameSystem.getDatanode: Data node DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) is attempting to report storage ID DS-1956763462-10.0.0.158-50010-1399248303882. Node 10.0.0.194:50010 is expected to serve this storage.
2014-05-05 11:22:03,280 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) storage DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:22:03,280 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: 10.0.0.194:50010 is replaced by DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0) with the same storageID DS-1956763462-10.0.0.158-50010-1399248303882
2014-05-05 11:22:03,280 INFO org.apache.hadoop.net.NetworkTopology: Removing a node: /default-rack/10.0.0.194:50010
2014-05-05 11:22:03,280 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:22:03,282 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1956763462-10.0.0.158-50010-1399248303882, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-d15da203-f6c5-4f57-ae24-0c30923abeda;nsid=1706908940;c=0), blocks: 89, processing time: 0 msecs
2014-05-05 11:22:03,565 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 11:22:03,567 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 11:23:18,140 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-patch/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-05-04T05:58Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 11:23:18,148 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 11:23:18,441 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 11:23:18,550 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 11:23:18,550 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 11:23:18,874 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-05-05 11:23:19,176 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 11:23:19,250 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 11:23:19,253 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 11:23:19,253 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 11:23:19,254 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 11:23:19,296 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 11:23:19,338 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 11:23:19,338 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 11:23:19,728 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 11:23:19,728 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 11:23:19,762 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 11:23:19,762 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 11:23:19,842 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 11:23:19,842 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 11:23:19,845 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 11:23:19,849 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 11:23:19,849 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 11:23:19,850 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2014-05-05 11:23:19,850 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2014-05-05 11:23:19,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 11:23:19,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 11:23:19,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 11:23:19,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 11:23:19,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 11:23:19,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 11:23:19,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 11:23:19,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 11:23:19,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 11:23:19,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 11:23:19,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 11:23:19,867 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 11:23:19,869 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 11:23:19,931 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 11:23:19,931 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 11:23:19,931 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2014-05-05 11:23:19,931 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2014-05-05 11:23:19,933 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 11:23:19,937 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 11:23:19,937 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 11:23:19,937 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 11:23:19,939 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 11:23:19,939 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 11:23:19,944 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 11:23:19,944 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 11:23:19,944 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2014-05-05 11:23:19,944 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2014-05-05 11:23:19,978 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 4826@ip-10-0-0-195
2014-05-05 11:23:20,073 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 11:23:20,076 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2014-05-05 11:23:20,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000 using no compression
2014-05-05 11:23:20,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 1
2014-05-05 11:23:20,097 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2014-05-05 11:23:20,098 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000 of size 198 bytes loaded in 0 seconds.
2014-05-05 11:23:20,098 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000
2014-05-05 11:23:20,105 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2014-05-05 11:23:20,280 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 11:23:20,280 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 334 msecs
2014-05-05 11:23:20,518 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 11:23:20,535 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 11:23:20,587 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 11:23:20,598 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 11:23:20,599 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 11:23:20,599 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2014-05-05 11:23:20,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2014-05-05 11:23:20,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2014-05-05 11:23:20,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2014-05-05 11:23:20,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2014-05-05 11:23:20,606 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2014-05-05 11:23:20,606 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2014-05-05 11:23:20,606 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2014-05-05 11:23:20,607 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2014-05-05 11:23:20,607 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2014-05-05 11:23:20,637 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 11:23:20,638 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 11:23:20,641 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 11:23:20,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 11:23:25,312 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1958716965-10.0.0.195-50010-1399289005080, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-1958716965-10.0.0.195-50010-1399289005080
2014-05-05 11:23:25,315 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:23:25,342 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-2003490428-10.0.0.194-50010-1399289005129, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-2003490428-10.0.0.194-50010-1399289005129
2014-05-05 11:23:25,342 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:23:25,390 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1840104526-10.0.0.193-50010-1399289005080, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-1840104526-10.0.0.193-50010-1399289005080
2014-05-05 11:23:25,391 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 11:23:25,440 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-704496375-10.0.0.200-50010-1399289005076, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-704496375-10.0.0.200-50010-1399289005076
2014-05-05 11:23:25,441 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 11:23:25,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:23:25,487 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-2003490428-10.0.0.194-50010-1399289005129, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 2 msecs
2014-05-05 11:23:25,491 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:23:25,491 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1840104526-10.0.0.193-50010-1399289005080, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 11:23:25,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:23:25,492 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1958716965-10.0.0.195-50010-1399289005080, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 1 msecs
2014-05-05 11:23:25,545 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:23:25,545 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-704496375-10.0.0.200-50010-1399289005076, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 11:23:28,259 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.196, storageID=DS-646502608-10.0.0.196-50010-1399289008028, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-646502608-10.0.0.196-50010-1399289008028
2014-05-05 11:23:28,259 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.196:50010
2014-05-05 11:23:28,365 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.196:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:23:28,365 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.196, storageID=DS-646502608-10.0.0.196-50010-1399289008028, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 11:23:28,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.197, storageID=DS-127611273-10.0.0.197-50010-1399289008642, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-127611273-10.0.0.197-50010-1399289008642
2014-05-05 11:23:28,882 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.197:50010
2014-05-05 11:23:29,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.197:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:23:29,009 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.197, storageID=DS-127611273-10.0.0.197-50010-1399289008642, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 11:23:29,096 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.199, storageID=DS-931001925-10.0.0.199-50010-1399289008879, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-931001925-10.0.0.199-50010-1399289008879
2014-05-05 11:23:29,097 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.199:50010
2014-05-05 11:23:29,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.199:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:23:29,216 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.199, storageID=DS-931001925-10.0.0.199-50010-1399289008879, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 11:23:31,217 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.198, storageID=DS-2100920188-10.0.0.198-50010-1399289010952, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-2100920188-10.0.0.198-50010-1399289010952
2014-05-05 11:23:31,218 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.198:50010
2014-05-05 11:23:31,290 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.198:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:23:31,290 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.198, storageID=DS-2100920188-10.0.0.198-50010-1399289010952, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 11:24:31,035 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 11:24:31,035 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 11:24:31,035 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2014-05-05 11:24:31,035 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 73 
2014-05-05 11:24:31,037 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 75 
2014-05-05 11:24:31,038 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000002
2014-05-05 11:24:31,038 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2014-05-05 11:24:31,706 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=2&storageInfo=-47:172347890:0:CID-12638edf-52d0-4ee2-860a-8c4caf72e336
2014-05-05 11:24:31,918 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.21s at 0.00 KB/s
2014-05-05 11:24:31,918 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 198 bytes.
2014-05-05 11:24:31,927 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2014-05-05 11:27:46,280 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.196, storageID=DS-646502608-10.0.0.196-50010-1399289008028, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 11:36:30,010 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 35 
2014-05-05 11:36:38,977 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-625903679-10.0.0.195-1399288960104 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 11:36:41,249 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:36:41,252 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:36:41,255 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:36:41,258 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:36:41,261 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-625903679-10.0.0.195-1399288960104 blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]}
2014-05-05 11:36:43,044 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:36:43,048 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:36:43,051 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:36:43,053 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:36:43,055 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-625903679-10.0.0.195-1399288960104 blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 11:36:44,550 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:36:44,551 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:36:44,553 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:36:44,555 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:36:44,557 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-625903679-10.0.0.195-1399288960104 blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 11:36:45,072 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:36:45,073 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:36:45,074 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:36:45,076 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:36:45,106 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /in1m/data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1607256882_1
2014-05-05 11:38:52,465 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 22 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 77 
2014-05-05 11:38:52,649 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job.jar. BP-625903679-10.0.0.195-1399288960104 blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 11:38:53,307 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 11:38:53,308 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 11:38:53,309 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 11:38:53,311 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 11:38:53,316 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-353868925_1
2014-05-05 11:38:53,323 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job.jar
2014-05-05 11:38:53,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job.split
2014-05-05 11:38:53,408 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job.split. BP-625903679-10.0.0.195-1399288960104 blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]}
2014-05-05 11:38:53,571 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:38:53,572 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:38:53,573 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:38:53,576 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:38:53,581 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:38:53,582 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:38:53,584 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:38:53,585 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:38:53,589 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job.split is closed by DFSClient_NONMAPREDUCE_-353868925_1
2014-05-05 11:38:53,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job.splitmetainfo. BP-625903679-10.0.0.195-1399288960104 blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 11:38:53,610 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:38:53,611 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:38:53,612 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:38:53,613 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:38:53,617 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-353868925_1
2014-05-05 11:38:53,688 INFO BlockStateChange: BLOCK* ask 10.0.0.198:50010 to replicate blk_1073741829_1005 to datanode(s) 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.196:50010
2014-05-05 11:38:54,018 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 11:38:54,041 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:38:54,042 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:38:54,043 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:38:54,044 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:38:54,062 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-353868925_1
2014-05-05 11:38:55,617 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741829_1005 size 39460542
2014-05-05 11:38:55,617 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741829_1005 size 39460542
2014-05-05 11:38:55,618 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741829_1005 size 39460542
2014-05-05 11:38:55,618 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741829_1005 size 39460542
2014-05-05 11:39:04,998 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job_1399289015992_0001_1_conf.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 11:39:05,180 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:39:05,181 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:39:05,182 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:39:05,183 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:39:05,189 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job_1399289015992_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1027871401_1
2014-05-05 11:39:20,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job_1399289015992_0001_1.jhist. BP-625903679-10.0.0.195-1399288960104 blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 11:39:20,251 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job_1399289015992_0001_1.jhist for DFSClient_NONMAPREDUCE_1027871401_1
2014-05-05 11:42:05,150 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:42:05,151 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:42:05,154 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:42:05,154 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:42:05,156 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 66 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 0 Number of syncs: 31 SyncTimes(ms): 146 
2014-05-05 11:42:05,157 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0001/job_1399289015992_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_1027871401_1
2014-05-05 11:42:05,163 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399289015992_0001.summary_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 11:42:05,178 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:42:05,179 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:42:05,180 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:42:05,181 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:42:05,187 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399289015992_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_1027871401_1
2014-05-05 11:42:05,208 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399289015992_0001-1399289934331-ubuntu-hints%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399290125135-4-6-KILLED-default.jhist_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 11:42:05,223 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:42:05,225 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:42:05,226 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:42:05,228 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:42:05,231 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399289015992_0001-1399289934331-ubuntu-hints%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399290125135-4-6-KILLED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1027871401_1
2014-05-05 11:42:05,246 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399289015992_0001_conf.xml_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 11:42:05,261 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 11:42:05,262 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 11:42:05,263 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 11:42:05,264 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 11:42:05,268 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399289015992_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1027871401_1
2014-05-05 11:42:06,325 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741829_1005 10.0.0.195:50010 10.0.0.197:50010 10.0.0.199:50010 10.0.0.198:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.196:50010 10.0.0.193:50010 
2014-05-05 11:42:06,325 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741830_1006 10.0.0.195:50010 10.0.0.196:50010 10.0.0.200:50010 10.0.0.198:50010 10.0.0.193:50010 10.0.0.197:50010 10.0.0.194:50010 10.0.0.199:50010 
2014-05-05 11:42:06,325 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741831_1007 10.0.0.195:50010 10.0.0.198:50010 10.0.0.193:50010 10.0.0.196:50010 
2014-05-05 11:42:06,325 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741832_1008 10.0.0.195:50010 10.0.0.200:50010 10.0.0.197:50010 10.0.0.196:50010 
2014-05-05 11:42:06,325 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741834_1010 10.0.0.193:50010 10.0.0.195:50010 10.0.0.196:50010 10.0.0.194:50010 
2014-05-05 11:42:06,325 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741833_1009 10.0.0.193:50010 10.0.0.194:50010 10.0.0.196:50010 10.0.0.197:50010 
2014-05-05 11:42:08,715 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.199:50010 to delete [blk_1073741829_1005, blk_1073741830_1006]
2014-05-05 11:42:08,716 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.196:50010 to delete [blk_1073741829_1005, blk_1073741830_1006, blk_1073741831_1007, blk_1073741832_1008, blk_1073741833_1009, blk_1073741834_1010]
2014-05-05 11:42:08,716 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741829_1005, blk_1073741830_1006, blk_1073741831_1007, blk_1073741833_1009, blk_1073741834_1010]
2014-05-05 11:42:11,716 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.198:50010 to delete [blk_1073741829_1005, blk_1073741830_1006, blk_1073741831_1007]
2014-05-05 11:42:11,716 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741829_1005, blk_1073741830_1006, blk_1073741833_1009, blk_1073741834_1010]
2014-05-05 11:42:11,716 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741829_1005, blk_1073741830_1006, blk_1073741832_1008]
2014-05-05 11:42:14,717 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.197:50010 to delete [blk_1073741829_1005, blk_1073741830_1006, blk_1073741832_1008, blk_1073741833_1009]
2014-05-05 11:42:14,717 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741829_1005, blk_1073741830_1006, blk_1073741831_1007, blk_1073741832_1008, blk_1073741834_1010]
2014-05-05 11:42:55,645 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job.jar. BP-625903679-10.0.0.195-1399288960104 blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 11:42:56,414 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:42:56,415 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:42:56,416 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:42:56,420 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:42:56,426 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job.jar is closed by DFSClient_NONMAPREDUCE_51479843_1
2014-05-05 11:42:56,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job.jar
2014-05-05 11:42:56,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job.split
2014-05-05 11:42:56,497 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 11:42:56,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job.split. BP-625903679-10.0.0.195-1399288960104 blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 11:42:56,521 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:42:56,523 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:42:56,523 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:42:56,525 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:42:56,525 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:42:56,527 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:42:56,528 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:42:56,531 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job.split is closed by DFSClient_NONMAPREDUCE_51479843_1
2014-05-05 11:42:56,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job.splitmetainfo. BP-625903679-10.0.0.195-1399288960104 blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 11:42:56,553 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:42:56,556 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:42:56,557 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:42:56,558 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:42:56,561 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_51479843_1
2014-05-05 11:42:56,844 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 11:42:56,864 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:42:56,865 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:42:56,866 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:42:56,868 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:42:57,687 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job.xml is closed by DFSClient_NONMAPREDUCE_51479843_1
2014-05-05 11:42:59,720 INFO BlockStateChange: BLOCK* ask 10.0.0.194:50010 to replicate blk_1073741838_1014 to datanode(s) 10.0.0.197:50010 10.0.0.193:50010 10.0.0.198:50010 10.0.0.200:50010
2014-05-05 11:42:59,721 INFO BlockStateChange: BLOCK* ask 10.0.0.196:50010 to replicate blk_1073741839_1015 to datanode(s) 10.0.0.199:50010
2014-05-05 11:43:01,334 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741839_1015 size 559
2014-05-05 11:43:01,671 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741838_1014 size 39460542
2014-05-05 11:43:01,673 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741838_1014 size 39460542
2014-05-05 11:43:01,674 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741838_1014 size 39460542
2014-05-05 11:43:01,674 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741838_1014 size 39460542
2014-05-05 11:43:04,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job_1399289015992_0002_1_conf.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]}
2014-05-05 11:43:05,105 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:43:05,106 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:43:05,107 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:43:05,111 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:43:05,962 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job_1399289015992_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_326606760_1
2014-05-05 11:43:25,581 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job_1399289015992_0002_1.jhist. BP-625903679-10.0.0.195-1399288960104 blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 11:43:25,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job_1399289015992_0002_1.jhist for DFSClient_NONMAPREDUCE_326606760_1
2014-05-05 11:43:25,598 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 126 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 0 Number of syncs: 64 SyncTimes(ms): 2659 
2014-05-05 11:46:32,381 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:46:32,382 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:46:32,383 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:46:32,384 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:46:32,424 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 127 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 0 Number of syncs: 65 SyncTimes(ms): 2660 
2014-05-05 11:46:32,443 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0002/job_1399289015992_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_326606760_1
2014-05-05 11:46:32,452 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399289015992_0002.summary_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 11:46:32,465 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:46:32,466 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:46:32,467 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:46:32,468 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:46:32,470 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399289015992_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_326606760_1
2014-05-05 11:46:32,492 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399289015992_0002-1399290177883-ubuntu-hints%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399290392351-2-0-KILLED-default.jhist_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 11:46:32,508 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:32,509 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:32,510 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:32,511 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:32,515 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399289015992_0002-1399290177883-ubuntu-hints%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399290392351-2-0-KILLED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_326606760_1
2014-05-05 11:46:32,528 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399289015992_0002_conf.xml_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 11:46:32,544 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:32,545 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:32,546 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:32,547 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:32,550 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399289015992_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_326606760_1
2014-05-05 11:46:33,584 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741838_1014 10.0.0.195:50010 10.0.0.199:50010 10.0.0.196:50010 10.0.0.194:50010 10.0.0.197:50010 10.0.0.193:50010 10.0.0.198:50010 10.0.0.200:50010 
2014-05-05 11:46:33,584 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741839_1015 10.0.0.198:50010 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.197:50010 10.0.0.193:50010 10.0.0.196:50010 10.0.0.199:50010 
2014-05-05 11:46:33,584 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741840_1016 10.0.0.195:50010 10.0.0.198:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 11:46:33,584 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741841_1017 10.0.0.195:50010 10.0.0.194:50010 10.0.0.196:50010 10.0.0.200:50010 
2014-05-05 11:46:33,584 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741843_1019 10.0.0.198:50010 10.0.0.199:50010 10.0.0.194:50010 10.0.0.195:50010 
2014-05-05 11:46:33,584 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741842_1018 10.0.0.198:50010 10.0.0.195:50010 10.0.0.194:50010 10.0.0.199:50010 
2014-05-05 11:46:35,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.197:50010 to delete [blk_1073741838_1014, blk_1073741839_1015]
2014-05-05 11:46:35,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741842_1018, blk_1073741843_1019, blk_1073741838_1014, blk_1073741839_1015]
2014-05-05 11:46:35,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.198:50010 to delete [blk_1073741840_1016, blk_1073741842_1018, blk_1073741843_1019, blk_1073741838_1014, blk_1073741839_1015]
2014-05-05 11:46:38,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741842_1018, blk_1073741843_1019, blk_1073741838_1014, blk_1073741839_1015]
2014-05-05 11:46:38,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.196:50010 to delete [blk_1073741841_1017, blk_1073741838_1014, blk_1073741839_1015]
2014-05-05 11:46:38,746 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741838_1014, blk_1073741839_1015]
2014-05-05 11:46:41,747 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741838_1014, blk_1073741839_1015]
2014-05-05 11:46:41,747 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.199:50010 to delete [blk_1073741842_1018, blk_1073741843_1019, blk_1073741838_1014, blk_1073741839_1015]
2014-05-05 11:46:47,184 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job.jar. BP-625903679-10.0.0.195-1399288960104 blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 11:46:47,806 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,807 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,807 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,809 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,814 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job.jar is closed by DFSClient_NONMAPREDUCE_1350707644_1
2014-05-05 11:46:47,818 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job.jar
2014-05-05 11:46:47,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job.split
2014-05-05 11:46:47,904 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job.split. BP-625903679-10.0.0.195-1399288960104 blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 11:46:47,935 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,936 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,937 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,938 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,939 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,941 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,943 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,944 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,947 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job.split is closed by DFSClient_NONMAPREDUCE_1350707644_1
2014-05-05 11:46:47,956 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job.splitmetainfo. BP-625903679-10.0.0.195-1399288960104 blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 11:46:47,970 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,971 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,972 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,973 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:47,976 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1350707644_1
2014-05-05 11:46:48,254 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 11:46:48,271 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:48,272 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:48,274 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:48,275 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:46:48,278 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job.xml is closed by DFSClient_NONMAPREDUCE_1350707644_1
2014-05-05 11:46:50,749 INFO BlockStateChange: BLOCK* ask 10.0.0.197:50010 to replicate blk_1073741847_1023 to datanode(s) 10.0.0.198:50010 10.0.0.193:50010 10.0.0.199:50010 10.0.0.194:50010
2014-05-05 11:46:53,221 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741847_1023 size 39460542
2014-05-05 11:46:53,222 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741847_1023 size 39460542
2014-05-05 11:46:53,223 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741847_1023 size 39460542
2014-05-05 11:46:53,223 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741847_1023 size 39460542
2014-05-05 11:46:59,870 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job_1399289015992_0003_1_conf.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 11:47:00,076 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:47:00,077 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:47:00,079 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:47:00,083 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:47:00,684 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job_1399289015992_0003_1_conf.xml is closed by DFSClient_NONMAPREDUCE_405020888_1
2014-05-05 11:47:29,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job_1399289015992_0003_1.jhist. BP-625903679-10.0.0.195-1399288960104 blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 11:47:29,625 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0003/job_1399289015992_0003_1.jhist for DFSClient_NONMAPREDUCE_405020888_1
2014-05-05 11:49:03,405 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 188 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 0 Number of syncs: 99 SyncTimes(ms): 5223 
2014-05-05 11:49:03,485 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job.jar. BP-625903679-10.0.0.195-1399288960104 blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 11:49:04,077 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,078 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,079 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,080 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,085 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job.jar is closed by DFSClient_NONMAPREDUCE_-1031593778_1
2014-05-05 11:49:04,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job.jar
2014-05-05 11:49:04,148 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job.split
2014-05-05 11:49:04,157 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job.split. BP-625903679-10.0.0.195-1399288960104 blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 11:49:04,186 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,187 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,188 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,189 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,190 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,191 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,192 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,193 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,207 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job.split is closed by DFSClient_NONMAPREDUCE_-1031593778_1
2014-05-05 11:49:04,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job.splitmetainfo. BP-625903679-10.0.0.195-1399288960104 blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 11:49:04,236 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:49:04,237 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:49:04,238 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:49:04,239 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:49:04,241 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1031593778_1
2014-05-05 11:49:04,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 11:49:04,542 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,543 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,544 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,545 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:49:04,549 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job.xml is closed by DFSClient_NONMAPREDUCE_-1031593778_1
2014-05-05 11:49:05,767 INFO BlockStateChange: BLOCK* ask 10.0.0.195:50010 to replicate blk_1073741853_1029 to datanode(s) 10.0.0.199:50010 10.0.0.198:50010 10.0.0.197:50010 10.0.0.193:50010
2014-05-05 11:49:07,906 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741853_1029 size 39460542
2014-05-05 11:49:07,908 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741853_1029 size 39460542
2014-05-05 11:49:07,909 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741853_1029 size 39460542
2014-05-05 11:49:07,909 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741853_1029 size 39460542
2014-05-05 11:49:11,310 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job_1399289015992_0004_1_conf.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 11:49:11,538 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:49:11,539 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:49:11,540 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:49:11,542 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:49:11,554 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job_1399289015992_0004_1_conf.xml is closed by DFSClient_NONMAPREDUCE_625965428_1
2014-05-05 11:49:23,973 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job_1399289015992_0004_1.jhist. BP-625903679-10.0.0.195-1399288960104 blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 11:49:23,988 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0004/job_1399289015992_0004_1.jhist for DFSClient_NONMAPREDUCE_625965428_1
2014-05-05 11:51:14,176 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.199, storageID=DS-931001925-10.0.0.199-50010-1399289008879, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 12, processing time: 1 msecs
2014-05-05 11:51:35,439 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 226 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 0 Number of syncs: 119 SyncTimes(ms): 5262 
2014-05-05 11:51:35,516 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job.jar. BP-625903679-10.0.0.195-1399288960104 blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 11:51:36,200 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:51:36,202 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:51:36,202 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:51:36,204 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:51:36,232 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job.jar is closed by DFSClient_NONMAPREDUCE_-502047622_1
2014-05-05 11:51:36,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job.jar
2014-05-05 11:51:36,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job.split
2014-05-05 11:51:36,365 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job.split. BP-625903679-10.0.0.195-1399288960104 blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]}
2014-05-05 11:51:36,413 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:51:36,414 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:51:36,415 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:51:36,420 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:51:36,421 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:51:36,422 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:51:36,426 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:51:36,426 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 11:51:36,439 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job.split is closed by DFSClient_NONMAPREDUCE_-502047622_1
2014-05-05 11:51:36,449 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job.splitmetainfo. BP-625903679-10.0.0.195-1399288960104 blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 11:51:36,469 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:51:36,470 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:51:36,471 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:51:36,472 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 11:51:36,476 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-502047622_1
2014-05-05 11:51:36,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741862_1038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 11:51:36,902 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741862_1038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:51:36,903 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741862_1038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:51:36,905 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741862_1038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:51:36,906 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741862_1038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:51:36,909 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job.xml is closed by DFSClient_NONMAPREDUCE_-502047622_1
2014-05-05 11:51:38,791 INFO BlockStateChange: BLOCK* ask 10.0.0.194:50010 to replicate blk_1073741859_1035 to datanode(s) 10.0.0.196:50010 10.0.0.200:50010 10.0.0.197:50010 10.0.0.198:50010
2014-05-05 11:51:40,745 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741859_1035 size 39460542
2014-05-05 11:51:40,745 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741859_1035 size 39460542
2014-05-05 11:51:40,746 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741859_1035 size 39460542
2014-05-05 11:51:40,746 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741859_1035 size 39460542
2014-05-05 11:51:43,252 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job_1399289015992_0005_1_conf.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741863_1039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 11:51:43,458 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741863_1039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:51:43,458 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741863_1039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:51:43,460 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741863_1039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:51:43,461 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741863_1039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:51:43,482 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job_1399289015992_0005_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1640957578_1
2014-05-05 11:51:57,393 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job_1399289015992_0005_1.jhist. BP-625903679-10.0.0.195-1399288960104 blk_1073741864_1040{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 11:51:57,407 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399289015992_0005/job_1399289015992_0005_1.jhist for DFSClient_NONMAPREDUCE_1640957578_1
2014-05-05 11:52:19,517 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 11:52:19,519 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 11:52:54,004 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-patch/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-05-04T05:58Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 11:52:54,016 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 11:52:54,318 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 11:52:54,428 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 11:52:54,428 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 11:52:54,738 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-05-05 11:52:55,027 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 11:52:55,128 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 11:52:55,131 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 11:52:55,131 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 11:52:55,132 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 11:52:55,151 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 11:52:55,172 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 11:52:55,172 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 11:52:55,630 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 11:52:55,630 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 11:52:55,664 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 11:52:55,664 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 11:52:55,739 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 11:52:55,739 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 11:52:55,742 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 11:52:55,744 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 11:52:55,744 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 11:52:55,745 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2014-05-05 11:52:55,745 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2014-05-05 11:52:55,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 11:52:55,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 11:52:55,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 11:52:55,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 11:52:55,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 11:52:55,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 11:52:55,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 11:52:55,750 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 11:52:55,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 11:52:55,758 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 11:52:55,758 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 11:52:55,758 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 11:52:55,759 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 11:52:55,815 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 11:52:55,815 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 11:52:55,815 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2014-05-05 11:52:55,816 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2014-05-05 11:52:55,816 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 11:52:55,819 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 11:52:55,819 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 11:52:55,819 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 11:52:55,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 11:52:55,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 11:52:55,823 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 11:52:55,823 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 11:52:55,823 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2014-05-05 11:52:55,823 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2014-05-05 11:52:55,870 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 10398@ip-10-0-0-195
2014-05-05 11:52:56,049 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 11:52:56,202 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000003 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000003-0000000000000000265
2014-05-05 11:52:56,223 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000002 using no compression
2014-05-05 11:52:56,223 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 1
2014-05-05 11:52:56,228 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2014-05-05 11:52:56,229 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000002 of size 198 bytes loaded in 0 seconds.
2014-05-05 11:52:56,229 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000002
2014-05-05 11:52:56,229 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5b1413a8 expecting start txid #3
2014-05-05 11:52:56,229 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000003-0000000000000000265
2014-05-05 11:52:56,232 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000000003-0000000000000000265' to transaction ID 3
2014-05-05 11:52:56,317 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000003-0000000000000000265 of size 1048576 edits # 263 loaded in 0 seconds
2014-05-05 11:52:56,318 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 266
2014-05-05 11:52:56,444 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 11:52:56,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 620 msecs
2014-05-05 11:52:56,666 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 11:52:56,685 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 11:52:56,739 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 11:52:56,750 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 3
2014-05-05 11:52:56,750 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 3
2014-05-05 11:52:56,752 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 25 blocks to reach the threshold 0.9990 of total blocks 25.
Safe mode will be turned off automatically
2014-05-05 11:52:56,780 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 11:52:56,780 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 11:52:56,783 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 11:52:56,783 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 11:53:01,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1958716965-10.0.0.195-50010-1399289005080, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-1958716965-10.0.0.195-50010-1399289005080
2014-05-05 11:53:01,224 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 11:53:01,228 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.199, storageID=DS-931001925-10.0.0.199-50010-1399289008879, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-931001925-10.0.0.199-50010-1399289008879
2014-05-05 11:53:01,238 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.199:50010
2014-05-05 11:53:01,239 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.198, storageID=DS-2100920188-10.0.0.198-50010-1399289010952, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-2100920188-10.0.0.198-50010-1399289010952
2014-05-05 11:53:01,239 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.198:50010
2014-05-05 11:53:01,290 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-704496375-10.0.0.200-50010-1399289005076, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-704496375-10.0.0.200-50010-1399289005076
2014-05-05 11:53:01,293 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 11:53:01,301 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.196, storageID=DS-646502608-10.0.0.196-50010-1399289008028, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-646502608-10.0.0.196-50010-1399289008028
2014-05-05 11:53:01,303 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.196:50010
2014-05-05 11:53:01,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1840104526-10.0.0.193-50010-1399289005080, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-1840104526-10.0.0.193-50010-1399289005080
2014-05-05 11:53:01,337 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 11:53:01,339 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-2003490428-10.0.0.194-50010-1399289005129, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-2003490428-10.0.0.194-50010-1399289005129
2014-05-05 11:53:01,339 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 11:53:01,404 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.199:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:53:01,404 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.199, storageID=DS-931001925-10.0.0.199-50010-1399289008879, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 15, processing time: 4 msecs
2014-05-05 11:53:01,404 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.197, storageID=DS-127611273-10.0.0.197-50010-1399289008642, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-127611273-10.0.0.197-50010-1399289008642
2014-05-05 11:53:01,405 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.197:50010
2014-05-05 11:53:01,412 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.198:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:53:01,412 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.198, storageID=DS-2100920188-10.0.0.198-50010-1399289010952, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 18, processing time: 0 msecs
2014-05-05 11:53:01,416 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 24 has reached the threshold 0.9990 of total blocks 25. The number of live datanodes 8 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2014-05-05 11:53:01,416 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2014-05-05 11:53:01,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 28
2014-05-05 11:53:01,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2014-05-05 11:53:01,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 25
2014-05-05 11:53:01,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2014-05-05 11:53:01,445 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 3
2014-05-05 11:53:01,445 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 29 msec
2014-05-05 11:53:01,446 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:53:01,446 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-2003490428-10.0.0.194-50010-1399289005129, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 18, processing time: 32 msecs
2014-05-05 11:53:01,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:53:01,449 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-704496375-10.0.0.200-50010-1399289005076, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 14, processing time: 0 msecs
2014-05-05 11:53:01,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:53:01,450 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1840104526-10.0.0.193-50010-1399289005080, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 13, processing time: 1 msecs
2014-05-05 11:53:01,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:53:01,456 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1958716965-10.0.0.195-50010-1399289005080, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 22, processing time: 1 msecs
2014-05-05 11:53:01,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.196:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:53:01,473 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.196, storageID=DS-646502608-10.0.0.196-50010-1399289008028, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 16, processing time: 1 msecs
2014-05-05 11:53:01,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.197:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 11:53:01,483 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.197, storageID=DS-127611273-10.0.0.197-50010-1399289008642, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 20, processing time: 1 msecs
2014-05-05 11:53:21,454 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 25 has reached the threshold 0.9990 of total blocks 25. The number of live datanodes 8 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2014-05-05 11:53:31,455 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2014-05-05 11:53:31,455 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2014-05-05 11:53:31,455 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 8 datanodes
2014-05-05 11:53:31,455 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 6 blocks
2014-05-05 11:54:05,594 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 77 
2014-05-05 11:54:05,990 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job.jar. BP-625903679-10.0.0.195-1399288960104 blk_1073741865_1041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 11:54:07,063 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741865_1041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:54:07,064 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741865_1041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:54:07,067 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741865_1041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:54:07,077 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741865_1041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:54:07,078 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 11:54:07,078 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 11:54:07,078 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 266
2014-05-05 11:54:07,082 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 8 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 88 
2014-05-05 11:54:07,083 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000266 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000266-0000000000000000273
2014-05-05 11:54:07,083 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 274
2014-05-05 11:54:07,160 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job.jar is closed by DFSClient_NONMAPREDUCE_2011889050_1
2014-05-05 11:54:07,202 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job.jar
2014-05-05 11:54:07,337 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job.split
2014-05-05 11:54:07,359 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job.split. BP-625903679-10.0.0.195-1399288960104 blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 11:54:07,715 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:54:07,716 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:54:07,722 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:54:07,724 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:54:07,726 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:54:07,728 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:54:07,730 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:54:07,733 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:54:07,737 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job.split is closed by DFSClient_NONMAPREDUCE_2011889050_1
2014-05-05 11:54:07,748 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job.splitmetainfo. BP-625903679-10.0.0.195-1399288960104 blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 11:54:07,766 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 11:54:07,766 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 11:54:07,768 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 11:54:07,771 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 11:54:07,775 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_2011889050_1
2014-05-05 11:54:08,186 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=273&storageInfo=-47:172347890:0:CID-12638edf-52d0-4ee2-860a-8c4caf72e336
2014-05-05 11:54:08,316 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 11:54:08,366 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:54:08,367 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:54:08,370 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:54:08,371 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:54:08,374 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job.xml is closed by DFSClient_NONMAPREDUCE_2011889050_1
2014-05-05 11:54:08,514 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.33s at 15.24 KB/s
2014-05-05 11:54:08,514 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000273 size 5606 bytes.
2014-05-05 11:54:08,523 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2014-05-05 11:54:08,523 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2014-05-05 11:54:08,774 INFO BlockStateChange: BLOCK* ask 10.0.0.200:50010 to replicate blk_1073741865_1041 to datanode(s) 10.0.0.198:50010 10.0.0.199:50010 10.0.0.196:50010 10.0.0.193:50010
2014-05-05 11:54:10,721 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741865_1041 size 39460542
2014-05-05 11:54:10,724 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741865_1041 size 39460542
2014-05-05 11:54:10,724 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741865_1041 size 39460542
2014-05-05 11:54:10,725 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741865_1041 size 39460542
2014-05-05 11:54:16,893 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job_1399290791848_0001_1_conf.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 11:54:17,026 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:54:17,028 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:54:17,029 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:54:17,030 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:54:17,036 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job_1399290791848_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_240659755_1
2014-05-05 11:54:34,773 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job_1399290791848_0001_1.jhist. BP-625903679-10.0.0.195-1399288960104 blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 11:54:34,832 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job_1399290791848_0001_1.jhist for DFSClient_NONMAPREDUCE_240659755_1
2014-05-05 11:58:15,001 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 34 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 19 SyncTimes(ms): 963 
2014-05-05 11:58:15,093 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job.jar. BP-625903679-10.0.0.195-1399288960104 blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 11:58:15,775 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:58:15,780 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:58:15,782 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:58:15,784 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 11:58:15,789 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job.jar is closed by DFSClient_NONMAPREDUCE_-1254116964_1
2014-05-05 11:58:15,794 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job.jar
2014-05-05 11:58:15,843 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job.split
2014-05-05 11:58:15,856 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job.split. BP-625903679-10.0.0.195-1399288960104 blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 11:58:15,888 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 11:58:15,889 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 11:58:15,890 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 11:58:15,892 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 11:58:15,898 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 11:58:15,899 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 11:58:15,900 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 11:58:15,902 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 11:58:15,930 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job.split is closed by DFSClient_NONMAPREDUCE_-1254116964_1
2014-05-05 11:58:15,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job.splitmetainfo. BP-625903679-10.0.0.195-1399288960104 blk_1073741873_1049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 11:58:15,953 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741873_1049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:58:15,955 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741873_1049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:58:15,956 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741873_1049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:58:15,958 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741873_1049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 11:58:15,960 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1254116964_1
2014-05-05 11:58:16,244 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741874_1050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 11:58:16,263 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741874_1050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:58:16,264 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741874_1050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:58:16,265 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741874_1050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:58:16,267 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741874_1050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 11:58:16,270 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job.xml is closed by DFSClient_NONMAPREDUCE_-1254116964_1
2014-05-05 11:58:17,833 INFO BlockStateChange: BLOCK* ask 10.0.0.193:50010 to replicate blk_1073741871_1047 to datanode(s) 10.0.0.198:50010 10.0.0.200:50010 10.0.0.199:50010 10.0.0.196:50010
2014-05-05 11:58:19,846 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741871_1047 size 39460542
2014-05-05 11:58:19,847 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741871_1047 size 39460542
2014-05-05 11:58:19,848 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741871_1047 size 39460542
2014-05-05 11:58:19,850 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741871_1047 size 39460542
2014-05-05 11:58:22,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job_1399290791848_0002_1_conf.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741875_1051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 11:58:22,702 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741875_1051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:58:22,704 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741875_1051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:58:22,704 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741875_1051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:58:22,705 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741875_1051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 11:58:22,713 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job_1399290791848_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-206103672_1
2014-05-05 12:05:01,644 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job_1399290791848_0002_1.jhist. BP-625903679-10.0.0.195-1399288960104 blk_1073741876_1052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 12:05:01,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job_1399290791848_0002_1.jhist for DFSClient_NONMAPREDUCE_-206103672_1
2014-05-05 12:05:01,660 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 71 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 38 SyncTimes(ms): 1034 
2014-05-05 12:05:01,694 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741876_1052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:05:01,695 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741876_1052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:05:01,698 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741876_1052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:05:01,699 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741876_1052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:05:01,709 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0002/job_1399290791848_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_-206103672_1
2014-05-05 12:05:01,715 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0002.summary_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741877_1053{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 12:05:01,733 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741877_1053{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:05:01,735 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741877_1053{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:05:01,735 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741877_1053{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:05:01,738 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741877_1053 size 343
2014-05-05 12:05:01,760 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_-206103672_1
2014-05-05 12:05:01,871 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0002-1399291096473-ubuntu-hints%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399291501642-0-0-KILLED-default.jhist_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741878_1054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 12:05:01,885 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741878_1054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:05:01,886 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741878_1054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:05:01,887 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741878_1054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:05:01,889 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741878_1054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:05:01,892 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0002-1399291096473-ubuntu-hints%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399291501642-0-0-KILLED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-206103672_1
2014-05-05 12:05:01,907 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0002_conf.xml_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741879_1055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 12:05:01,926 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741879_1055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:05:01,927 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741879_1055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:05:01,928 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741879_1055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:05:01,929 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741879_1055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:05:01,953 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-206103672_1
2014-05-05 12:05:03,033 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741871_1047 10.0.0.195:50010 10.0.0.197:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.196:50010 10.0.0.199:50010 10.0.0.198:50010 
2014-05-05 12:05:03,034 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741872_1048 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.198:50010 10.0.0.197:50010 10.0.0.196:50010 10.0.0.199:50010 10.0.0.193:50010 
2014-05-05 12:05:03,034 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741873_1049 10.0.0.195:50010 10.0.0.196:50010 10.0.0.198:50010 10.0.0.200:50010 
2014-05-05 12:05:03,034 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741874_1050 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.196:50010 
2014-05-05 12:05:03,034 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741876_1052 10.0.0.198:50010 10.0.0.195:50010 10.0.0.199:50010 10.0.0.197:50010 
2014-05-05 12:05:03,034 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741875_1051 10.0.0.198:50010 10.0.0.194:50010 10.0.0.196:50010 10.0.0.195:50010 
2014-05-05 12:05:05,910 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741872_1048, blk_1073741874_1050, blk_1073741875_1051, blk_1073741871_1047]
2014-05-05 12:05:05,910 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.198:50010 to delete [blk_1073741872_1048, blk_1073741873_1049, blk_1073741875_1051, blk_1073741876_1052, blk_1073741871_1047]
2014-05-05 12:05:05,910 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741872_1048, blk_1073741873_1049, blk_1073741874_1050, blk_1073741875_1051, blk_1073741876_1052, blk_1073741871_1047]
2014-05-05 12:05:08,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.199:50010 to delete [blk_1073741872_1048, blk_1073741876_1052, blk_1073741871_1047]
2014-05-05 12:05:08,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741872_1048, blk_1073741873_1049, blk_1073741874_1050, blk_1073741871_1047]
2014-05-05 12:05:08,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741872_1048, blk_1073741871_1047]
2014-05-05 12:05:11,912 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.197:50010 to delete [blk_1073741872_1048, blk_1073741876_1052, blk_1073741871_1047]
2014-05-05 12:05:11,912 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.196:50010 to delete [blk_1073741872_1048, blk_1073741873_1049, blk_1073741874_1050, blk_1073741875_1051, blk_1073741871_1047]
2014-05-05 12:05:15,196 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 12:05:15,198 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 12:05:15,199 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 12:05:15,200 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 12:05:15,264 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0001/job_1399290791848_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_240659755_1
2014-05-05 12:05:15,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0001.summary_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741880_1056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:05:15,287 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741880_1056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:15,289 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741880_1056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:15,289 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741880_1056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:15,291 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741880_1056 size 370
2014-05-05 12:05:15,313 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_240659755_1
2014-05-05 12:05:15,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0001-1399290848693-ubuntu-hints%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399291515170-4-6-KILLED-default.jhist_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741881_1057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 12:05:15,425 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741881_1057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:05:15,426 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741881_1057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:05:15,427 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741881_1057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:05:15,428 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741881_1057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:05:15,431 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0001-1399290848693-ubuntu-hints%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399291515170-4-6-KILLED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_240659755_1
2014-05-05 12:05:15,472 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0001_conf.xml_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741882_1058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:05:15,489 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741882_1058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:15,490 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741882_1058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:15,491 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741882_1058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:15,492 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741882_1058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:15,522 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_240659755_1
2014-05-05 12:05:16,578 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741865_1041 10.0.0.195:50010 10.0.0.194:50010 10.0.0.197:50010 10.0.0.200:50010 10.0.0.198:50010 10.0.0.199:50010 10.0.0.193:50010 10.0.0.196:50010 
2014-05-05 12:05:16,578 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741866_1042 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.197:50010 10.0.0.196:50010 10.0.0.198:50010 10.0.0.199:50010 10.0.0.194:50010 
2014-05-05 12:05:16,578 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741867_1043 10.0.0.195:50010 10.0.0.200:50010 10.0.0.197:50010 10.0.0.193:50010 
2014-05-05 12:05:16,578 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741868_1044 10.0.0.198:50010 10.0.0.195:50010 10.0.0.200:50010 10.0.0.196:50010 
2014-05-05 12:05:16,578 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741870_1046 10.0.0.199:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.195:50010 
2014-05-05 12:05:16,578 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741869_1045 10.0.0.199:50010 10.0.0.193:50010 10.0.0.196:50010 10.0.0.195:50010 
2014-05-05 12:05:17,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741865_1041, blk_1073741866_1042, blk_1073741867_1043, blk_1073741869_1045, blk_1073741870_1046]
2014-05-05 12:05:17,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.198:50010 to delete [blk_1073741865_1041, blk_1073741866_1042, blk_1073741868_1044]
2014-05-05 12:05:17,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.197:50010 to delete [blk_1073741865_1041, blk_1073741866_1042, blk_1073741867_1043]
2014-05-05 12:05:20,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741865_1041, blk_1073741866_1042, blk_1073741870_1046]
2014-05-05 12:05:20,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741865_1041, blk_1073741866_1042, blk_1073741867_1043, blk_1073741868_1044]
2014-05-05 12:05:20,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.196:50010 to delete [blk_1073741865_1041, blk_1073741866_1042, blk_1073741868_1044, blk_1073741869_1045]
2014-05-05 12:05:23,915 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741865_1041, blk_1073741866_1042, blk_1073741867_1043, blk_1073741868_1044, blk_1073741869_1045, blk_1073741870_1046]
2014-05-05 12:05:23,915 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.199:50010 to delete [blk_1073741865_1041, blk_1073741866_1042, blk_1073741869_1045, blk_1073741870_1046]
2014-05-05 12:05:33,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job.jar. BP-625903679-10.0.0.195-1399288960104 blk_1073741883_1059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]}
2014-05-05 12:05:34,729 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741883_1059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:05:34,730 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741883_1059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:05:34,734 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741883_1059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:05:34,734 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741883_1059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:05:34,744 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job.jar is closed by DFSClient_NONMAPREDUCE_297779505_1
2014-05-05 12:05:34,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job.jar
2014-05-05 12:05:34,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job.split
2014-05-05 12:05:34,901 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job.split. BP-625903679-10.0.0.195-1399288960104 blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:05:34,930 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:34,930 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:34,932 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:34,933 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:34,935 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:34,937 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:34,938 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:34,939 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:34,953 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job.split is closed by DFSClient_NONMAPREDUCE_297779505_1
2014-05-05 12:05:34,964 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job.splitmetainfo. BP-625903679-10.0.0.195-1399288960104 blk_1073741885_1061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:05:34,981 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741885_1061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:34,981 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741885_1061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:34,983 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741885_1061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:34,983 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741885_1061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:35,008 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_297779505_1
2014-05-05 12:05:35,290 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741886_1062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:05:35,315 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741886_1062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:35,316 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741886_1062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:35,317 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741886_1062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:35,319 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741886_1062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:05:35,323 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job.xml is closed by DFSClient_NONMAPREDUCE_297779505_1
2014-05-05 12:05:35,917 INFO BlockStateChange: BLOCK* ask 10.0.0.199:50010 to replicate blk_1073741883_1059 to datanode(s) 10.0.0.197:50010 10.0.0.193:50010 10.0.0.198:50010 10.0.0.200:50010
2014-05-05 12:05:37,597 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741883_1059 size 39460542
2014-05-05 12:05:37,598 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741883_1059 size 39460542
2014-05-05 12:05:37,600 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741883_1059 size 39460542
2014-05-05 12:05:37,602 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741883_1059 size 39460542
2014-05-05 12:05:42,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job_1399290791848_0003_1_conf.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741887_1063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 12:05:43,112 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741887_1063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:05:43,113 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741887_1063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:05:43,115 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741887_1063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:05:43,116 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741887_1063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:05:43,126 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job_1399290791848_0003_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-636862941_1
2014-05-05 12:05:57,153 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job_1399290791848_0003_1.jhist. BP-625903679-10.0.0.195-1399288960104 blk_1073741888_1064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:05:57,185 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job_1399290791848_0003_1.jhist for DFSClient_NONMAPREDUCE_-636862941_1
2014-05-05 12:08:21,780 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 156 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 0 Number of syncs: 87 SyncTimes(ms): 2500 
2014-05-05 12:08:21,871 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job.jar. BP-625903679-10.0.0.195-1399288960104 blk_1073741889_1065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 12:08:22,638 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741889_1065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:08:22,640 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741889_1065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:08:22,640 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741889_1065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:08:22,642 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741889_1065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:08:22,667 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job.jar is closed by DFSClient_NONMAPREDUCE_296773824_1
2014-05-05 12:08:22,672 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job.jar
2014-05-05 12:08:22,733 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job.split
2014-05-05 12:08:22,743 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job.split. BP-625903679-10.0.0.195-1399288960104 blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 12:08:22,780 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:08:22,781 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:08:22,782 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:08:22,784 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:08:22,785 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:08:22,786 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:08:22,788 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:08:22,789 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:08:22,794 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job.split is closed by DFSClient_NONMAPREDUCE_296773824_1
2014-05-05 12:08:22,806 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job.splitmetainfo. BP-625903679-10.0.0.195-1399288960104 blk_1073741891_1067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 12:08:22,838 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741891_1067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:08:22,838 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741891_1067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:08:22,840 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741891_1067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:08:22,842 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741891_1067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:08:22,845 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_296773824_1
2014-05-05 12:08:23,180 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741892_1068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 12:08:23,202 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741892_1068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:08:23,203 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741892_1068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:08:23,204 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741892_1068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:08:23,207 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741892_1068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:08:23,223 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job.xml is closed by DFSClient_NONMAPREDUCE_296773824_1
2014-05-05 12:08:23,942 INFO BlockStateChange: BLOCK* ask 10.0.0.200:50010 to replicate blk_1073741889_1065 to datanode(s) 10.0.0.198:50010 10.0.0.196:50010 10.0.0.199:50010 10.0.0.193:50010
2014-05-05 12:08:25,596 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741889_1065 size 39460542
2014-05-05 12:08:25,597 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741889_1065 size 39460542
2014-05-05 12:08:25,676 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741889_1065 size 39460542
2014-05-05 12:08:25,677 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741889_1065 size 39460542
2014-05-05 12:08:29,168 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job_1399290791848_0004_1_conf.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741893_1069{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:08:29,288 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741893_1069{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:08:29,290 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741893_1069{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:08:29,292 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741893_1069{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:08:29,292 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741893_1069{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:08:29,319 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job_1399290791848_0004_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1413705679_1
2014-05-05 12:08:41,845 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job_1399290791848_0004_1.jhist. BP-625903679-10.0.0.195-1399288960104 blk_1073741894_1070{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 12:08:41,863 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job_1399290791848_0004_1.jhist for DFSClient_NONMAPREDUCE_-1413705679_1
2014-05-05 12:09:28,354 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-704496375-10.0.0.200-50010-1399289005076, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 25, processing time: 1 msecs
2014-05-05 12:11:07,562 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 194 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 107 SyncTimes(ms): 2665 
2014-05-05 12:11:07,718 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job.jar. BP-625903679-10.0.0.195-1399288960104 blk_1073741895_1071{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:11:08,908 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741895_1071{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:11:08,909 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741895_1071{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:11:08,910 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741895_1071{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:11:08,911 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741895_1071{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:11:08,919 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job.jar is closed by DFSClient_NONMAPREDUCE_1776905291_1
2014-05-05 12:11:08,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job.jar
2014-05-05 12:11:08,969 INFO BlockStateChange: BLOCK* ask 10.0.0.196:50010 to replicate blk_1073741895_1071 to datanode(s) 10.0.0.199:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010
2014-05-05 12:11:09,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job.split
2014-05-05 12:11:09,106 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job.split. BP-625903679-10.0.0.195-1399288960104 blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:11:09,146 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:09,147 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:09,148 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:09,149 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:09,151 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:09,152 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:09,153 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:09,155 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:09,159 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job.split is closed by DFSClient_NONMAPREDUCE_1776905291_1
2014-05-05 12:11:09,177 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job.splitmetainfo. BP-625903679-10.0.0.195-1399288960104 blk_1073741897_1073{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 12:11:09,209 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741897_1073{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:11:09,210 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741897_1073{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:11:09,211 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741897_1073{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:11:09,212 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741897_1073{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:11:09,216 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1776905291_1
2014-05-05 12:11:09,691 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741898_1074{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 12:11:09,712 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741898_1074{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:09,714 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741898_1074{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:09,715 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741898_1074{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:09,717 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741898_1074{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:09,729 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job.xml is closed by DFSClient_NONMAPREDUCE_1776905291_1
2014-05-05 12:11:10,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741895_1071 size 39460542
2014-05-05 12:11:10,752 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741895_1071 size 39460542
2014-05-05 12:11:10,753 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741895_1071 size 39460542
2014-05-05 12:11:10,753 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741895_1071 size 39460542
2014-05-05 12:11:10,756 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job.jar. BP-625903679-10.0.0.195-1399288960104 blk_1073741899_1075{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 12:11:11,541 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741899_1075{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:11,543 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741899_1075{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:11,544 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741899_1075{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:11,545 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741899_1075{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:11,550 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job.jar is closed by DFSClient_NONMAPREDUCE_1126183084_1
2014-05-05 12:11:11,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job.jar
2014-05-05 12:11:11,970 INFO BlockStateChange: BLOCK* ask 10.0.0.199:50010 to replicate blk_1073741899_1075 to datanode(s) 10.0.0.194:50010 10.0.0.197:50010 10.0.0.198:50010 10.0.0.200:50010
2014-05-05 12:11:12,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job.split
2014-05-05 12:11:12,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job.split. BP-625903679-10.0.0.195-1399288960104 blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 12:11:12,293 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:12,294 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:12,295 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:12,296 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:12,298 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:12,299 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:12,301 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:12,302 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:13,543 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741899_1075 size 39460542
2014-05-05 12:11:13,547 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741899_1075 size 39460542
2014-05-05 12:11:13,548 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741899_1075 size 39460542
2014-05-05 12:11:13,549 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741899_1075 size 39460542
2014-05-05 12:11:14,028 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job.split is closed by DFSClient_NONMAPREDUCE_1126183084_1
2014-05-05 12:11:14,915 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job.splitmetainfo. BP-625903679-10.0.0.195-1399288960104 blk_1073741901_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]}
2014-05-05 12:11:14,931 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741901_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:11:14,932 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741901_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:11:14,933 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741901_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:11:14,934 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741901_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:11:15,277 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1126183084_1
2014-05-05 12:11:15,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741902_1078{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:11:15,579 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741902_1078{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:15,581 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741902_1078{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:15,582 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741902_1078{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:15,583 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741902_1078{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:15,586 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job.xml is closed by DFSClient_NONMAPREDUCE_1126183084_1
2014-05-05 12:11:16,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job_1399290791848_0005_1_conf.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741903_1079{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 12:11:16,791 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741903_1079{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:16,792 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741903_1079{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:16,793 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741903_1079{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:16,794 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741903_1079{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:11:16,799 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job_1399290791848_0005_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1916016408_1
2014-05-05 12:11:22,666 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job_1399290791848_0006_1_conf.xml. BP-625903679-10.0.0.195-1399288960104 blk_1073741904_1080{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:11:22,907 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741904_1080{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:22,909 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741904_1080{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:22,910 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741904_1080{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:22,912 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741904_1080{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:11:24,536 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job_1399290791848_0006_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1883524856_1
2014-05-05 12:11:34,529 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job_1399290791848_0005_1.jhist. BP-625903679-10.0.0.195-1399288960104 blk_1073741905_1081{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 12:11:34,550 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0005/job_1399290791848_0005_1.jhist for DFSClient_NONMAPREDUCE_1916016408_1
2014-05-05 12:11:40,553 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job_1399290791848_0006_1.jhist. BP-625903679-10.0.0.195-1399288960104 blk_1073741906_1082{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:11:40,572 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0006/job_1399290791848_0006_1.jhist for DFSClient_NONMAPREDUCE_-1883524856_1
2014-05-05 12:12:18,326 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741888_1064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:12:18,328 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741888_1064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:12:18,329 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741888_1064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:12:18,330 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741888_1064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:12:18,332 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 270 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 0 Number of syncs: 147 SyncTimes(ms): 9449 
2014-05-05 12:12:18,920 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741894_1070{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:12:19,036 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741894_1070{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:12:19,036 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741894_1070{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:12:19,036 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741894_1070{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:12:19,928 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0003/job_1399290791848_0003_1.jhist is closed by DFSClient_NONMAPREDUCE_-636862941_1
2014-05-05 12:12:20,958 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399290791848_0004/job_1399290791848_0004_1.jhist is closed by DFSClient_NONMAPREDUCE_-1413705679_1
2014-05-05 12:12:22,687 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0003.summary_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741907_1083{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:12:22,702 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0004.summary_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741908_1084{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:12:22,703 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741907_1083{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:12:22,710 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741907_1083 size 369
2014-05-05 12:12:22,710 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741907_1083 size 369
2014-05-05 12:12:22,711 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741907_1083 size 369
2014-05-05 12:12:22,711 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0003.summary_tmp is closed by DFSClient_NONMAPREDUCE_-636862941_1
2014-05-05 12:12:22,719 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741908_1084{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:12:22,720 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741908_1084{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:12:22,723 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741908_1084{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:12:22,725 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741908_1084 size 371
2014-05-05 12:12:24,650 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0004.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1413705679_1
2014-05-05 12:12:24,667 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0003-1399291535514-ubuntu-hints%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399291938298-4-0-KILLED-default.jhist_tmp. BP-625903679-10.0.0.195-1399288960104 blk_1073741909_1085{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:12:24,683 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741909_1085{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:12:24,687 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741909_1085{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:12:24,688 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741909_1085{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:12:24,689 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741909_1085{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:12:29,748 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399290791848_0003-1399291535514-ubuntu-hints%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399291938298-4-0-KILLED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-636862941_1
2014-05-05 12:12:30,050 WARN org.apache.hadoop.ipc.Server: IPC Server Responder, call org.apache.hadoop.hdfs.protocol.ClientProtocol.complete from 10.0.0.200:50768 Call#461 Retry#0: output error
2014-05-05 12:12:30,051 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 54310 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:265)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:474)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:2577)
	at org.apache.hadoop.ipc.Server.access$2200(Server.java:122)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1011)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1076)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2104)
2014-05-05 12:12:35,167 WARN org.apache.hadoop.ipc.Server: IPC Server Responder, call org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 10.0.0.197:54629 Call#290 Retry#0: output error
2014-05-05 12:12:35,167 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 54310 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:265)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:474)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:2577)
	at org.apache.hadoop.ipc.Server.access$2200(Server.java:122)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1011)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1076)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2104)
2014-05-05 12:12:45,811 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 12:12:45,813 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 12:53:59,523 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-patch/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-05-04T05:58Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 12:53:59,532 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 12:53:59,827 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 12:53:59,936 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 12:53:59,936 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 12:54:00,232 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-05-05 12:54:00,536 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 12:54:00,641 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 12:54:00,644 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 12:54:00,645 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 12:54:00,645 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 12:54:00,664 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 12:54:00,685 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 12:54:00,685 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 12:54:01,101 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 12:54:01,102 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 12:54:01,135 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 12:54:01,135 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 12:54:01,212 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 12:54:01,212 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 12:54:01,215 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 12:54:01,217 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 12:54:01,217 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 12:54:01,218 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2014-05-05 12:54:01,218 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2014-05-05 12:54:01,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 12:54:01,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 12:54:01,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 12:54:01,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 12:54:01,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 12:54:01,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 12:54:01,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 12:54:01,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 12:54:01,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 12:54:01,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 12:54:01,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 12:54:01,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 12:54:01,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 12:54:01,287 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 12:54:01,287 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 12:54:01,287 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2014-05-05 12:54:01,287 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2014-05-05 12:54:01,288 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 12:54:01,290 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 12:54:01,290 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 12:54:01,290 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 12:54:01,292 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 12:54:01,292 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 12:54:01,294 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 12:54:01,294 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 12:54:01,294 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2014-05-05 12:54:01,294 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2014-05-05 12:54:01,310 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 23464@ip-10-0-0-195
2014-05-05 12:54:01,398 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 12:54:01,552 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000003 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000003-0000000000000000230
2014-05-05 12:54:01,571 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000002 using no compression
2014-05-05 12:54:01,571 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 1
2014-05-05 12:54:01,576 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2014-05-05 12:54:01,576 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000002 of size 198 bytes loaded in 0 seconds.
2014-05-05 12:54:01,576 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000002
2014-05-05 12:54:01,577 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@39b0af03 expecting start txid #3
2014-05-05 12:54:01,577 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000003-0000000000000000230
2014-05-05 12:54:01,579 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000000003-0000000000000000230' to transaction ID 3
2014-05-05 12:54:01,654 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000003-0000000000000000230 of size 1048576 edits # 228 loaded in 0 seconds
2014-05-05 12:54:01,656 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 231
2014-05-05 12:54:01,767 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 12:54:01,767 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 471 msecs
2014-05-05 12:54:01,989 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 12:54:02,012 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 12:54:02,059 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 12:54:02,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 12:54:02,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 12:54:02,073 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 15.
Safe mode will be turned off automatically
2014-05-05 12:54:02,100 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 12:54:02,101 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 12:54:02,104 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 12:54:02,104 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 12:54:06,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-88490224-10.0.0.195-50010-1399294446420, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0) storage DS-88490224-10.0.0.195-50010-1399294446420
2014-05-05 12:54:06,656 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 12:54:06,695 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-1144061666-10.0.0.200-50010-1399294446477, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0) storage DS-1144061666-10.0.0.200-50010-1399294446477
2014-05-05 12:54:06,695 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 12:54:06,742 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1910598227-10.0.0.193-50010-1399294446492, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0) storage DS-1910598227-10.0.0.193-50010-1399294446492
2014-05-05 12:54:06,745 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 12:54:06,784 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:54:06,784 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-88490224-10.0.0.195-50010-1399294446420, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0), blocks: 0, processing time: 1 msecs
2014-05-05 12:54:06,793 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:54:06,793 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-1144061666-10.0.0.200-50010-1399294446477, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:54:06,797 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-355898560-10.0.0.194-50010-1399294446462, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0) storage DS-355898560-10.0.0.194-50010-1399294446462
2014-05-05 12:54:06,801 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 12:54:06,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:54:06,857 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-355898560-10.0.0.194-50010-1399294446462, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:54:06,883 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:54:06,883 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1910598227-10.0.0.193-50010-1399294446492, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:55:12,261 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 15.
Safe mode will be turned off automatically
2014-05-05 12:55:12,261 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 54310, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 10.0.0.195:39939 Call#1 Retry#0: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 15.
Safe mode will be turned off automatically
2014-05-05 12:55:42,110 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume 'null' is 0, which is below the configured reserved amount 104857600
2014-05-05 12:55:42,110 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2014-05-05 12:55:42,110 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 41 
2014-05-05 12:55:42,110 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:55:47,110 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume 'null' is 0, which is below the configured reserved amount 104857600
2014-05-05 12:55:47,110 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2014-05-05 12:55:47,110 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:55:52,111 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume 'null' is 0, which is below the configured reserved amount 104857600
2014-05-05 12:55:52,111 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2014-05-05 12:55:52,111 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:55:57,111 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume 'null' is 0, which is below the configured reserved amount 104857600
2014-05-05 12:55:57,111 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2014-05-05 12:55:57,111 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:56:02,111 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume 'null' is 0, which is below the configured reserved amount 104857600
2014-05-05 12:56:02,111 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2014-05-05 12:56:02,112 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:56:07,112 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume 'null' is 0, which is below the configured reserved amount 104857600
2014-05-05 12:56:07,112 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2014-05-05 12:56:07,112 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:56:12,112 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume 'null' is 0, which is below the configured reserved amount 104857600
2014-05-05 12:56:12,112 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2014-05-05 12:56:12,114 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:56:12,275 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:56:12,275 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 54310, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 10.0.0.195:40021 Call#3 Retry#0: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:56:17,114 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume 'null' is 0, which is below the configured reserved amount 104857600
2014-05-05 12:56:17,114 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2014-05-05 12:56:17,114 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:56:22,114 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume 'null' is 0, which is below the configured reserved amount 104857600
2014-05-05 12:56:22,114 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2014-05-05 12:56:22,117 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:56:27,117 WARN org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker: Space available on volume 'null' is 0, which is below the configured reserved amount 104857600
2014-05-05 12:56:27,117 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNode low on available disk space. Already in safe mode.
2014-05-05 12:56:27,117 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is ONResources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:57:12,286 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:57:12,286 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 54310, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 10.0.0.195:40086 Call#5 Retry#0: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2014-05-05 12:57:51,019 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 12:57:51,022 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 18:45:57,997 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-patch/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-05-04T05:58Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 18:45:58,032 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 18:45:58,411 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 18:45:58,526 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 18:45:58,526 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 18:45:58,838 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-05-05 18:45:59,168 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 18:45:59,316 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 18:45:59,319 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 18:45:59,319 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 18:45:59,319 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 18:45:59,357 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 18:45:59,398 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 18:45:59,398 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 18:45:59,735 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 18:45:59,735 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 18:45:59,799 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 18:45:59,799 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 18:45:59,881 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 18:45:59,881 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 18:45:59,883 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 18:45:59,886 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 18:45:59,886 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 18:45:59,886 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2014-05-05 18:45:59,886 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2014-05-05 18:45:59,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 18:45:59,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 18:45:59,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 18:45:59,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 18:45:59,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 18:45:59,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 18:45:59,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 18:45:59,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 18:45:59,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 18:45:59,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 18:45:59,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 18:45:59,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 18:45:59,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 18:45:59,958 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 18:45:59,958 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 18:45:59,958 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2014-05-05 18:45:59,959 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2014-05-05 18:45:59,979 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 18:45:59,984 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 18:45:59,984 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 18:45:59,984 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 18:45:59,985 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 18:45:59,985 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 18:45:59,987 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 18:45:59,987 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 18:45:59,987 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2014-05-05 18:45:59,987 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2014-05-05 18:46:00,002 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 7628@ip-10-0-0-195
2014-05-05 18:46:00,120 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 18:46:00,261 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000001420 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000001420-0000000000000001420
2014-05-05 18:46:00,295 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000001419 using no compression
2014-05-05 18:46:00,295 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 64
2014-05-05 18:46:00,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2014-05-05 18:46:00,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000001419 of size 9263 bytes loaded in 0 seconds.
2014-05-05 18:46:00,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1419 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000001419
2014-05-05 18:46:00,335 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@47217048 expecting start txid #1420
2014-05-05 18:46:00,336 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000001420-0000000000000001420
2014-05-05 18:46:00,338 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000001420-0000000000000001420' to transaction ID 1420
2014-05-05 18:46:00,342 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000001420-0000000000000001420 of size 1048576 edits # 1 loaded in 0 seconds
2014-05-05 18:46:00,351 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1421
2014-05-05 18:46:00,487 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 18:46:00,487 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 498 msecs
2014-05-05 18:46:00,844 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 18:46:00,868 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 18:46:00,923 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 18:46:00,935 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 18:46:00,935 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 18:46:00,936 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 48 blocks to reach the threshold 0.9990 of total blocks 48.
Safe mode will be turned off automatically
2014-05-05 18:46:00,968 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 18:46:00,969 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 18:46:00,971 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 18:46:00,971 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 18:46:05,146 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1314301678-10.0.0.193-50010-1399315564915, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-1314301678-10.0.0.193-50010-1399315564915
2014-05-05 18:46:05,154 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 18:46:05,154 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-1475469283-10.0.0.194-50010-1399315564921, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-1475469283-10.0.0.194-50010-1399315564921
2014-05-05 18:46:05,155 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 18:46:05,194 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-407144037-10.0.0.195-50010-1399315564936, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-407144037-10.0.0.195-50010-1399315564936
2014-05-05 18:46:05,194 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 18:46:05,299 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-900950489-10.0.0.200-50010-1399315564992, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-900950489-10.0.0.200-50010-1399315564992
2014-05-05 18:46:05,299 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 18:46:05,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:46:05,343 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1314301678-10.0.0.193-50010-1399315564915, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 1 msecs
2014-05-05 18:46:05,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:46:05,350 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-1475469283-10.0.0.194-50010-1399315564921, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 18:46:05,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:46:05,390 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-407144037-10.0.0.195-50010-1399315564936, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 1 msecs
2014-05-05 18:46:05,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:46:05,423 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-900950489-10.0.0.200-50010-1399315564992, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 18:46:06,237 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.37, storageID=DS-98104379-10.0.0.37-50010-1399315566121, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-98104379-10.0.0.37-50010-1399315566121
2014-05-05 18:46:06,237 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.37:50010
2014-05-05 18:46:06,371 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.37:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:46:06,371 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.37, storageID=DS-98104379-10.0.0.37-50010-1399315566121, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 18:46:06,661 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.38, storageID=DS-1894644392-10.0.0.38-50010-1399315566531, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-1894644392-10.0.0.38-50010-1399315566531
2014-05-05 18:46:06,662 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.38:50010
2014-05-05 18:46:06,769 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.38:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:46:06,769 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.38, storageID=DS-1894644392-10.0.0.38-50010-1399315566531, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 18:46:06,868 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.36, storageID=DS-1519824005-10.0.0.36-50010-1399315566740, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-1519824005-10.0.0.36-50010-1399315566740
2014-05-05 18:46:06,868 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.36:50010
2014-05-05 18:46:06,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.36:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:46:06,990 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.36, storageID=DS-1519824005-10.0.0.36-50010-1399315566740, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 18:46:10,128 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.35, storageID=DS-1751081309-10.0.0.35-50010-1399315569968, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-1751081309-10.0.0.35-50010-1399315569968
2014-05-05 18:46:10,129 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.35:50010
2014-05-05 18:46:10,260 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.35:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:46:10,260 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.35, storageID=DS-1751081309-10.0.0.35-50010-1399315569968, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 18:46:41,505 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 18:46:41,508 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 18:47:34,345 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-patch/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-05-04T05:58Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 18:47:34,353 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 18:47:34,651 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 18:47:34,761 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 18:47:34,761 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 18:47:35,093 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-05-05 18:47:35,411 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 18:47:35,480 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 18:47:35,483 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 18:47:35,483 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 18:47:35,483 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 18:47:35,522 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 18:47:35,570 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 18:47:35,570 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 18:47:35,966 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 18:47:35,966 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 18:47:36,013 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 18:47:36,013 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 18:47:36,080 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 18:47:36,080 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 18:47:36,083 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 18:47:36,085 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 18:47:36,085 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 18:47:36,086 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2014-05-05 18:47:36,086 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2014-05-05 18:47:36,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 18:47:36,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 18:47:36,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 18:47:36,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 18:47:36,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 18:47:36,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 18:47:36,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 18:47:36,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 18:47:36,098 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 18:47:36,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 18:47:36,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 18:47:36,099 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 18:47:36,100 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 18:47:36,156 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 18:47:36,156 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 18:47:36,156 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2014-05-05 18:47:36,156 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2014-05-05 18:47:36,157 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 18:47:36,160 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 18:47:36,160 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 18:47:36,160 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 18:47:36,161 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 18:47:36,161 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 18:47:36,163 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 18:47:36,164 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 18:47:36,164 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2014-05-05 18:47:36,164 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2014-05-05 18:47:36,180 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 9721@ip-10-0-0-195
2014-05-05 18:47:36,272 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 18:47:36,276 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2014-05-05 18:47:36,290 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000 using no compression
2014-05-05 18:47:36,290 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 1
2014-05-05 18:47:36,297 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2014-05-05 18:47:36,297 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000 of size 198 bytes loaded in 0 seconds.
2014-05-05 18:47:36,297 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000
2014-05-05 18:47:36,305 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2014-05-05 18:47:36,459 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 18:47:36,459 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 294 msecs
2014-05-05 18:47:36,716 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 18:47:36,734 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 18:47:36,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 18:47:36,798 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 18:47:36,798 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 18:47:36,798 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2014-05-05 18:47:36,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2014-05-05 18:47:36,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2014-05-05 18:47:36,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2014-05-05 18:47:36,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2014-05-05 18:47:36,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2014-05-05 18:47:36,806 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2014-05-05 18:47:36,806 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2014-05-05 18:47:36,806 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2014-05-05 18:47:36,806 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2014-05-05 18:47:36,837 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 18:47:36,838 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 18:47:36,841 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 18:47:36,841 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 18:47:41,512 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1214695977-10.0.0.193-50010-1399315661285
2014-05-05 18:47:41,515 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 18:47:41,549 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1668817953-10.0.0.195-50010-1399315661283
2014-05-05 18:47:41,549 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 18:47:41,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.35, storageID=DS-283411255-10.0.0.35-50010-1399315661421, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-283411255-10.0.0.35-50010-1399315661421
2014-05-05 18:47:41,602 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.35:50010
2014-05-05 18:47:41,614 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-258220490-10.0.0.194-50010-1399315661308, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-258220490-10.0.0.194-50010-1399315661308
2014-05-05 18:47:41,620 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 18:47:41,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.37, storageID=DS-1870530911-10.0.0.37-50010-1399315661396, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1870530911-10.0.0.37-50010-1399315661396
2014-05-05 18:47:41,652 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.37:50010
2014-05-05 18:47:41,671 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.38, storageID=DS-1670817916-10.0.0.38-50010-1399315661447, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1670817916-10.0.0.38-50010-1399315661447
2014-05-05 18:47:41,700 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.38:50010
2014-05-05 18:47:41,708 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:47:41,708 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-258220490-10.0.0.194-50010-1399315661308, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 0, processing time: 2 msecs
2014-05-05 18:47:41,712 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.35:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:47:41,712 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.35, storageID=DS-283411255-10.0.0.35-50010-1399315661421, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 0, processing time: 1 msecs
2014-05-05 18:47:41,712 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.36, storageID=DS-1358703672-10.0.0.36-50010-1399315661430, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1358703672-10.0.0.36-50010-1399315661430
2014-05-05 18:47:41,716 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.36:50010
2014-05-05 18:47:41,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:47:41,726 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 18:47:41,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-13906350-10.0.0.200-50010-1399315661489, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-13906350-10.0.0.200-50010-1399315661489
2014-05-05 18:47:41,727 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 18:47:41,744 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:47:41,744 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 18:47:41,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.38:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:47:41,763 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.38, storageID=DS-1670817916-10.0.0.38-50010-1399315661447, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 18:47:41,774 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.37:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:47:41,774 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.37, storageID=DS-1870530911-10.0.0.37-50010-1399315661396, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 18:47:41,778 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.36:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:47:41,778 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.36, storageID=DS-1358703672-10.0.0.36-50010-1399315661430, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 18:47:41,795 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 18:47:41,795 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-13906350-10.0.0.200-50010-1399315661489, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 18:48:47,040 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 18:48:47,040 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 18:48:47,040 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2014-05-05 18:48:47,040 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 66 
2014-05-05 18:48:47,041 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 67 
2014-05-05 18:48:47,042 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000002
2014-05-05 18:48:47,042 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2014-05-05 18:48:47,891 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=2&storageInfo=-47:793646566:0:CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d
2014-05-05 18:48:48,091 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.20s at 0.00 KB/s
2014-05-05 18:48:48,091 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 198 bytes.
2014-05-05 18:48:48,101 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2014-05-05 18:49:56,007 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 97 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 58 
2014-05-05 18:51:11,371 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 99 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 75 
2014-05-05 18:51:11,478 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /5m/data._COPYING_. BP-114085979-10.0.0.195-1399315646731 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]}
2014-05-05 18:51:12,736 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:51:12,742 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:51:12,745 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:51:12,749 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:51:12,760 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /5m/data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1824125050_1
2014-05-05 18:52:04,847 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job.jar. BP-114085979-10.0.0.195-1399315646731 blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]}
2014-05-05 18:52:05,596 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 18:52:05,599 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 18:52:05,601 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 18:52:05,602 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 18:52:05,608 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-1625398783_1
2014-05-05 18:52:05,616 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job.jar
2014-05-05 18:52:05,675 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job.split
2014-05-05 18:52:05,705 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job.split. BP-114085979-10.0.0.195-1399315646731 blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 18:52:06,206 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:52:06,207 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:52:06,209 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:52:06,212 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:52:06,215 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:52:06,216 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:52:06,218 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:52:06,221 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:52:06,224 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job.split is closed by DFSClient_NONMAPREDUCE_-1625398783_1
2014-05-05 18:52:06,233 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job.splitmetainfo. BP-114085979-10.0.0.195-1399315646731 blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]}
2014-05-05 18:52:06,260 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:52:06,261 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:52:06,262 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:52:06,264 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:52:06,266 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1625398783_1
2014-05-05 18:52:06,686 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job.xml. BP-114085979-10.0.0.195-1399315646731 blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 18:52:06,723 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:52:06,725 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:52:06,726 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:52:06,728 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:52:06,731 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-1625398783_1
2014-05-05 18:52:07,313 INFO BlockStateChange: BLOCK* ask 10.0.0.35:50010 to replicate blk_1073741826_1002 to datanode(s) 10.0.0.37:50010 10.0.0.38:50010 10.0.0.36:50010 10.0.0.200:50010
2014-05-05 18:52:08,985 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741826_1002 size 39460542
2014-05-05 18:52:08,986 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741826_1002 size 39460542
2014-05-05 18:52:08,987 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741826_1002 size 39460542
2014-05-05 18:52:08,987 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741826_1002 size 39460542
2014-05-05 18:52:13,437 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 43 Total time for transactions(ms): 102 Number of transactions batched in Syncs: 0 Number of syncs: 23 SyncTimes(ms): 118 
2014-05-05 18:52:16,342 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job_1399315672071_0001_1_conf.xml. BP-114085979-10.0.0.195-1399315646731 blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 18:52:16,457 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:52:16,458 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:52:16,459 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:52:16,461 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:52:16,467 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job_1399315672071_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1654185630_1
2014-05-05 18:53:14,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job_1399315672071_0001_1.jhist. BP-114085979-10.0.0.195-1399315646731 blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]}
2014-05-05 18:53:14,803 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0001/job_1399315672071_0001_1.jhist for DFSClient_NONMAPREDUCE_-1654185630_1
2014-05-05 18:53:14,803 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 56 Total time for transactions(ms): 102 Number of transactions batched in Syncs: 0 Number of syncs: 30 SyncTimes(ms): 138 
2014-05-05 18:56:07,995 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 57 Total time for transactions(ms): 102 Number of transactions batched in Syncs: 0 Number of syncs: 31 SyncTimes(ms): 139 
2014-05-05 18:56:08,077 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job.jar. BP-114085979-10.0.0.195-1399315646731 blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]}
2014-05-05 18:56:08,713 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:56:08,713 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:56:08,715 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:56:08,717 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:56:08,724 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job.jar is closed by DFSClient_NONMAPREDUCE_1643195107_1
2014-05-05 18:56:08,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job.jar
2014-05-05 18:56:08,786 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job.split
2014-05-05 18:56:08,797 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job.split. BP-114085979-10.0.0.195-1399315646731 blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 18:56:08,826 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:56:08,826 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:56:08,829 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:56:08,830 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:56:08,832 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:56:08,833 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:56:08,834 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:56:08,836 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:56:08,838 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job.split is closed by DFSClient_NONMAPREDUCE_1643195107_1
2014-05-05 18:56:08,847 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job.splitmetainfo. BP-114085979-10.0.0.195-1399315646731 blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]}
2014-05-05 18:56:08,860 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:56:08,861 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:56:08,862 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:56:08,863 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:56:08,866 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1643195107_1
2014-05-05 18:56:09,155 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job.xml. BP-114085979-10.0.0.195-1399315646731 blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 18:56:09,184 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:56:09,184 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:56:09,185 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:56:09,186 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:56:09,207 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job.xml is closed by DFSClient_NONMAPREDUCE_1643195107_1
2014-05-05 18:56:10,346 INFO BlockStateChange: BLOCK* ask 10.0.0.37:50010 to replicate blk_1073741832_1008 to datanode(s) 10.0.0.36:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.38:50010
2014-05-05 18:56:11,945 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741832_1008 size 39460542
2014-05-05 18:56:11,945 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741832_1008 size 39460542
2014-05-05 18:56:11,946 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741832_1008 size 39460542
2014-05-05 18:56:11,946 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741832_1008 size 39460542
2014-05-05 18:56:15,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job_1399315672071_0002_1_conf.xml. BP-114085979-10.0.0.195-1399315646731 blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]}
2014-05-05 18:56:15,426 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 18:56:15,427 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 18:56:15,429 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 18:56:15,430 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 18:56:15,436 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job_1399315672071_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1255578956_1
2014-05-05 18:57:16,672 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job_1399315672071_0002_1.jhist. BP-114085979-10.0.0.195-1399315646731 blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 18:57:16,704 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399315672071_0002/job_1399315672071_0002_1.jhist for DFSClient_NONMAPREDUCE_-1255578956_1
2014-05-05 18:57:16,704 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 94 Total time for transactions(ms): 104 Number of transactions batched in Syncs: 0 Number of syncs: 50 SyncTimes(ms): 181 
2014-05-05 19:03:34,175 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 19:03:34,176 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 19:07:09,879 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-patch/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-05-04T05:58Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 19:07:09,887 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 19:07:10,189 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 19:07:10,300 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 19:07:10,300 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 19:07:10,600 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-05-05 19:07:10,917 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 19:07:11,011 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 19:07:11,014 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 19:07:11,014 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 19:07:11,014 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 19:07:11,034 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 19:07:11,057 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 19:07:11,057 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 19:07:11,503 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 19:07:11,503 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 19:07:11,538 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 19:07:11,538 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 19:07:11,614 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 19:07:11,614 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 19:07:11,617 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 19:07:11,619 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 19:07:11,619 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:07:11,623 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 8.9 GB
2014-05-05 19:07:11,623 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2014-05-05 19:07:11,766 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 19:07:11,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 19:07:11,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 19:07:11,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 19:07:11,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 19:07:11,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 19:07:11,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 19:07:11,767 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 19:07:11,774 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 19:07:11,774 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 19:07:11,774 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 19:07:11,774 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 19:07:11,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 19:07:11,833 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 19:07:11,833 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:07:11,833 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 8.9 GB
2014-05-05 19:07:11,833 INFO org.apache.hadoop.util.GSet: capacity      = 2^24 = 16777216 entries
2014-05-05 19:07:11,902 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 19:07:11,906 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 19:07:11,906 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 19:07:11,906 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 19:07:11,907 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 19:07:11,907 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 19:07:11,909 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 19:07:11,909 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:07:11,910 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 8.9 GB
2014-05-05 19:07:11,910 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2014-05-05 19:07:11,925 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 14056@ip-10-0-0-195
2014-05-05 19:07:12,009 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 19:07:12,094 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000097 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000097-0000000000000000097
2014-05-05 19:07:12,115 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000002 using no compression
2014-05-05 19:07:12,115 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 1
2014-05-05 19:07:12,121 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2014-05-05 19:07:12,122 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000002 of size 198 bytes loaded in 0 seconds.
2014-05-05 19:07:12,122 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 2 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000002
2014-05-05 19:07:12,122 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6ea4ca0 expecting start txid #3
2014-05-05 19:07:12,122 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000003-0000000000000000096
2014-05-05 19:07:12,125 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000000003-0000000000000000096' to transaction ID 3
2014-05-05 19:07:12,186 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000003-0000000000000000096 of size 1048576 edits # 94 loaded in 0 seconds
2014-05-05 19:07:12,186 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4c9fec expecting start txid #97
2014-05-05 19:07:12,186 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000097-0000000000000000097
2014-05-05 19:07:12,186 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000000097-0000000000000000097' to transaction ID 3
2014-05-05 19:07:12,190 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000097-0000000000000000097 of size 1048576 edits # 1 loaded in 0 seconds
2014-05-05 19:07:12,192 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 98
2014-05-05 19:07:12,319 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 19:07:12,319 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 408 msecs
2014-05-05 19:07:12,780 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 19:07:12,798 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 19:07:12,851 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 19:07:12,864 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 2
2014-05-05 19:07:12,864 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 2
2014-05-05 19:07:12,864 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 11 blocks to reach the threshold 0.9990 of total blocks 11.
Safe mode will be turned off automatically
2014-05-05 19:07:12,894 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 19:07:12,895 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 19:07:12,898 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 19:07:12,898 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 19:07:17,081 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.38, storageID=DS-1670817916-10.0.0.38-50010-1399315661447, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1670817916-10.0.0.38-50010-1399315661447
2014-05-05 19:07:17,084 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.38:50010
2014-05-05 19:07:17,084 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-258220490-10.0.0.194-50010-1399315661308, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-258220490-10.0.0.194-50010-1399315661308
2014-05-05 19:07:17,085 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 19:07:17,086 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1214695977-10.0.0.193-50010-1399315661285
2014-05-05 19:07:17,086 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 19:07:17,114 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.36, storageID=DS-1358703672-10.0.0.36-50010-1399315661430, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1358703672-10.0.0.36-50010-1399315661430
2014-05-05 19:07:17,115 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.36:50010
2014-05-05 19:07:17,124 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.35, storageID=DS-283411255-10.0.0.35-50010-1399315661421, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-283411255-10.0.0.35-50010-1399315661421
2014-05-05 19:07:17,125 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.35:50010
2014-05-05 19:07:17,140 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1668817953-10.0.0.195-50010-1399315661283
2014-05-05 19:07:17,144 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 19:07:17,177 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-13906350-10.0.0.200-50010-1399315661489, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-13906350-10.0.0.200-50010-1399315661489
2014-05-05 19:07:17,178 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 19:07:17,217 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.37, storageID=DS-1870530911-10.0.0.37-50010-1399315661396, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1870530911-10.0.0.37-50010-1399315661396
2014-05-05 19:07:17,217 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.37:50010
2014-05-05 19:07:17,266 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.38:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:07:17,266 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.38, storageID=DS-1670817916-10.0.0.38-50010-1399315661447, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 6, processing time: 3 msecs
2014-05-05 19:07:17,269 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:07:17,269 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-258220490-10.0.0.194-50010-1399315661308, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 9, processing time: 1 msecs
2014-05-05 19:07:17,272 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:07:17,272 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 7, processing time: 0 msecs
2014-05-05 19:07:17,289 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 10 has reached the threshold 0.9990 of total blocks 11. The number of live datanodes 8 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2014-05-05 19:07:17,289 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2014-05-05 19:07:17,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 13
2014-05-05 19:07:17,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2014-05-05 19:07:17,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 11
2014-05-05 19:07:17,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2014-05-05 19:07:17,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 2
2014-05-05 19:07:17,378 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 89 msec
2014-05-05 19:07:17,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:07:17,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.36:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:07:17,379 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.36, storageID=DS-1358703672-10.0.0.36-50010-1399315661430, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 11, processing time: 1 msecs
2014-05-05 19:07:17,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.35:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:07:17,380 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.35, storageID=DS-283411255-10.0.0.35-50010-1399315661421, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 6, processing time: 1 msecs
2014-05-05 19:07:17,380 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-13906350-10.0.0.200-50010-1399315661489, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 7, processing time: 105 msecs
2014-05-05 19:07:17,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:07:17,381 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 13, processing time: 1 msecs
2014-05-05 19:07:17,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.37:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:07:17,381 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.37, storageID=DS-1870530911-10.0.0.37-50010-1399315661396, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 9, processing time: 0 msecs
2014-05-05 19:07:37,383 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 11 has reached the threshold 0.9990 of total blocks 11. The number of live datanodes 8 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2014-05-05 19:07:42,221 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 11 has reached the threshold 0.9990 of total blocks 11. The number of live datanodes 8 has reached the minimum number 0. Safe mode will be turned off automatically in 5 seconds.
2014-05-05 19:07:42,221 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 54310, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 10.0.0.195:42121 Call#3 Retry#0: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 11 has reached the threshold 0.9990 of total blocks 11. The number of live datanodes 8 has reached the minimum number 0. Safe mode will be turned off automatically in 5 seconds.
2014-05-05 19:07:47,385 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2014-05-05 19:07:47,385 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2014-05-05 19:07:47,385 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 8 datanodes
2014-05-05 19:07:47,385 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 4 blocks
2014-05-05 19:08:06,033 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job.jar. BP-114085979-10.0.0.195-1399315646731 blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]}
2014-05-05 19:08:07,029 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 19:08:07,030 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 19:08:07,032 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 19:08:07,034 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 19:08:07,047 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-269868318_1
2014-05-05 19:08:07,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job.jar
2014-05-05 19:08:07,139 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job.split
2014-05-05 19:08:07,149 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job.split. BP-114085979-10.0.0.195-1399315646731 blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 19:08:07,516 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 19:08:07,517 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 19:08:07,518 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 19:08:07,520 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 19:08:07,521 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 19:08:07,523 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 19:08:07,529 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 19:08:07,531 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 19:08:07,536 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job.split is closed by DFSClient_NONMAPREDUCE_-269868318_1
2014-05-05 19:08:07,545 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job.splitmetainfo. BP-114085979-10.0.0.195-1399315646731 blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 19:08:07,562 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:08:07,564 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:08:07,565 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:08:07,567 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:08:07,569 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-269868318_1
2014-05-05 19:08:07,849 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job.xml. BP-114085979-10.0.0.195-1399315646731 blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 19:08:07,876 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:08:07,877 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:08:07,879 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:08:07,880 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:08:07,884 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-269868318_1
2014-05-05 19:08:09,880 INFO BlockStateChange: BLOCK* ask 10.0.0.36:50010 to replicate blk_1073741838_1014 to datanode(s) 10.0.0.37:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.38:50010
2014-05-05 19:08:11,534 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741838_1014 size 39460542
2014-05-05 19:08:11,535 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741838_1014 size 39460542
2014-05-05 19:08:11,535 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741838_1014 size 39460542
2014-05-05 19:08:11,535 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741838_1014 size 39460542
2014-05-05 19:08:16,129 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 30 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 18 SyncTimes(ms): 81 
2014-05-05 19:08:16,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job_1399316666607_0001_1_conf.xml. BP-114085979-10.0.0.195-1399315646731 blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 19:08:16,688 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:08:16,690 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:08:16,691 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:08:16,692 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:08:16,698 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job_1399316666607_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1958157866_1
2014-05-05 19:08:42,232 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 19:08:42,232 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 19:08:42,233 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 98
2014-05-05 19:08:42,234 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 36 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 22 SyncTimes(ms): 85 
2014-05-05 19:08:42,235 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000098 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000098-0000000000000000133
2014-05-05 19:08:42,235 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 134
2014-05-05 19:08:42,955 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=133&storageInfo=-47:793646566:0:CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d
2014-05-05 19:08:43,179 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.22s at 17.86 KB/s
2014-05-05 19:08:43,180 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000133 size 4162 bytes.
2014-05-05 19:08:43,190 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2014-05-05 19:08:43,190 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2014-05-05 19:09:14,137 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job_1399316666607_0001_1.jhist. BP-114085979-10.0.0.195-1399315646731 blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]}
2014-05-05 19:09:14,157 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399316666607_0001/job_1399316666607_0001_1.jhist for DFSClient_NONMAPREDUCE_1958157866_1
2014-05-05 19:11:33,555 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 19:11:33,557 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 19:12:07,898 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-patch/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-05-04T05:58Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 19:12:07,907 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 19:12:08,205 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 19:12:08,314 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 19:12:08,314 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 19:12:08,591 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-05-05 19:12:08,918 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 19:12:08,988 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 19:12:08,992 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 19:12:08,992 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 19:12:08,992 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 19:12:09,034 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 19:12:09,067 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 19:12:09,067 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 19:12:09,580 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 19:12:09,581 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 19:12:09,627 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 19:12:09,627 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 19:12:09,713 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 19:12:09,713 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 19:12:09,717 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 19:12:09,720 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 19:12:09,720 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:12:09,725 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 8.9 GB
2014-05-05 19:12:09,725 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2014-05-05 19:12:09,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 19:12:09,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 19:12:09,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 19:12:09,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 19:12:09,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 19:12:09,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 19:12:09,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 19:12:09,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 19:12:09,900 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 19:12:09,900 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 19:12:09,900 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 19:12:09,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 19:12:09,902 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 19:12:09,958 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 19:12:09,958 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:12:09,958 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 8.9 GB
2014-05-05 19:12:09,958 INFO org.apache.hadoop.util.GSet: capacity      = 2^24 = 16777216 entries
2014-05-05 19:12:10,030 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 19:12:10,033 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 19:12:10,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 19:12:10,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 19:12:10,035 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 19:12:10,035 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 19:12:10,037 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 19:12:10,037 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:12:10,037 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 8.9 GB
2014-05-05 19:12:10,037 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2014-05-05 19:12:10,055 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 15821@ip-10-0-0-195
2014-05-05 19:12:10,129 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 19:12:10,214 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000134 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000134-0000000000000000138
2014-05-05 19:12:10,233 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000133 using no compression
2014-05-05 19:12:10,233 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 32
2014-05-05 19:12:10,245 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 3
2014-05-05 19:12:10,253 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000133 of size 4162 bytes loaded in 0 seconds.
2014-05-05 19:12:10,253 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 133 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000133
2014-05-05 19:12:10,254 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7891135e expecting start txid #134
2014-05-05 19:12:10,254 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000134-0000000000000000138
2014-05-05 19:12:10,256 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000000134-0000000000000000138' to transaction ID 134
2014-05-05 19:12:10,263 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000134-0000000000000000138 of size 1048576 edits # 5 loaded in 0 seconds
2014-05-05 19:12:10,266 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 139
2014-05-05 19:12:10,459 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 19:12:10,459 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 420 msecs
2014-05-05 19:12:10,925 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 19:12:10,944 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 19:12:10,996 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 19:12:11,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 3
2014-05-05 19:12:11,009 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 3
2014-05-05 19:12:11,009 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 16 blocks to reach the threshold 0.9990 of total blocks 16.
Safe mode will be turned off automatically
2014-05-05 19:12:11,037 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 19:12:11,037 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 19:12:11,041 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 19:12:11,041 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 19:12:15,196 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.38, storageID=DS-1670817916-10.0.0.38-50010-1399315661447, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1670817916-10.0.0.38-50010-1399315661447
2014-05-05 19:12:15,199 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.38:50010
2014-05-05 19:12:15,204 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.35, storageID=DS-283411255-10.0.0.35-50010-1399315661421, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-283411255-10.0.0.35-50010-1399315661421
2014-05-05 19:12:15,212 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.35:50010
2014-05-05 19:12:15,213 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-13906350-10.0.0.200-50010-1399315661489, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-13906350-10.0.0.200-50010-1399315661489
2014-05-05 19:12:15,216 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 19:12:15,237 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1668817953-10.0.0.195-50010-1399315661283
2014-05-05 19:12:15,237 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 19:12:15,293 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.37, storageID=DS-1870530911-10.0.0.37-50010-1399315661396, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1870530911-10.0.0.37-50010-1399315661396
2014-05-05 19:12:15,293 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.37:50010
2014-05-05 19:12:15,300 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1214695977-10.0.0.193-50010-1399315661285
2014-05-05 19:12:15,305 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 19:12:15,310 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.36, storageID=DS-1358703672-10.0.0.36-50010-1399315661430, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1358703672-10.0.0.36-50010-1399315661430
2014-05-05 19:12:15,312 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.36:50010
2014-05-05 19:12:15,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:12:15,381 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-13906350-10.0.0.200-50010-1399315661489, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 12, processing time: 9 msecs
2014-05-05 19:12:15,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.38:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:12:15,391 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.38, storageID=DS-1670817916-10.0.0.38-50010-1399315661447, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 11, processing time: 0 msecs
2014-05-05 19:12:15,393 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 15 has reached the threshold 0.9990 of total blocks 16. The number of live datanodes 7 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2014-05-05 19:12:15,394 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2014-05-05 19:12:15,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 19
2014-05-05 19:12:15,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2014-05-05 19:12:15,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 16
2014-05-05 19:12:15,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2014-05-05 19:12:15,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 3
2014-05-05 19:12:15,474 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 80 msec
2014-05-05 19:12:15,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.35:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:12:15,474 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.35, storageID=DS-283411255-10.0.0.35-50010-1399315661421, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 9, processing time: 83 msecs
2014-05-05 19:12:15,475 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-258220490-10.0.0.194-50010-1399315661308, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-258220490-10.0.0.194-50010-1399315661308
2014-05-05 19:12:15,475 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 19:12:15,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:12:15,476 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 17, processing time: 1 msecs
2014-05-05 19:12:15,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.36:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:12:15,477 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.36, storageID=DS-1358703672-10.0.0.36-50010-1399315661430, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 15, processing time: 1 msecs
2014-05-05 19:12:15,478 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.37:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:12:15,478 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.37, storageID=DS-1870530911-10.0.0.37-50010-1399315661396, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 14, processing time: 1 msecs
2014-05-05 19:12:15,479 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:12:15,479 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 10, processing time: 1 msecs
2014-05-05 19:12:15,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:12:15,531 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-258220490-10.0.0.194-50010-1399315661308, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 12, processing time: 1 msecs
2014-05-05 19:12:35,480 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 16 has reached the threshold 0.9990 of total blocks 16. The number of live datanodes 8 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2014-05-05 19:12:45,481 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2014-05-05 19:12:45,481 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2014-05-05 19:12:45,481 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 8 datanodes
2014-05-05 19:12:45,481 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 6 blocks
2014-05-05 19:13:21,290 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 19:13:21,290 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 19:13:21,290 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 139
2014-05-05 19:13:21,290 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 118 
2014-05-05 19:13:21,292 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 120 
2014-05-05 19:13:21,293 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000139 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000139-0000000000000000140
2014-05-05 19:13:21,293 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 141
2014-05-05 19:13:22,657 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=140&storageInfo=-47:793646566:0:CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d
2014-05-05 19:13:22,919 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.26s at 15.27 KB/s
2014-05-05 19:13:22,919 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000140 size 4210 bytes.
2014-05-05 19:13:22,929 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 133
2014-05-05 19:13:22,930 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2014-05-05 19:13:28,452 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job.jar. BP-114085979-10.0.0.195-1399315646731 blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 19:13:29,420 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:13:29,421 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:13:29,423 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:13:29,425 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:13:29,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job.jar is closed by DFSClient_NONMAPREDUCE_1549217734_1
2014-05-05 19:13:29,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job.jar
2014-05-05 19:13:29,582 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job.split
2014-05-05 19:13:29,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job.split. BP-114085979-10.0.0.195-1399315646731 blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]}
2014-05-05 19:13:29,963 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 19:13:29,965 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 19:13:29,970 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 19:13:29,971 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 19:13:29,972 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 19:13:29,978 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 19:13:29,980 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 19:13:29,982 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 19:13:29,985 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job.split is closed by DFSClient_NONMAPREDUCE_1549217734_1
2014-05-05 19:13:29,995 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job.splitmetainfo. BP-114085979-10.0.0.195-1399315646731 blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 19:13:30,012 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:13:30,013 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:13:30,014 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:13:30,015 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:13:30,034 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1549217734_1
2014-05-05 19:13:30,386 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job.xml. BP-114085979-10.0.0.195-1399315646731 blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]}
2014-05-05 19:13:30,427 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 19:13:30,428 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 19:13:30,429 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 19:13:30,431 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 19:13:30,448 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job.xml is closed by DFSClient_NONMAPREDUCE_1549217734_1
2014-05-05 19:13:32,040 INFO BlockStateChange: BLOCK* ask 10.0.0.200:50010 to replicate blk_1073741844_1020 to datanode(s) 10.0.0.193:50010 10.0.0.38:50010 10.0.0.35:50010 10.0.0.37:50010
2014-05-05 19:13:33,528 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741844_1020 size 39460542
2014-05-05 19:13:33,530 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741844_1020 size 39460542
2014-05-05 19:13:33,531 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741844_1020 size 39460542
2014-05-05 19:13:33,531 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741844_1020 size 39460542
2014-05-05 19:13:38,492 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job_1399317145678_0001_1_conf.xml. BP-114085979-10.0.0.195-1399315646731 blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 19:13:38,705 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:13:38,706 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:13:38,707 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:13:38,710 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:13:38,716 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job_1399317145678_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1795941614_1
2014-05-05 19:14:37,472 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job_1399317145678_0001_1.jhist. BP-114085979-10.0.0.195-1399315646731 blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]}
2014-05-05 19:14:37,495 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399317145678_0001/job_1399317145678_0001_1.jhist for DFSClient_NONMAPREDUCE_-1795941614_1
2014-05-05 19:14:37,495 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 39 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 21 SyncTimes(ms): 439 
2014-05-05 19:25:18,101 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 19:25:18,103 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 19:25:52,345 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-patch/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-05-04T05:58Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 19:25:52,356 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 19:25:52,660 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 19:25:52,771 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 19:25:52,771 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 19:25:53,077 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-05-05 19:25:53,331 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 19:25:53,400 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 19:25:53,403 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 19:25:53,403 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 19:25:53,403 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 19:25:53,423 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 19:25:53,452 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 19:25:53,452 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 19:25:53,977 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 19:25:53,978 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 19:25:54,023 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 19:25:54,023 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 19:25:54,090 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 19:25:54,090 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 19:25:54,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 19:25:54,095 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 19:25:54,095 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:25:54,099 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 8.9 GB
2014-05-05 19:25:54,099 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2014-05-05 19:25:54,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 19:25:54,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 19:25:54,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 19:25:54,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 19:25:54,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 19:25:54,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 19:25:54,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 19:25:54,250 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 19:25:54,258 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 19:25:54,258 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 19:25:54,258 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 19:25:54,258 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 19:25:54,260 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 19:25:54,316 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 19:25:54,316 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:25:54,316 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 8.9 GB
2014-05-05 19:25:54,316 INFO org.apache.hadoop.util.GSet: capacity      = 2^24 = 16777216 entries
2014-05-05 19:25:54,389 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 19:25:54,392 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 19:25:54,392 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 19:25:54,392 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 19:25:54,393 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 19:25:54,394 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 19:25:54,396 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 19:25:54,396 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:25:54,396 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 8.9 GB
2014-05-05 19:25:54,396 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2014-05-05 19:25:54,412 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 18281@ip-10-0-0-195
2014-05-05 19:25:54,490 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 19:25:54,586 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000141 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000141-0000000000000000179
2014-05-05 19:25:54,605 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000140 using no compression
2014-05-05 19:25:54,605 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 32
2014-05-05 19:25:54,619 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 3
2014-05-05 19:25:54,626 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000140 of size 4210 bytes loaded in 0 seconds.
2014-05-05 19:25:54,626 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 140 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000140
2014-05-05 19:25:54,626 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7891135e expecting start txid #141
2014-05-05 19:25:54,626 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000141-0000000000000000179
2014-05-05 19:25:54,629 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000000141-0000000000000000179' to transaction ID 141
2014-05-05 19:25:54,647 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000141-0000000000000000179 of size 1048576 edits # 39 loaded in 0 seconds
2014-05-05 19:25:54,653 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 180
2014-05-05 19:25:54,860 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 19:25:54,860 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 463 msecs
2014-05-05 19:25:55,327 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 19:25:55,346 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 19:25:55,400 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 19:25:55,413 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 4
2014-05-05 19:25:55,413 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 4
2014-05-05 19:25:55,414 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 21 blocks to reach the threshold 0.9990 of total blocks 21.
Safe mode will be turned off automatically
2014-05-05 19:25:55,442 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 19:25:55,442 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 19:25:55,445 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 19:25:55,446 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 19:25:59,607 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1214695977-10.0.0.193-50010-1399315661285
2014-05-05 19:25:59,619 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 19:25:59,620 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.35, storageID=DS-283411255-10.0.0.35-50010-1399315661421, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-283411255-10.0.0.35-50010-1399315661421
2014-05-05 19:25:59,620 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.35:50010
2014-05-05 19:25:59,648 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-258220490-10.0.0.194-50010-1399315661308, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-258220490-10.0.0.194-50010-1399315661308
2014-05-05 19:25:59,649 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 19:25:59,692 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.38, storageID=DS-1670817916-10.0.0.38-50010-1399315661447, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1670817916-10.0.0.38-50010-1399315661447
2014-05-05 19:25:59,700 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.38:50010
2014-05-05 19:25:59,714 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-13906350-10.0.0.200-50010-1399315661489, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-13906350-10.0.0.200-50010-1399315661489
2014-05-05 19:25:59,714 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 19:25:59,732 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.37, storageID=DS-1870530911-10.0.0.37-50010-1399315661396, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1870530911-10.0.0.37-50010-1399315661396
2014-05-05 19:25:59,732 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.37:50010
2014-05-05 19:25:59,748 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.36, storageID=DS-1358703672-10.0.0.36-50010-1399315661430, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1358703672-10.0.0.36-50010-1399315661430
2014-05-05 19:25:59,749 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.36:50010
2014-05-05 19:25:59,789 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.35:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:25:59,789 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.35, storageID=DS-283411255-10.0.0.35-50010-1399315661421, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 14, processing time: 5 msecs
2014-05-05 19:25:59,792 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:25:59,792 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-13906350-10.0.0.200-50010-1399315661489, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 16, processing time: 1 msecs
2014-05-05 19:25:59,793 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:25:59,793 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-258220490-10.0.0.194-50010-1399315661308, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 16, processing time: 1 msecs
2014-05-05 19:25:59,804 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 20 has reached the threshold 0.9990 of total blocks 21. The number of live datanodes 7 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2014-05-05 19:25:59,804 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2014-05-05 19:25:59,927 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 25
2014-05-05 19:25:59,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2014-05-05 19:25:59,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 21
2014-05-05 19:25:59,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2014-05-05 19:25:59,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 4
2014-05-05 19:25:59,928 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 124 msec
2014-05-05 19:25:59,929 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:25:59,929 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1668817953-10.0.0.195-50010-1399315661283
2014-05-05 19:25:59,931 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 14, processing time: 136 msecs
2014-05-05 19:25:59,932 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 19:25:59,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.37:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:25:59,933 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.37, storageID=DS-1870530911-10.0.0.37-50010-1399315661396, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 16, processing time: 1 msecs
2014-05-05 19:25:59,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.38:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:25:59,934 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.38, storageID=DS-1670817916-10.0.0.38-50010-1399315661447, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 15, processing time: 1 msecs
2014-05-05 19:25:59,936 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.36:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:25:59,936 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.36, storageID=DS-1358703672-10.0.0.36-50010-1399315661430, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 18, processing time: 2 msecs
2014-05-05 19:26:00,026 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:26:00,026 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 23, processing time: 1 msecs
2014-05-05 19:26:19,937 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 21 has reached the threshold 0.9990 of total blocks 21. The number of live datanodes 8 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2014-05-05 19:26:29,938 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2014-05-05 19:26:29,938 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2014-05-05 19:26:29,938 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 8 datanodes
2014-05-05 19:26:29,939 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 8 blocks
2014-05-05 19:26:59,434 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 19:26:59,437 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 19:27:33,814 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-patch/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-05-04T05:58Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 19:27:33,826 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 19:27:34,125 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 19:27:34,236 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 19:27:34,236 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 19:27:34,533 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-05-05 19:27:34,839 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 19:27:34,906 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 19:27:34,909 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 19:27:34,909 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 19:27:34,909 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 19:27:34,928 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 19:27:34,959 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 19:27:34,959 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 19:27:35,446 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 19:27:35,446 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 19:27:35,491 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 19:27:35,491 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 19:27:35,556 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 19:27:35,556 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 19:27:35,559 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 19:27:35,561 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 19:27:35,561 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:27:35,564 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 8.9 GB
2014-05-05 19:27:35,565 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2014-05-05 19:27:35,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 19:27:35,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 19:27:35,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 19:27:35,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 19:27:35,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 19:27:35,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 19:27:35,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 19:27:35,700 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 19:27:35,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 19:27:35,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 19:27:35,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 19:27:35,708 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 19:27:35,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 19:27:35,765 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 19:27:35,765 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:27:35,765 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 8.9 GB
2014-05-05 19:27:35,765 INFO org.apache.hadoop.util.GSet: capacity      = 2^24 = 16777216 entries
2014-05-05 19:27:35,830 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 19:27:35,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 19:27:35,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 19:27:35,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 19:27:35,835 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 19:27:35,835 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 19:27:35,837 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 19:27:35,837 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:27:35,837 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 8.9 GB
2014-05-05 19:27:35,837 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2014-05-05 19:27:35,893 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 20342@ip-10-0-0-195
2014-05-05 19:27:35,967 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 19:27:36,051 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000180 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000180-0000000000000000180
2014-05-05 19:27:36,074 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000140 using no compression
2014-05-05 19:27:36,074 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 32
2014-05-05 19:27:36,091 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 3
2014-05-05 19:27:36,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000140 of size 4210 bytes loaded in 0 seconds.
2014-05-05 19:27:36,106 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 140 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000140
2014-05-05 19:27:36,107 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4c9fec expecting start txid #141
2014-05-05 19:27:36,107 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000141-0000000000000000179
2014-05-05 19:27:36,109 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000000141-0000000000000000179' to transaction ID 141
2014-05-05 19:27:36,129 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000141-0000000000000000179 of size 1048576 edits # 39 loaded in 0 seconds
2014-05-05 19:27:36,129 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@26973f1b expecting start txid #180
2014-05-05 19:27:36,129 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000180-0000000000000000180
2014-05-05 19:27:36,129 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000000180-0000000000000000180' to transaction ID 141
2014-05-05 19:27:36,133 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000180-0000000000000000180 of size 1048576 edits # 1 loaded in 0 seconds
2014-05-05 19:27:36,137 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 181
2014-05-05 19:27:36,244 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 19:27:36,244 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 405 msecs
2014-05-05 19:27:36,735 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 19:27:36,752 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 19:27:36,804 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 19:27:36,817 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 4
2014-05-05 19:27:36,818 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 4
2014-05-05 19:27:36,818 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 21 blocks to reach the threshold 0.9990 of total blocks 21.
Safe mode will be turned off automatically
2014-05-05 19:27:36,849 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 19:27:36,851 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 19:27:36,853 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 19:27:36,853 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 19:27:40,935 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1214695977-10.0.0.193-50010-1399315661285
2014-05-05 19:27:40,938 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 19:27:40,947 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-258220490-10.0.0.194-50010-1399315661308, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-258220490-10.0.0.194-50010-1399315661308
2014-05-05 19:27:40,952 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 19:27:40,952 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.36, storageID=DS-1358703672-10.0.0.36-50010-1399315661430, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1358703672-10.0.0.36-50010-1399315661430
2014-05-05 19:27:40,953 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.36:50010
2014-05-05 19:27:40,962 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.35, storageID=DS-283411255-10.0.0.35-50010-1399315661421, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-283411255-10.0.0.35-50010-1399315661421
2014-05-05 19:27:40,970 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.35:50010
2014-05-05 19:27:41,005 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.38, storageID=DS-1670817916-10.0.0.38-50010-1399315661447, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1670817916-10.0.0.38-50010-1399315661447
2014-05-05 19:27:41,007 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.38:50010
2014-05-05 19:27:41,047 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-13906350-10.0.0.200-50010-1399315661489, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-13906350-10.0.0.200-50010-1399315661489
2014-05-05 19:27:41,053 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 19:27:41,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:27:41,134 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 14, processing time: 9 msecs
2014-05-05 19:27:41,135 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:27:41,135 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-258220490-10.0.0.194-50010-1399315661308, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 16, processing time: 1 msecs
2014-05-05 19:27:41,137 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 20 has reached the threshold 0.9990 of total blocks 21. The number of live datanodes 6 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2014-05-05 19:27:41,137 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2014-05-05 19:27:41,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 25
2014-05-05 19:27:41,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2014-05-05 19:27:41,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 21
2014-05-05 19:27:41,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2014-05-05 19:27:41,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 4
2014-05-05 19:27:41,232 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 95 msec
2014-05-05 19:27:41,232 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:27:41,232 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-13906350-10.0.0.200-50010-1399315661489, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 16, processing time: 97 msecs
2014-05-05 19:27:41,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.36:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:27:41,234 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.36, storageID=DS-1358703672-10.0.0.36-50010-1399315661430, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 18, processing time: 2 msecs
2014-05-05 19:27:41,234 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1668817953-10.0.0.195-50010-1399315661283
2014-05-05 19:27:41,234 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 19:27:41,236 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.35:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:27:41,236 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.35, storageID=DS-283411255-10.0.0.35-50010-1399315661421, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 14, processing time: 1 msecs
2014-05-05 19:27:41,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.38:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:27:41,240 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.38, storageID=DS-1670817916-10.0.0.38-50010-1399315661447, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 15, processing time: 4 msecs
2014-05-05 19:27:41,241 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.37, storageID=DS-1870530911-10.0.0.37-50010-1399315661396, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1870530911-10.0.0.37-50010-1399315661396
2014-05-05 19:27:41,248 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.37:50010
2014-05-05 19:27:41,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.37:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:27:41,299 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.37, storageID=DS-1870530911-10.0.0.37-50010-1399315661396, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 16, processing time: 1 msecs
2014-05-05 19:27:41,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:27:41,329 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 23, processing time: 1 msecs
2014-05-05 19:28:01,239 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 21 has reached the threshold 0.9990 of total blocks 21. The number of live datanodes 8 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2014-05-05 19:28:11,241 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2014-05-05 19:28:11,241 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2014-05-05 19:28:11,241 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 8 datanodes
2014-05-05 19:28:11,241 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 8 blocks
2014-05-05 19:28:17,109 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job.jar. BP-114085979-10.0.0.195-1399315646731 blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]}
2014-05-05 19:28:18,094 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:28:18,096 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:28:18,098 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:28:18,099 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:28:18,108 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-1317710094_1
2014-05-05 19:28:18,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job.jar
2014-05-05 19:28:18,179 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job.split
2014-05-05 19:28:18,189 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job.split. BP-114085979-10.0.0.195-1399315646731 blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]}
2014-05-05 19:28:18,551 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:28:18,553 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:28:18,558 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:28:18,560 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:28:18,565 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:28:18,570 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:28:18,572 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:28:18,573 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:28:18,577 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job.split is closed by DFSClient_NONMAPREDUCE_-1317710094_1
2014-05-05 19:28:18,586 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job.splitmetainfo. BP-114085979-10.0.0.195-1399315646731 blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]}
2014-05-05 19:28:18,600 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 19:28:18,601 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 19:28:18,602 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 19:28:18,608 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 19:28:18,610 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1317710094_1
2014-05-05 19:28:18,848 INFO BlockStateChange: BLOCK* ask 10.0.0.37:50010 to replicate blk_1073741850_1026 to datanode(s) 10.0.0.36:50010 10.0.0.38:50010 10.0.0.194:50010 10.0.0.200:50010
2014-05-05 19:28:18,911 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job.xml. BP-114085979-10.0.0.195-1399315646731 blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 19:28:18,946 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:28:18,947 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:28:18,948 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:28:18,950 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 19:28:18,956 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-1317710094_1
2014-05-05 19:28:20,549 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741850_1026 size 39460542
2014-05-05 19:28:20,551 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741850_1026 size 39460542
2014-05-05 19:28:20,552 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741850_1026 size 39460542
2014-05-05 19:28:20,553 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741850_1026 size 39460542
2014-05-05 19:28:27,098 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job_1399318071615_0001_1_conf.xml. BP-114085979-10.0.0.195-1399315646731 blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 19:28:27,222 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:28:27,223 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:28:27,224 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:28:27,226 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 19:28:27,233 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job_1399318071615_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_596198447_1
2014-05-05 19:28:47,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 19:28:47,016 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 19:28:47,016 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 181
2014-05-05 19:28:47,016 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 36 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 21 SyncTimes(ms): 60 
2014-05-05 19:28:47,661 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 36 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 22 SyncTimes(ms): 705 
2014-05-05 19:28:47,662 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000181 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000181-0000000000000000216
2014-05-05 19:28:47,662 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 217
2014-05-05 19:28:55,580 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=216&storageInfo=-47:793646566:0:CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d
2014-05-05 19:28:55,796 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.22s at 23.26 KB/s
2014-05-05 19:28:55,796 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000216 size 6118 bytes.
2014-05-05 19:28:55,804 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 140
2014-05-05 19:28:55,804 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000133, cpktTxId=0000000000000000133)
2014-05-05 19:29:25,157 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job_1399318071615_0001_1.jhist. BP-114085979-10.0.0.195-1399315646731 blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 19:29:25,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0001/job_1399318071615_0001_1.jhist for DFSClient_NONMAPREDUCE_596198447_1
2014-05-05 19:32:05,117 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 6 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 3612 
2014-05-05 19:32:05,194 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job.jar. BP-114085979-10.0.0.195-1399315646731 blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 19:32:05,855 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 19:32:05,856 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 19:32:05,857 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 19:32:05,859 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 19:32:05,865 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job.jar is closed by DFSClient_NONMAPREDUCE_317040883_1
2014-05-05 19:32:05,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job.jar
2014-05-05 19:32:05,929 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job.split
2014-05-05 19:32:05,938 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job.split. BP-114085979-10.0.0.195-1399315646731 blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]}
2014-05-05 19:32:05,972 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 19:32:05,973 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 19:32:05,974 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 19:32:05,975 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 19:32:05,976 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 19:32:05,978 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 19:32:05,979 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 19:32:05,980 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 19:32:05,983 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job.split is closed by DFSClient_NONMAPREDUCE_317040883_1
2014-05-05 19:32:05,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job.splitmetainfo. BP-114085979-10.0.0.195-1399315646731 blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]}
2014-05-05 19:32:06,007 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 19:32:06,007 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 19:32:06,009 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 19:32:06,010 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW]]} size 0
2014-05-05 19:32:06,013 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_317040883_1
2014-05-05 19:32:06,292 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job.xml. BP-114085979-10.0.0.195-1399315646731 blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]}
2014-05-05 19:32:06,319 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:32:06,320 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:32:06,321 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:32:06,323 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 19:32:06,325 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job.xml is closed by DFSClient_NONMAPREDUCE_317040883_1
2014-05-05 19:32:06,965 INFO BlockStateChange: BLOCK* ask 10.0.0.193:50010 to replicate blk_1073741856_1032 to datanode(s) 10.0.0.36:50010 10.0.0.35:50010 10.0.0.38:50010 10.0.0.200:50010
2014-05-05 19:32:10,181 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741856_1032 size 39460542
2014-05-05 19:32:10,181 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741856_1032 size 39460542
2014-05-05 19:32:10,182 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741856_1032 size 39460542
2014-05-05 19:32:10,182 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741856_1032 size 39460542
2014-05-05 19:32:12,950 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job_1399318071615_0002_1_conf.xml. BP-114085979-10.0.0.195-1399315646731 blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]}
2014-05-05 19:32:13,042 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 19:32:13,043 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.35:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 19:32:13,045 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 19:32:13,047 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.35:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 19:32:13,052 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job_1399318071615_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_2095166237_1
2014-05-05 19:33:13,886 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job_1399318071615_0002_1.jhist. BP-114085979-10.0.0.195-1399315646731 blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 19:33:13,912 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399318071615_0002/job_1399318071615_0002_1.jhist for DFSClient_NONMAPREDUCE_2095166237_1
2014-05-05 19:33:13,912 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 43 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 22 SyncTimes(ms): 3633 
2014-05-05 19:43:03,961 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 20, processing time: 1 msecs
2014-05-05 19:51:37,040 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 19:51:37,043 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 19:52:11,480 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-patch/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-patch/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-05-04T05:58Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 19:52:11,488 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 19:52:11,787 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 19:52:11,898 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 19:52:11,898 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 19:52:12,177 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-05-05 19:52:12,526 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 19:52:12,641 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 19:52:12,644 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 19:52:12,645 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 19:52:12,645 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 19:52:12,681 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 19:52:12,719 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 19:52:12,719 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 19:52:13,203 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 19:52:13,203 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 19:52:13,237 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 19:52:13,237 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 19:52:13,316 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 19:52:13,316 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 19:52:13,319 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 19:52:13,323 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 19:52:13,323 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:52:13,328 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 8.9 GB
2014-05-05 19:52:13,328 INFO org.apache.hadoop.util.GSet: capacity      = 2^25 = 33554432 entries
2014-05-05 19:52:13,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 19:52:13,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 19:52:13,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 19:52:13,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 19:52:13,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 19:52:13,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 19:52:13,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 19:52:13,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 19:52:13,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 19:52:13,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 19:52:13,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 19:52:13,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 19:52:13,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 19:52:13,551 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 19:52:13,552 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:52:13,552 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 8.9 GB
2014-05-05 19:52:13,552 INFO org.apache.hadoop.util.GSet: capacity      = 2^24 = 16777216 entries
2014-05-05 19:52:13,616 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 19:52:13,620 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 19:52:13,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 19:52:13,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 19:52:13,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 19:52:13,624 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 19:52:13,627 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 19:52:13,627 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 19:52:13,627 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 8.9 GB
2014-05-05 19:52:13,627 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2014-05-05 19:52:13,642 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 23396@ip-10-0-0-195
2014-05-05 19:52:13,718 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 19:52:13,819 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000217 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000217-0000000000000000259
2014-05-05 19:52:13,839 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000216 using no compression
2014-05-05 19:52:13,839 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 46
2014-05-05 19:52:13,855 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 5
2014-05-05 19:52:13,864 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000216 of size 6118 bytes loaded in 0 seconds.
2014-05-05 19:52:13,864 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 216 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000216
2014-05-05 19:52:13,864 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@46476275 expecting start txid #217
2014-05-05 19:52:13,864 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000217-0000000000000000259
2014-05-05 19:52:13,867 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000000217-0000000000000000259' to transaction ID 217
2014-05-05 19:52:13,886 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000217-0000000000000000259 of size 1048576 edits # 43 loaded in 0 seconds
2014-05-05 19:52:13,891 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 260
2014-05-05 19:52:14,025 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 19:52:14,025 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 397 msecs
2014-05-05 19:52:14,499 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 19:52:14,517 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 19:52:14,575 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 19:52:14,585 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 6
2014-05-05 19:52:14,586 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 6
2014-05-05 19:52:14,586 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 31 blocks to reach the threshold 0.9990 of total blocks 31.
Safe mode will be turned off automatically
2014-05-05 19:52:14,616 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 19:52:14,617 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 19:52:14,619 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 19:52:14,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 19:52:18,466 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.35, storageID=DS-283411255-10.0.0.35-50010-1399315661421, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-283411255-10.0.0.35-50010-1399315661421
2014-05-05 19:52:18,469 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.35:50010
2014-05-05 19:52:18,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.38, storageID=DS-1670817916-10.0.0.38-50010-1399315661447, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1670817916-10.0.0.38-50010-1399315661447
2014-05-05 19:52:18,499 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.38:50010
2014-05-05 19:52:18,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-13906350-10.0.0.200-50010-1399315661489, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-13906350-10.0.0.200-50010-1399315661489
2014-05-05 19:52:18,563 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 19:52:18,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-258220490-10.0.0.194-50010-1399315661308, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-258220490-10.0.0.194-50010-1399315661308
2014-05-05 19:52:18,592 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 19:52:18,619 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.36, storageID=DS-1358703672-10.0.0.36-50010-1399315661430, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1358703672-10.0.0.36-50010-1399315661430
2014-05-05 19:52:18,620 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.36:50010
2014-05-05 19:52:18,673 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:52:18,673 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-13906350-10.0.0.200-50010-1399315661489, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 25, processing time: 8 msecs
2014-05-05 19:52:18,673 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.37, storageID=DS-1870530911-10.0.0.37-50010-1399315661396, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1870530911-10.0.0.37-50010-1399315661396
2014-05-05 19:52:18,679 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.37:50010
2014-05-05 19:52:18,680 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.38:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:52:18,680 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.38, storageID=DS-1670817916-10.0.0.38-50010-1399315661447, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 26, processing time: 1 msecs
2014-05-05 19:52:18,680 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1214695977-10.0.0.193-50010-1399315661285
2014-05-05 19:52:18,681 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 19:52:18,683 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 30 has reached the threshold 0.9990 of total blocks 31. The number of live datanodes 7 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2014-05-05 19:52:18,683 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2014-05-05 19:52:18,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 37
2014-05-05 19:52:18,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2014-05-05 19:52:18,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 31
2014-05-05 19:52:18,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2014-05-05 19:52:18,773 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 6
2014-05-05 19:52:18,774 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 91 msec
2014-05-05 19:52:18,775 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.35:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:52:18,775 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.35, storageID=DS-283411255-10.0.0.35-50010-1399315661421, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 22, processing time: 94 msecs
2014-05-05 19:52:18,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.36:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:52:18,777 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.36, storageID=DS-1358703672-10.0.0.36-50010-1399315661430, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 23, processing time: 2 msecs
2014-05-05 19:52:18,779 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:52:18,779 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-258220490-10.0.0.194-50010-1399315661308, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 24, processing time: 2 msecs
2014-05-05 19:52:18,815 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:52:18,816 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1214695977-10.0.0.193-50010-1399315661285, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 20, processing time: 2 msecs
2014-05-05 19:52:18,841 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.37:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:52:18,841 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.37, storageID=DS-1870530911-10.0.0.37-50010-1399315661396, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 21, processing time: 1 msecs
2014-05-05 19:52:18,881 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0) storage DS-1668817953-10.0.0.195-50010-1399315661283
2014-05-05 19:52:18,881 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 19:52:19,000 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 19:52:19,000 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 35, processing time: 2 msecs
2014-05-05 19:52:38,781 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 31 has reached the threshold 0.9990 of total blocks 31. The number of live datanodes 8 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2014-05-05 19:52:48,782 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2014-05-05 19:52:48,782 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2014-05-05 19:52:48,782 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 8 datanodes
2014-05-05 19:52:48,782 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 12 blocks
2014-05-05 19:53:24,790 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 19:53:24,790 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 19:53:24,790 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 260
2014-05-05 19:53:24,790 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 63 
2014-05-05 19:53:24,792 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 65 
2014-05-05 19:53:24,793 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000260 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000260-0000000000000000261
2014-05-05 19:53:24,793 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 262
2014-05-05 19:53:25,659 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=261&storageInfo=-47:793646566:0:CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d
2014-05-05 19:53:25,896 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.24s at 25.32 KB/s
2014-05-05 19:53:25,896 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000261 size 7144 bytes.
2014-05-05 19:53:25,906 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 216
2014-05-05 19:53:25,907 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000140, cpktTxId=0000000000000000140)
2014-05-05 19:54:08,946 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: Lease mismatch: BP-899801483-10.0.0.195-1399294588764:blk_1073741849_1025 is accessed by a non lease holder DFSClient_NONMAPREDUCE_-1037182608_1
2014-05-05 19:54:08,946 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 54310, call org.apache.hadoop.hdfs.protocol.ClientProtocol.updateBlockForPipeline from 10.0.0.195:42630 Call#10 Retry#0: error: org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: Lease mismatch: BP-899801483-10.0.0.195-1399294588764:blk_1073741849_1025 is accessed by a non lease holder DFSClient_NONMAPREDUCE_-1037182608_1
2014-05-05 19:58:48,902 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1668817953-10.0.0.195-50010-1399315661283, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-00dcdf23-3ed2-40a5-ade4-a878f4e0e53d;nsid=793646566;c=0), blocks: 35, processing time: 2 msecs
