2014-04-24 22:38:33,490 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-04-24 22:38:33,501 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-04-24 22:38:34,324 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-04-24 22:38:34,486 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-04-24 22:38:34,487 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2014-04-24 22:38:34,511 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2014-04-24 22:38:34,511 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1398311343215_0069, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@536922b)
2014-04-24 22:38:34,667 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2014-04-24 22:38:35,345 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-04-24 22:38:35,346 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-04-24 22:38:35,655 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /var/hadoop/tmp/nm-local-dir/usercache/ubuntu/appcache/application_1398311343215_0069
2014-04-24 22:38:36,051 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-04-24 22:38:36,053 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-04-24 22:38:36,241 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2014-04-24 22:38:36,241 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2014-04-24 22:38:36,242 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2014-04-24 22:38:36,243 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2014-04-24 22:38:36,252 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2014-04-24 22:38:36,253 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2014-04-24 22:38:36,253 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2014-04-24 22:38:36,254 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2014-04-24 22:38:36,625 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2014-04-24 22:38:37,123 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2014-04-24 22:38:37,215 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22eaa01b
2014-04-24 22:38:37,244 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130652568, maxSingleShuffleLimit=32663142, mergeThreshold=86230696, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-04-24 22:38:37,248 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1398311343215_0069_r_000003_1 Thread started: EventFetcher for fetching Map Completion Events
2014-04-24 22:38:37,260 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1398311343215_0069_r_000003_1: Got 1 new map-outputs
2014-04-24 22:38:37,264 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning noded:13562 with 1 to fetcher#1
2014-04-24 22:38:37,264 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 1 of 1 to noded:13562 to fetcher#1
2014-04-24 22:38:37,301 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=13562/mapOutput?job=job_1398311343215_0069&reduce=3&map=attempt_1398311343215_0069_m_000000_0 sent hash and received reply
2014-04-24 22:38:37,305 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1398311343215_0069_m_000000_0 decomp: 1200672 len: 1200676 to MEMORY
2014-04-24 22:38:37,323 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1200672 bytes from map-output for attempt_1398311343215_0069_m_000000_0
2014-04-24 22:38:37,328 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1200672, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1200672
2014-04-24 22:38:37,329 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2014-04-24 22:38:37,329 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: noded:13562 freed by fetcher#1 in 65ms
2014-04-24 22:38:37,336 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-04-24 22:38:37,345 INFO [main] org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2014-04-24 22:38:37,346 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1200662 bytes
2014-04-24 22:38:37,691 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 1200672 bytes to disk to satisfy reduce memory limit
2014-04-24 22:38:37,692 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 1200676 bytes from disk
2014-04-24 22:38:37,694 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2014-04-24 22:38:37,694 INFO [main] org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2014-04-24 22:38:37,698 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1200662 bytes
2014-04-24 22:38:37,981 ERROR [main] org.apache.cassandra.hadoop.ConfigHelper: failed to connect to any initial addresses
2014-04-24 22:38:37,981 ERROR [main] org.apache.cassandra.hadoop.ConfigHelper: 
java.io.IOException: Unable to connect to server ec2-54-187-121-79.us-west-2.compute.amazonaws.com:9160
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:563)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromAddressList(ConfigHelper.java:534)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromOutputAddressList(ConfigHelper.java:523)
	at org.apache.cassandra.client.RingCache.refreshEndpointMap(RingCache.java:67)
	at org.apache.cassandra.client.RingCache.<init>(RingCache.java:60)
	at org.apache.cassandra.hadoop.AbstractColumnFamilyRecordWriter.<init>(AbstractColumnFamilyRecordWriter.java:76)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:102)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:91)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:74)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:1)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:558)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:632)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:405)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:162)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:157)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:558)
	... 17 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
	... 20 more
2014-04-24 22:38:37,986 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.RuntimeException: java.io.IOException: Unable to connect to server ec2-54-187-121-79.us-west-2.compute.amazonaws.com:9160
	at org.apache.cassandra.client.RingCache.refreshEndpointMap(RingCache.java:96)
	at org.apache.cassandra.client.RingCache.<init>(RingCache.java:60)
	at org.apache.cassandra.hadoop.AbstractColumnFamilyRecordWriter.<init>(AbstractColumnFamilyRecordWriter.java:76)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:102)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:91)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:74)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:1)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:558)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:632)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:405)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:162)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:157)
Caused by: java.io.IOException: Unable to connect to server ec2-54-187-121-79.us-west-2.compute.amazonaws.com:9160
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:563)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromAddressList(ConfigHelper.java:534)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromOutputAddressList(ConfigHelper.java:523)
	at org.apache.cassandra.client.RingCache.refreshEndpointMap(RingCache.java:67)
	... 14 more
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:558)
	... 17 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
	... 20 more

2014-04-24 22:38:37,990 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2014-04-24 22:38:37,995 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ReduceTask metrics system...
2014-04-24 22:38:38,001 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system stopped.
2014-04-24 22:38:38,001 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system shutdown complete.
