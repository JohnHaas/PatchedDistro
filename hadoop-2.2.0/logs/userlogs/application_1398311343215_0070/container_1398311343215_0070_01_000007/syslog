2014-04-24 22:39:37,781 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-04-24 22:39:37,784 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-04-24 22:39:38,530 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-04-24 22:39:38,654 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-04-24 22:39:38,654 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2014-04-24 22:39:38,678 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2014-04-24 22:39:38,678 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1398311343215_0070, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@41b647b9)
2014-04-24 22:39:38,833 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2014-04-24 22:39:39,812 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-04-24 22:39:39,813 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-04-24 22:39:40,045 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /var/hadoop/tmp/nm-local-dir/usercache/ubuntu/appcache/application_1398311343215_0070
2014-04-24 22:39:40,360 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-04-24 22:39:40,360 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-04-24 22:39:40,539 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2014-04-24 22:39:40,540 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2014-04-24 22:39:40,541 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2014-04-24 22:39:40,542 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2014-04-24 22:39:40,552 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2014-04-24 22:39:40,553 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2014-04-24 22:39:40,553 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2014-04-24 22:39:40,554 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2014-04-24 22:39:41,296 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2014-04-24 22:39:41,992 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2014-04-24 22:39:42,281 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6af4a4e0
2014-04-24 22:39:42,354 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130652568, maxSingleShuffleLimit=32663142, mergeThreshold=86230696, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-04-24 22:39:42,370 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1398311343215_0070_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2014-04-24 22:39:42,413 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1398311343215_0070_r_000004_0: Got 1 new map-outputs
2014-04-24 22:39:42,413 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning nodec:13562 with 1 to fetcher#2
2014-04-24 22:39:42,413 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 1 of 1 to nodec:13562 to fetcher#2
2014-04-24 22:39:42,564 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=13562/mapOutput?job=job_1398311343215_0070&reduce=4&map=attempt_1398311343215_0070_m_000000_0 sent hash and received reply
2014-04-24 22:39:42,597 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1398311343215_0070_m_000000_0 decomp: 798018 len: 798022 to MEMORY
2014-04-24 22:39:42,649 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 798018 bytes from map-output for attempt_1398311343215_0070_m_000000_0
2014-04-24 22:39:42,661 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 798018, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->798018
2014-04-24 22:39:42,666 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2014-04-24 22:39:42,667 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: nodec:13562 freed by fetcher#2 in 254ms
2014-04-24 22:39:42,676 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-04-24 22:39:42,694 INFO [main] org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2014-04-24 22:39:42,694 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 798007 bytes
2014-04-24 22:39:43,449 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 798018 bytes to disk to satisfy reduce memory limit
2014-04-24 22:39:43,450 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 798022 bytes from disk
2014-04-24 22:39:43,452 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2014-04-24 22:39:43,452 INFO [main] org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2014-04-24 22:39:43,461 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 798007 bytes
2014-04-24 22:39:43,824 ERROR [main] org.apache.cassandra.hadoop.ConfigHelper: failed to connect to any initial addresses
2014-04-24 22:39:43,825 ERROR [main] org.apache.cassandra.hadoop.ConfigHelper: 
java.io.IOException: Unable to connect to server ec2-54-187-121-79.us-west-2.compute.amazonaws.com:9160
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:563)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromAddressList(ConfigHelper.java:534)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromOutputAddressList(ConfigHelper.java:523)
	at org.apache.cassandra.client.RingCache.refreshEndpointMap(RingCache.java:67)
	at org.apache.cassandra.client.RingCache.<init>(RingCache.java:60)
	at org.apache.cassandra.hadoop.AbstractColumnFamilyRecordWriter.<init>(AbstractColumnFamilyRecordWriter.java:76)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:102)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:91)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:74)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:1)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:558)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:632)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:405)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:162)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:157)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:558)
	... 17 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
	... 20 more
2014-04-24 22:39:43,830 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.RuntimeException: java.io.IOException: Unable to connect to server ec2-54-187-121-79.us-west-2.compute.amazonaws.com:9160
	at org.apache.cassandra.client.RingCache.refreshEndpointMap(RingCache.java:96)
	at org.apache.cassandra.client.RingCache.<init>(RingCache.java:60)
	at org.apache.cassandra.hadoop.AbstractColumnFamilyRecordWriter.<init>(AbstractColumnFamilyRecordWriter.java:76)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:102)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:91)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:74)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:1)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:558)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:632)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:405)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:162)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:157)
Caused by: java.io.IOException: Unable to connect to server ec2-54-187-121-79.us-west-2.compute.amazonaws.com:9160
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:563)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromAddressList(ConfigHelper.java:534)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromOutputAddressList(ConfigHelper.java:523)
	at org.apache.cassandra.client.RingCache.refreshEndpointMap(RingCache.java:67)
	... 14 more
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:558)
	... 17 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
	... 20 more

2014-04-24 22:39:43,835 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2014-04-24 22:39:43,840 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ReduceTask metrics system...
2014-04-24 22:39:43,841 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system stopped.
2014-04-24 22:39:43,841 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system shutdown complete.
