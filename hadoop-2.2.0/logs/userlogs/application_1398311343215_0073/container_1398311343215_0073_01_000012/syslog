2014-04-24 22:44:17,934 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-04-24 22:44:17,937 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-04-24 22:44:18,267 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-04-24 22:44:18,386 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-04-24 22:44:18,386 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2014-04-24 22:44:18,404 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2014-04-24 22:44:18,404 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1398311343215_0073, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@536922b)
2014-04-24 22:44:18,514 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2014-04-24 22:44:18,946 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-04-24 22:44:18,947 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-04-24 22:44:19,041 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /var/hadoop/tmp/nm-local-dir/usercache/ubuntu/appcache/application_1398311343215_0073
2014-04-24 22:44:19,283 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-04-24 22:44:19,284 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-04-24 22:44:19,405 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2014-04-24 22:44:19,405 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2014-04-24 22:44:19,406 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2014-04-24 22:44:19,407 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2014-04-24 22:44:19,408 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2014-04-24 22:44:19,409 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2014-04-24 22:44:19,409 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2014-04-24 22:44:19,410 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2014-04-24 22:44:19,796 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2014-04-24 22:44:20,279 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2014-04-24 22:44:20,374 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5be93954
2014-04-24 22:44:20,404 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130652568, maxSingleShuffleLimit=32663142, mergeThreshold=86230696, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-04-24 22:44:20,408 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1398311343215_0073_r_000003_2 Thread started: EventFetcher for fetching Map Completion Events
2014-04-24 22:44:20,422 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1398311343215_0073_r_000003_2: Got 1 new map-outputs
2014-04-24 22:44:20,422 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning nodeb:13562 with 1 to fetcher#5
2014-04-24 22:44:20,422 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 1 of 1 to nodeb:13562 to fetcher#5
2014-04-24 22:44:20,458 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=13562/mapOutput?job=job_1398311343215_0073&reduce=3&map=attempt_1398311343215_0073_m_000000_0 sent hash and received reply
2014-04-24 22:44:20,463 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1398311343215_0073_m_000000_0 decomp: 1200672 len: 1200676 to MEMORY
2014-04-24 22:44:20,481 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 1200672 bytes from map-output for attempt_1398311343215_0073_m_000000_0
2014-04-24 22:44:20,485 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1200672, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1200672
2014-04-24 22:44:20,486 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2014-04-24 22:44:20,487 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: nodeb:13562 freed by fetcher#5 in 65ms
2014-04-24 22:44:20,498 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-04-24 22:44:20,508 INFO [main] org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2014-04-24 22:44:20,509 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1200662 bytes
2014-04-24 22:44:20,835 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 1200672 bytes to disk to satisfy reduce memory limit
2014-04-24 22:44:20,835 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 1200676 bytes from disk
2014-04-24 22:44:20,837 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2014-04-24 22:44:20,837 INFO [main] org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2014-04-24 22:44:20,841 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1200662 bytes
2014-04-24 22:44:21,123 ERROR [main] org.apache.cassandra.hadoop.ConfigHelper: failed to connect to any initial addresses
2014-04-24 22:44:21,124 ERROR [main] org.apache.cassandra.hadoop.ConfigHelper: 
java.io.IOException: Unable to connect to server ec2-54-187-121-79.us-west-2.compute.amazonaws.com:9160
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:563)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromAddressList(ConfigHelper.java:534)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromOutputAddressList(ConfigHelper.java:523)
	at org.apache.cassandra.client.RingCache.refreshEndpointMap(RingCache.java:67)
	at org.apache.cassandra.client.RingCache.<init>(RingCache.java:60)
	at org.apache.cassandra.hadoop.AbstractColumnFamilyRecordWriter.<init>(AbstractColumnFamilyRecordWriter.java:76)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:102)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:91)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:74)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:1)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:558)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:632)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:405)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:162)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:157)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:558)
	... 17 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
	... 20 more
2014-04-24 22:44:21,128 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.RuntimeException: java.io.IOException: Unable to connect to server ec2-54-187-121-79.us-west-2.compute.amazonaws.com:9160
	at org.apache.cassandra.client.RingCache.refreshEndpointMap(RingCache.java:96)
	at org.apache.cassandra.client.RingCache.<init>(RingCache.java:60)
	at org.apache.cassandra.hadoop.AbstractColumnFamilyRecordWriter.<init>(AbstractColumnFamilyRecordWriter.java:76)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:102)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:91)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:74)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:1)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:558)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:632)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:405)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:162)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:157)
Caused by: java.io.IOException: Unable to connect to server ec2-54-187-121-79.us-west-2.compute.amazonaws.com:9160
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:563)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromAddressList(ConfigHelper.java:534)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromOutputAddressList(ConfigHelper.java:523)
	at org.apache.cassandra.client.RingCache.refreshEndpointMap(RingCache.java:67)
	... 14 more
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:558)
	... 17 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
	... 20 more

2014-04-24 22:44:21,133 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
