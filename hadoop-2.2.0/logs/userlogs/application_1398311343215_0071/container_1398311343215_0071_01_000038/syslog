2014-04-24 22:41:30,440 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-04-24 22:41:30,444 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-04-24 22:41:30,820 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-04-24 22:41:30,945 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-04-24 22:41:30,945 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2014-04-24 22:41:30,962 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2014-04-24 22:41:30,962 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1398311343215_0071, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@536922b)
2014-04-24 22:41:31,070 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2014-04-24 22:41:31,524 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-04-24 22:41:31,525 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-04-24 22:41:31,722 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /var/hadoop/tmp/nm-local-dir/usercache/ubuntu/appcache/application_1398311343215_0071
2014-04-24 22:41:31,888 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2014-04-24 22:41:31,889 WARN [main] org.apache.hadoop.conf.Configuration: job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2014-04-24 22:41:31,981 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2014-04-24 22:41:31,981 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2014-04-24 22:41:31,982 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2014-04-24 22:41:31,983 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2014-04-24 22:41:31,989 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2014-04-24 22:41:31,989 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2014-04-24 22:41:31,990 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2014-04-24 22:41:31,990 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2014-04-24 22:41:32,481 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2014-04-24 22:41:32,984 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2014-04-24 22:41:33,081 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3d7f0649
2014-04-24 22:41:33,108 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130652568, maxSingleShuffleLimit=32663142, mergeThreshold=86230696, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2014-04-24 22:41:33,112 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1398311343215_0071_r_000001_2 Thread started: EventFetcher for fetching Map Completion Events
2014-04-24 22:41:33,121 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1398311343215_0071_r_000001_2: Got 1 new map-outputs
2014-04-24 22:41:33,124 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning nodeb:13562 with 1 to fetcher#1
2014-04-24 22:41:33,124 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 1 of 1 to nodeb:13562 to fetcher#1
2014-04-24 22:41:33,161 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=13562/mapOutput?job=job_1398311343215_0071&reduce=1&map=attempt_1398311343215_0071_m_000000_0 sent hash and received reply
2014-04-24 22:41:33,165 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1398311343215_0071_m_000000_0 decomp: 596726 len: 596730 to MEMORY
2014-04-24 22:41:33,176 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 596726 bytes from map-output for attempt_1398311343215_0071_m_000000_0
2014-04-24 22:41:33,181 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 596726, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->596726
2014-04-24 22:41:33,182 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2014-04-24 22:41:33,182 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: nodeb:13562 freed by fetcher#1 in 58ms
2014-04-24 22:41:33,187 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2014-04-24 22:41:33,197 INFO [main] org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2014-04-24 22:41:33,197 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 596714 bytes
2014-04-24 22:41:33,510 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 596726 bytes to disk to satisfy reduce memory limit
2014-04-24 22:41:33,511 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 596730 bytes from disk
2014-04-24 22:41:33,513 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2014-04-24 22:41:33,513 INFO [main] org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2014-04-24 22:41:33,516 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 596714 bytes
2014-04-24 22:41:33,781 ERROR [main] org.apache.cassandra.hadoop.ConfigHelper: failed to connect to any initial addresses
2014-04-24 22:41:33,782 ERROR [main] org.apache.cassandra.hadoop.ConfigHelper: 
java.io.IOException: Unable to connect to server ec2-54-187-121-79.us-west-2.compute.amazonaws.com:9160
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:563)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromAddressList(ConfigHelper.java:534)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromOutputAddressList(ConfigHelper.java:523)
	at org.apache.cassandra.client.RingCache.refreshEndpointMap(RingCache.java:67)
	at org.apache.cassandra.client.RingCache.<init>(RingCache.java:60)
	at org.apache.cassandra.hadoop.AbstractColumnFamilyRecordWriter.<init>(AbstractColumnFamilyRecordWriter.java:76)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:102)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:91)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:74)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:1)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:558)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:632)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:405)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:162)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:157)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:558)
	... 17 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
	... 20 more
2014-04-24 22:41:33,786 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.RuntimeException: java.io.IOException: Unable to connect to server ec2-54-187-121-79.us-west-2.compute.amazonaws.com:9160
	at org.apache.cassandra.client.RingCache.refreshEndpointMap(RingCache.java:96)
	at org.apache.cassandra.client.RingCache.<init>(RingCache.java:60)
	at org.apache.cassandra.hadoop.AbstractColumnFamilyRecordWriter.<init>(AbstractColumnFamilyRecordWriter.java:76)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:102)
	at org.apache.cassandra.hadoop.cql3.CqlRecordWriter.<init>(CqlRecordWriter.java:91)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:74)
	at org.apache.cassandra.hadoop.cql3.CqlOutputFormat.getRecordWriter(CqlOutputFormat.java:1)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.<init>(ReduceTask.java:558)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:632)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:405)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:162)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:157)
Caused by: java.io.IOException: Unable to connect to server ec2-54-187-121-79.us-west-2.compute.amazonaws.com:9160
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:563)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromAddressList(ConfigHelper.java:534)
	at org.apache.cassandra.hadoop.ConfigHelper.getClientFromOutputAddressList(ConfigHelper.java:523)
	at org.apache.cassandra.client.RingCache.refreshEndpointMap(RingCache.java:67)
	... 14 more
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
	at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
	at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
	at org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)
	at org.apache.cassandra.hadoop.ConfigHelper.createConnection(ConfigHelper.java:558)
	... 17 more
Caused by: java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
	... 20 more

2014-04-24 22:41:33,791 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
