2014-05-05 12:15:50,963 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-2.2.0/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'Joey' on 2014-03-24T00:00Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 12:15:50,975 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 12:15:51,368 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 12:15:51,482 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 12:15:51,482 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 12:15:52,204 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 12:15:52,285 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 12:15:52,288 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 12:15:52,288 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 12:15:52,288 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 12:15:52,337 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 12:15:52,374 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 12:15:52,374 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 12:15:52,724 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 12:15:52,725 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 12:15:52,783 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 12:15:52,783 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 12:15:52,860 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 12:15:52,860 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 12:15:52,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 12:15:52,865 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 12:15:52,865 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 12:15:52,866 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2014-05-05 12:15:52,866 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2014-05-05 12:15:52,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 12:15:52,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 12:15:52,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 12:15:52,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 12:15:52,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 12:15:52,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 12:15:52,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 12:15:52,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 12:15:52,878 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 12:15:52,878 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 12:15:52,878 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 12:15:52,878 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 12:15:52,880 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 12:15:52,937 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 12:15:52,937 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 12:15:52,937 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2014-05-05 12:15:52,937 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2014-05-05 12:15:52,960 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 12:15:52,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 12:15:52,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 12:15:52,964 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 12:15:52,965 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 12:15:52,966 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 12:15:52,968 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 12:15:52,968 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 12:15:52,968 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2014-05-05 12:15:52,968 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2014-05-05 12:15:52,984 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 14904@ip-10-0-0-195
2014-05-05 12:15:53,061 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 12:15:53,205 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000274 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000274-0000000000000000562
2014-05-05 12:15:53,224 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000273 using no compression
2014-05-05 12:15:53,224 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 40
2014-05-05 12:15:53,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 4
2014-05-05 12:15:53,247 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000273 of size 5606 bytes loaded in 0 seconds.
2014-05-05 12:15:53,247 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 273 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000273
2014-05-05 12:15:53,247 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5268ab18 expecting start txid #274
2014-05-05 12:15:53,248 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000274-0000000000000000562
2014-05-05 12:15:53,250 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000000274-0000000000000000562' to transaction ID 274
2014-05-05 12:15:53,329 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000000274-0000000000000000562 of size 1048576 edits # 289 loaded in 0 seconds
2014-05-05 12:15:53,331 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 563
2014-05-05 12:15:53,466 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 12:15:53,466 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 497 msecs
2014-05-05 12:15:53,819 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 12:15:53,843 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 12:15:53,897 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 12:15:53,909 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 5
2014-05-05 12:15:53,910 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 5
2014-05-05 12:15:53,911 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 56 blocks to reach the threshold 0.9990 of total blocks 56.
Safe mode will be turned off automatically
2014-05-05 12:15:53,941 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 12:15:53,942 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 12:15:53,944 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 12:15:53,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 12:15:58,355 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1713066011-10.0.0.195-50010-1399292158045, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-1713066011-10.0.0.195-50010-1399292158045
2014-05-05 12:15:58,357 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 12:15:58,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:15:58,452 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1713066011-10.0.0.195-50010-1399292158045, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 1 msecs
2014-05-05 12:16:00,106 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1329126455-10.0.0.193-50010-1399292159802, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-1329126455-10.0.0.193-50010-1399292159802
2014-05-05 12:16:00,106 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 12:16:00,152 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:16:00,152 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1329126455-10.0.0.193-50010-1399292159802, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:16:01,456 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-2146034224-10.0.0.194-50010-1399292161189, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-2146034224-10.0.0.194-50010-1399292161189
2014-05-05 12:16:01,460 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 12:16:01,482 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-1325743637-10.0.0.200-50010-1399292160221, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-1325743637-10.0.0.200-50010-1399292160221
2014-05-05 12:16:01,483 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 12:16:01,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:16:01,507 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-2146034224-10.0.0.194-50010-1399292161189, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:16:01,696 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:16:01,696 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-1325743637-10.0.0.200-50010-1399292160221, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:16:47,530 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.196, storageID=DS-612785173-10.0.0.196-50010-1399292207228, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-612785173-10.0.0.196-50010-1399292207228
2014-05-05 12:16:47,531 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.196:50010
2014-05-05 12:16:47,531 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 56 blocks to reach the threshold 0.9990 of total blocks 56.
Safe mode will be turned off automatically
2014-05-05 12:16:47,575 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.196:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:16:47,575 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.196, storageID=DS-612785173-10.0.0.196-50010-1399292207228, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:16:47,669 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.199, storageID=DS-1248165096-10.0.0.199-50010-1399292207370, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-1248165096-10.0.0.199-50010-1399292207370
2014-05-05 12:16:47,669 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.199:50010
2014-05-05 12:16:47,714 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.199:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:16:47,714 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.199, storageID=DS-1248165096-10.0.0.199-50010-1399292207370, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 1 msecs
2014-05-05 12:16:48,594 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.198, storageID=DS-212208416-10.0.0.198-50010-1399292208307, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-212208416-10.0.0.198-50010-1399292208307
2014-05-05 12:16:48,595 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.198:50010
2014-05-05 12:16:48,670 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.198:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:16:48,670 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.198, storageID=DS-212208416-10.0.0.198-50010-1399292208307, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:16:48,881 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.197, storageID=DS-1171498557-10.0.0.197-50010-1399292208605, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0) storage DS-1171498557-10.0.0.197-50010-1399292208605
2014-05-05 12:16:48,882 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.197:50010
2014-05-05 12:16:48,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.197:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:16:48,948 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.197, storageID=DS-1171498557-10.0.0.197-50010-1399292208605, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-12638edf-52d0-4ee2-860a-8c4caf72e336;nsid=172347890;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:17:03,995 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 56 blocks to reach the threshold 0.9990 of total blocks 56.
Safe mode will be turned off automatically
2014-05-05 12:17:03,995 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 54310, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 10.0.0.195:39251 Call#1 Retry#0: error: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 56 blocks to reach the threshold 0.9990 of total blocks 56.
Safe mode will be turned off automatically
2014-05-05 12:17:47,326 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 12:17:47,328 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 12:18:41,377 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-2.2.0/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'Joey' on 2014-03-24T00:00Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 12:18:41,386 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 12:18:41,680 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 12:18:41,790 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 12:18:41,790 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 12:18:42,407 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 12:18:42,547 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 12:18:42,551 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 12:18:42,552 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 12:18:42,552 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 12:18:42,592 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 12:18:42,636 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 12:18:42,636 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 12:18:42,991 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 12:18:42,991 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 12:18:43,026 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 12:18:43,026 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 12:18:43,105 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 12:18:43,105 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 12:18:43,109 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 12:18:43,112 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 12:18:43,112 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 12:18:43,113 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2014-05-05 12:18:43,113 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2014-05-05 12:18:43,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 12:18:43,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 12:18:43,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 12:18:43,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 12:18:43,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 12:18:43,120 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 12:18:43,121 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 12:18:43,121 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 12:18:43,130 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 12:18:43,130 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 12:18:43,130 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 12:18:43,130 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 12:18:43,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 12:18:43,194 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 12:18:43,194 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 12:18:43,194 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2014-05-05 12:18:43,194 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2014-05-05 12:18:43,196 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 12:18:43,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 12:18:43,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 12:18:43,200 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 12:18:43,202 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 12:18:43,202 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 12:18:43,205 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 12:18:43,205 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 12:18:43,205 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2014-05-05 12:18:43,205 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2014-05-05 12:18:43,305 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 17724@ip-10-0-0-195
2014-05-05 12:18:43,413 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 12:18:43,417 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2014-05-05 12:18:43,431 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000 using no compression
2014-05-05 12:18:43,431 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 1
2014-05-05 12:18:43,438 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2014-05-05 12:18:43,438 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000 of size 198 bytes loaded in 0 seconds.
2014-05-05 12:18:43,439 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000
2014-05-05 12:18:43,446 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2014-05-05 12:18:43,841 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 12:18:43,841 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 633 msecs
2014-05-05 12:18:44,068 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 12:18:44,086 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 12:18:44,137 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 12:18:44,150 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 12:18:44,150 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 12:18:44,151 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2014-05-05 12:18:44,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2014-05-05 12:18:44,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2014-05-05 12:18:44,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2014-05-05 12:18:44,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2014-05-05 12:18:44,158 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2014-05-05 12:18:44,158 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2014-05-05 12:18:44,158 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2014-05-05 12:18:44,159 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2014-05-05 12:18:44,159 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2014-05-05 12:18:44,189 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 12:18:44,190 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 12:18:44,193 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 12:18:44,193 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 12:18:48,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.198, storageID=DS-64404635-10.0.0.198-50010-1399292328439, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0) storage DS-64404635-10.0.0.198-50010-1399292328439
2014-05-05 12:18:48,737 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.198:50010
2014-05-05 12:18:48,738 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-744592578-10.0.0.194-50010-1399292328453, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0) storage DS-744592578-10.0.0.194-50010-1399292328453
2014-05-05 12:18:48,739 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 12:18:48,741 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-827107951-10.0.0.195-50010-1399292328415, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0) storage DS-827107951-10.0.0.195-50010-1399292328415
2014-05-05 12:18:48,748 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 12:18:48,748 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.197, storageID=DS-156716729-10.0.0.197-50010-1399292328426, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0) storage DS-156716729-10.0.0.197-50010-1399292328426
2014-05-05 12:18:48,749 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.197:50010
2014-05-05 12:18:48,752 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.199, storageID=DS-185567819-10.0.0.199-50010-1399292328417, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0) storage DS-185567819-10.0.0.199-50010-1399292328417
2014-05-05 12:18:48,756 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.199:50010
2014-05-05 12:18:48,776 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-1872928241-10.0.0.193-50010-1399292328408, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0) storage DS-1872928241-10.0.0.193-50010-1399292328408
2014-05-05 12:18:48,777 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 12:18:48,778 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-489694566-10.0.0.200-50010-1399292328425, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0) storage DS-489694566-10.0.0.200-50010-1399292328425
2014-05-05 12:18:48,784 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 12:18:48,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:18:48,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.198:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:18:48,865 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-1872928241-10.0.0.193-50010-1399292328408, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0), blocks: 0, processing time: 1 msecs
2014-05-05 12:18:48,865 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.198, storageID=DS-64404635-10.0.0.198-50010-1399292328439, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:18:48,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:18:48,868 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-827107951-10.0.0.195-50010-1399292328415, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0), blocks: 0, processing time: 1 msecs
2014-05-05 12:18:48,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:18:48,868 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-489694566-10.0.0.200-50010-1399292328425, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:18:48,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:18:48,868 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-744592578-10.0.0.194-50010-1399292328453, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:18:48,905 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.197:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:18:48,905 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.197, storageID=DS-156716729-10.0.0.197-50010-1399292328426, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:18:48,909 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.199:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:18:48,909 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.199, storageID=DS-185567819-10.0.0.199-50010-1399292328417, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:19:38,535 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.196, storageID=DS-1441897823-10.0.0.196-50010-1399292378250, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0) storage DS-1441897823-10.0.0.196-50010-1399292378250
2014-05-05 12:19:38,535 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.196:50010
2014-05-05 12:19:38,643 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.196:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:19:38,643 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.196, storageID=DS-1441897823-10.0.0.196-50010-1399292378250, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-1502c6bf-31ec-446a-8c66-f148e9614950;nsid=1689216550;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:19:54,091 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 12:19:54,091 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 12:19:54,091 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2014-05-05 12:19:54,091 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 146 
2014-05-05 12:19:54,124 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 178 
2014-05-05 12:19:54,125 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000002
2014-05-05 12:19:54,125 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2014-05-05 12:19:55,046 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=2&storageInfo=-47:1689216550:0:CID-1502c6bf-31ec-446a-8c66-f148e9614950
2014-05-05 12:19:55,273 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.23s at 0.00 KB/s
2014-05-05 12:19:55,273 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 198 bytes.
2014-05-05 12:19:55,291 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2014-05-05 12:24:49,972 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 175 
2014-05-05 12:25:22,841 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in500k/data._COPYING_. BP-664678693-10.0.0.195-1399292316143 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 12:25:27,107 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:25:27,110 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:25:27,112 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:25:27,118 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:25:27,120 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in500k/data._COPYING_. BP-664678693-10.0.0.195-1399292316143 blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 12:25:31,564 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:25:31,567 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:25:31,568 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:25:31,570 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:25:36,754 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /in500k/data._COPYING_ is closed by DFSClient_NONMAPREDUCE_647221885_1
2014-05-05 12:26:44,319 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 13 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 6781 
2014-05-05 12:26:44,390 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-664678693-10.0.0.195-1399292316143 blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:26:46,427 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:26:46,427 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:26:46,429 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:26:46,430 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:26:46,437 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-664678693-10.0.0.195-1399292316143 blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:26:47,806 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:26:47,807 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:26:47,808 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:26:47,812 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:26:47,814 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-664678693-10.0.0.195-1399292316143 blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:26:49,057 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:26:49,058 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:26:49,059 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:26:49,062 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-664678693-10.0.0.195-1399292316143 blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]}
2014-05-05 12:26:49,064 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741829_1005 size 134217728
2014-05-05 12:26:49,770 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:26:49,773 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:26:49,774 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:26:49,775 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:26:49,790 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /in1m/data._COPYING_ is closed by DFSClient_NONMAPREDUCE_2019322955_1
2014-05-05 12:27:54,548 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 32 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 0 Number of syncs: 10 SyncTimes(ms): 6807 
2014-05-05 12:27:54,709 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job.jar. BP-664678693-10.0.0.195-1399292316143 blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:27:55,239 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:27:55,240 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:27:55,241 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:27:55,243 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:27:55,249 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-1276595827_1
2014-05-05 12:27:55,258 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job.jar
2014-05-05 12:27:55,366 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job.split
2014-05-05 12:27:55,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job.split. BP-664678693-10.0.0.195-1399292316143 blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 12:27:55,562 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:27:55,563 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:27:55,564 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:27:55,566 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:27:55,567 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:27:55,569 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:27:55,570 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:27:55,573 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:27:55,576 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job.split is closed by DFSClient_NONMAPREDUCE_-1276595827_1
2014-05-05 12:27:55,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job.splitmetainfo. BP-664678693-10.0.0.195-1399292316143 blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:27:55,597 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:27:55,599 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:27:55,600 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:27:55,601 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:27:55,606 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1276595827_1
2014-05-05 12:27:55,908 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job.xml. BP-664678693-10.0.0.195-1399292316143 blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:27:55,924 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:27:55,925 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:27:55,926 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:27:55,929 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:27:55,933 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-1276595827_1
2014-05-05 12:27:56,203 INFO BlockStateChange: BLOCK* ask 10.0.0.193:50010 to replicate blk_1073741831_1007 to datanode(s) 10.0.0.196:50010 10.0.0.199:50010 10.0.0.200:50010 10.0.0.197:50010
2014-05-05 12:28:01,564 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741831_1007 size 39460542
2014-05-05 12:28:01,569 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741831_1007 size 39460542
2014-05-05 12:28:01,570 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741831_1007 size 39460542
2014-05-05 12:28:01,570 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741831_1007 size 39460542
2014-05-05 12:28:04,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job_1399292339232_0001_1_conf.xml. BP-664678693-10.0.0.195-1399292316143 blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:28:04,430 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:28:04,432 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:28:04,433 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:28:04,433 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:28:04,448 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job_1399292339232_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1256809563_1
2014-05-05 12:28:37,701 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job_1399292339232_0001_1.jhist. BP-664678693-10.0.0.195-1399292316143 blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:28:37,722 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job_1399292339232_0001_1.jhist for DFSClient_NONMAPREDUCE_-1256809563_1
2014-05-05 12:31:53,129 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 76 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 35 SyncTimes(ms): 6869 
2014-05-05 12:31:53,138 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1256809563_1
2014-05-05 12:31:53,143 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1256809563_1
2014-05-05 12:31:53,159 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:31:53,160 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:31:53,162 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:31:53,163 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:31:53,166 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0001/job_1399292339232_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_-1256809563_1
2014-05-05 12:31:53,172 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0001.summary_tmp. BP-664678693-10.0.0.195-1399292316143 blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 12:31:53,185 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 12:31:53,187 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 12:31:53,188 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 12:31:53,189 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 12:31:53,191 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1256809563_1
2014-05-05 12:31:53,212 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0001-1399292876184-ubuntu-hints%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399293113143-4-8-SUCCEEDED-default.jhist_tmp. BP-664678693-10.0.0.195-1399292316143 blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 12:31:53,229 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:31:53,230 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:31:53,231 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:31:53,232 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:31:53,236 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0001-1399292876184-ubuntu-hints%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399293113143-4-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1256809563_1
2014-05-05 12:31:53,258 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0001_conf.xml_tmp. BP-664678693-10.0.0.195-1399292316143 blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:31:53,293 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:31:53,294 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:31:53,296 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:31:53,299 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741839_1015 size 191091
2014-05-05 12:31:53,301 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1256809563_1
2014-05-05 12:31:54,348 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741831_1007 10.0.0.195:50010 10.0.0.198:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.196:50010 10.0.0.199:50010 10.0.0.197:50010 10.0.0.200:50010 
2014-05-05 12:31:54,348 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741832_1008 10.0.0.195:50010 10.0.0.193:50010 10.0.0.196:50010 10.0.0.200:50010 10.0.0.198:50010 10.0.0.199:50010 10.0.0.194:50010 10.0.0.197:50010 
2014-05-05 12:31:54,348 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741833_1009 10.0.0.195:50010 10.0.0.199:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 12:31:54,348 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741834_1010 10.0.0.195:50010 10.0.0.193:50010 10.0.0.199:50010 10.0.0.198:50010 
2014-05-05 12:31:54,348 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741836_1012 10.0.0.199:50010 10.0.0.200:50010 10.0.0.197:50010 10.0.0.198:50010 
2014-05-05 12:31:54,348 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741835_1011 10.0.0.199:50010 10.0.0.194:50010 10.0.0.197:50010 10.0.0.198:50010 
2014-05-05 12:31:56,237 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741831_1007, blk_1073741832_1008, blk_1073741833_1009, blk_1073741834_1010]
2014-05-05 12:31:56,238 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.197:50010 to delete [blk_1073741831_1007, blk_1073741832_1008, blk_1073741835_1011, blk_1073741836_1012]
2014-05-05 12:31:56,238 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741831_1007, blk_1073741832_1008, blk_1073741836_1012]
2014-05-05 12:31:59,238 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741831_1007, blk_1073741832_1008, blk_1073741833_1009, blk_1073741834_1010]
2014-05-05 12:31:59,238 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.198:50010 to delete [blk_1073741831_1007, blk_1073741832_1008, blk_1073741834_1010, blk_1073741835_1011, blk_1073741836_1012]
2014-05-05 12:31:59,238 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741831_1007, blk_1073741832_1008, blk_1073741833_1009, blk_1073741835_1011]
2014-05-05 12:32:02,239 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.199:50010 to delete [blk_1073741831_1007, blk_1073741832_1008, blk_1073741833_1009, blk_1073741834_1010, blk_1073741835_1011, blk_1073741836_1012]
2014-05-05 12:32:02,239 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.196:50010 to delete [blk_1073741831_1007, blk_1073741832_1008]
2014-05-05 12:34:26,457 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 103 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 53 SyncTimes(ms): 6897 
2014-05-05 12:34:26,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job.jar. BP-664678693-10.0.0.195-1399292316143 blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 12:34:27,154 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:34:27,155 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:34:27,156 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:34:27,158 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:34:27,164 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job.jar is closed by DFSClient_NONMAPREDUCE_1528726518_1
2014-05-05 12:34:27,169 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job.jar
2014-05-05 12:34:27,231 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job.split
2014-05-05 12:34:27,242 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 12:34:27,242 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job.split. BP-664678693-10.0.0.195-1399292316143 blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 12:34:27,266 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:34:27,268 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:34:27,268 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:34:27,269 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:34:27,270 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:34:27,271 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:34:27,272 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:34:27,275 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job.split is closed by DFSClient_NONMAPREDUCE_1528726518_1
2014-05-05 12:34:27,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job.splitmetainfo. BP-664678693-10.0.0.195-1399292316143 blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]}
2014-05-05 12:34:27,296 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:34:27,297 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:34:27,298 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:34:27,299 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:34:27,302 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1528726518_1
2014-05-05 12:34:27,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job.xml. BP-664678693-10.0.0.195-1399292316143 blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:34:27,593 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:34:27,595 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:34:27,595 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:34:27,597 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:34:27,599 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job.xml is closed by DFSClient_NONMAPREDUCE_1528726518_1
2014-05-05 12:34:29,249 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 12:34:29,249 INFO BlockStateChange: BLOCK* ask 10.0.0.199:50010 to replicate blk_1073741840_1016 to datanode(s) 10.0.0.198:50010 10.0.0.200:50010 10.0.0.197:50010 10.0.0.193:50010
2014-05-05 12:34:33,227 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741840_1016 size 39460499
2014-05-05 12:34:33,228 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741840_1016 size 39460499
2014-05-05 12:34:33,230 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741840_1016 size 39460499
2014-05-05 12:34:33,232 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741840_1016 size 39460499
2014-05-05 12:34:34,327 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job_1399292339232_0002_1_conf.xml. BP-664678693-10.0.0.195-1399292316143 blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:34:34,510 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:34:34,511 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:34:34,512 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:34:34,514 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:34:34,520 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job_1399292339232_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-209084124_1
2014-05-05 12:34:35,250 INFO BlockStateChange: BLOCK* ask 10.0.0.197:50010 to replicate blk_1073741841_1017 to datanode(s) 10.0.0.194:50010
2014-05-05 12:34:36,818 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741841_1017 size 559
2014-05-05 12:34:57,041 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job_1399292339232_0002_1.jhist. BP-664678693-10.0.0.195-1399292316143 blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]}
2014-05-05 12:34:57,057 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job_1399292339232_0002_1.jhist for DFSClient_NONMAPREDUCE_-209084124_1
2014-05-05 12:39:07,903 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:39:07,904 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:39:07,906 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:39:07,907 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW]]} size 0
2014-05-05 12:39:07,909 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 141 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 0 Number of syncs: 73 SyncTimes(ms): 7186 
2014-05-05 12:39:07,910 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0002/job_1399292339232_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_-209084124_1
2014-05-05 12:39:07,917 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0002.summary_tmp. BP-664678693-10.0.0.195-1399292316143 blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 12:39:07,935 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:39:07,937 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:39:07,938 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:39:07,939 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:39:07,942 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_-209084124_1
2014-05-05 12:39:07,967 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0002-1399293267778-ubuntu-base%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399293547688-4-2-FAILED-default.jhist_tmp. BP-664678693-10.0.0.195-1399292316143 blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]}
2014-05-05 12:39:07,986 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:39:07,987 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:39:07,988 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:39:07,989 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW]]} size 0
2014-05-05 12:39:07,992 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0002-1399293267778-ubuntu-base%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399293547688-4-2-FAILED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-209084124_1
2014-05-05 12:39:08,008 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0002_conf.xml_tmp. BP-664678693-10.0.0.195-1399292316143 blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 12:39:08,021 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:39:08,023 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:39:08,025 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:39:08,026 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:39:08,034 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-209084124_1
2014-05-05 12:39:09,066 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741840_1016 10.0.0.195:50010 10.0.0.199:50010 10.0.0.196:50010 10.0.0.194:50010 10.0.0.198:50010 10.0.0.200:50010 10.0.0.197:50010 10.0.0.193:50010 
2014-05-05 12:39:09,066 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741841_1017 10.0.0.195:50010 10.0.0.199:50010 10.0.0.196:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.198:50010 10.0.0.197:50010 10.0.0.194:50010 
2014-05-05 12:39:09,066 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741842_1018 10.0.0.195:50010 10.0.0.198:50010 10.0.0.196:50010 10.0.0.199:50010 
2014-05-05 12:39:09,066 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741843_1019 10.0.0.195:50010 10.0.0.200:50010 10.0.0.197:50010 10.0.0.193:50010 
2014-05-05 12:39:09,066 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741845_1021 10.0.0.193:50010 10.0.0.194:50010 10.0.0.198:50010 10.0.0.199:50010 
2014-05-05 12:39:09,066 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741844_1020 10.0.0.193:50010 10.0.0.200:50010 10.0.0.197:50010 10.0.0.198:50010 
2014-05-05 12:39:11,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741843_1019, blk_1073741844_1020, blk_1073741845_1021]
2014-05-05 12:39:11,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.199:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741842_1018, blk_1073741845_1021]
2014-05-05 12:39:11,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.198:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741842_1018, blk_1073741844_1020, blk_1073741845_1021]
2014-05-05 12:39:14,283 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.196:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741842_1018]
2014-05-05 12:39:14,284 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741843_1019, blk_1073741844_1020]
2014-05-05 12:39:14,284 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741842_1018, blk_1073741843_1019]
2014-05-05 12:39:17,284 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.197:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741843_1019, blk_1073741844_1020]
2014-05-05 12:39:17,284 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741845_1021]
2014-05-05 12:44:40,391 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 164 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 0 Number of syncs: 87 SyncTimes(ms): 7213 
2014-05-05 12:44:40,476 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job.jar. BP-664678693-10.0.0.195-1399292316143 blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 12:44:41,010 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:44:41,011 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:44:41,012 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:44:41,014 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:44:41,025 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job.jar is closed by DFSClient_NONMAPREDUCE_-1163183949_1
2014-05-05 12:44:41,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job.jar
2014-05-05 12:44:41,149 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job.split
2014-05-05 12:44:41,158 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job.split. BP-664678693-10.0.0.195-1399292316143 blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]}
2014-05-05 12:44:41,185 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:44:41,186 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:44:41,187 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:44:41,188 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:44:41,189 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:44:41,190 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:44:41,191 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:44:41,193 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.199:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW]]} size 0
2014-05-05 12:44:41,197 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job.split is closed by DFSClient_NONMAPREDUCE_-1163183949_1
2014-05-05 12:44:41,206 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job.splitmetainfo. BP-664678693-10.0.0.195-1399292316143 blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 12:44:41,229 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:44:41,230 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:44:41,231 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:44:41,233 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:44:41,236 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1163183949_1
2014-05-05 12:44:41,306 INFO BlockStateChange: BLOCK* ask 10.0.0.193:50010 to replicate blk_1073741849_1025 to datanode(s) 10.0.0.196:50010 10.0.0.198:50010 10.0.0.197:50010 10.0.0.199:50010
2014-05-05 12:44:41,493 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job.xml. BP-664678693-10.0.0.195-1399292316143 blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]}
2014-05-05 12:44:41,509 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:44:41,510 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:44:41,511 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:44:41,513 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW]]} size 0
2014-05-05 12:44:41,515 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job.xml is closed by DFSClient_NONMAPREDUCE_-1163183949_1
2014-05-05 12:44:45,430 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741849_1025 size 39460499
2014-05-05 12:44:45,430 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741849_1025 size 39460499
2014-05-05 12:44:45,430 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.199:50010 is added to blk_1073741849_1025 size 39460499
2014-05-05 12:44:45,431 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741849_1025 size 39460499
2014-05-05 12:44:48,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job_1399292339232_0003_1_conf.xml. BP-664678693-10.0.0.195-1399292316143 blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 12:44:48,179 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:44:48,180 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:44:48,181 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:44:48,182 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:44:48,188 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job_1399292339232_0003_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1846535681_1
2014-05-05 12:45:11,801 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job_1399292339232_0003_1.jhist. BP-664678693-10.0.0.195-1399292316143 blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 12:45:11,816 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job_1399292339232_0003_1.jhist for DFSClient_NONMAPREDUCE_-1846535681_1
2014-05-05 12:49:13,193 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 202 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 0 Number of syncs: 107 SyncTimes(ms): 8467 
2014-05-05 12:49:13,203 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1846535681_1
2014-05-05 12:49:13,208 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1846535681_1
2014-05-05 12:49:13,237 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:49:13,238 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:49:13,239 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:49:13,241 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 12:49:13,247 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399292339232_0003/job_1399292339232_0003_1.jhist is closed by DFSClient_NONMAPREDUCE_-1846535681_1
2014-05-05 12:49:13,252 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0003.summary_tmp. BP-664678693-10.0.0.195-1399292316143 blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 12:49:13,264 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:49:13,268 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:49:13,269 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:49:13,269 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 12:49:13,291 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0003.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1846535681_1
2014-05-05 12:49:13,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0003-1399293881698-ubuntu-base%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399294153208-4-8-SUCCEEDED-default.jhist_tmp. BP-664678693-10.0.0.195-1399292316143 blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 12:49:13,327 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 12:49:13,328 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.196:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 12:49:13,329 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 12:49:13,330 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.196:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 12:49:13,334 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0003-1399293881698-ubuntu-base%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399294153208-4-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1846535681_1
2014-05-05 12:49:13,374 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0003_conf.xml_tmp. BP-664678693-10.0.0.195-1399292316143 blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 12:49:13,389 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:49:13,391 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:49:13,392 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.197:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:49:13,393 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.198:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.198:50010|RBW], ReplicaUnderConstruction[10.0.0.197:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 12:49:13,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399292339232_0003_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1846535681_1
2014-05-05 12:49:14,449 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741849_1025 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.196:50010 10.0.0.198:50010 10.0.0.199:50010 10.0.0.197:50010 
2014-05-05 12:49:14,449 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741850_1026 10.0.0.195:50010 10.0.0.194:50010 10.0.0.198:50010 10.0.0.196:50010 10.0.0.199:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.197:50010 
2014-05-05 12:49:14,449 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741851_1027 10.0.0.195:50010 10.0.0.193:50010 10.0.0.196:50010 10.0.0.194:50010 
2014-05-05 12:49:14,449 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741852_1028 10.0.0.195:50010 10.0.0.200:50010 10.0.0.197:50010 10.0.0.196:50010 
2014-05-05 12:49:14,449 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741854_1030 10.0.0.198:50010 10.0.0.194:50010 10.0.0.197:50010 10.0.0.193:50010 
2014-05-05 12:49:14,449 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741853_1029 10.0.0.198:50010 10.0.0.196:50010 10.0.0.197:50010 10.0.0.194:50010 
2014-05-05 12:49:17,342 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741849_1025, blk_1073741850_1026, blk_1073741852_1028]
2014-05-05 12:49:17,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.199:50010 to delete [blk_1073741849_1025, blk_1073741850_1026]
2014-05-05 12:49:17,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741849_1025, blk_1073741850_1026, blk_1073741851_1027, blk_1073741854_1030]
2014-05-05 12:49:20,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741849_1025, blk_1073741850_1026, blk_1073741851_1027, blk_1073741852_1028]
2014-05-05 12:49:20,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.196:50010 to delete [blk_1073741849_1025, blk_1073741850_1026, blk_1073741851_1027, blk_1073741852_1028, blk_1073741853_1029]
2014-05-05 12:49:20,343 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.198:50010 to delete [blk_1073741849_1025, blk_1073741850_1026, blk_1073741853_1029, blk_1073741854_1030]
2014-05-05 12:49:23,344 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.197:50010 to delete [blk_1073741849_1025, blk_1073741850_1026, blk_1073741852_1028, blk_1073741853_1029, blk_1073741854_1030]
2014-05-05 12:49:23,344 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741849_1025, blk_1073741850_1026, blk_1073741851_1027, blk_1073741853_1029, blk_1073741854_1030]
2014-05-05 12:52:50,437 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 12:52:50,439 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 12:58:25,104 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-2.2.0/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'Joey' on 2014-03-24T00:00Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 12:58:25,113 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 12:58:25,410 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 12:58:25,522 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 12:58:25,522 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 12:58:26,102 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 12:58:26,172 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 12:58:26,175 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 12:58:26,176 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 12:58:26,176 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 12:58:26,217 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 12:58:26,255 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 12:58:26,255 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 12:58:26,704 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 12:58:26,704 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 12:58:26,739 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 12:58:26,739 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 12:58:26,819 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 12:58:26,819 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 12:58:26,823 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 12:58:26,826 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 12:58:26,827 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 12:58:26,827 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2014-05-05 12:58:26,828 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2014-05-05 12:58:26,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 12:58:26,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 12:58:26,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 12:58:26,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 12:58:26,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 12:58:26,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 12:58:26,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 12:58:26,835 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 12:58:26,845 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 12:58:26,845 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 12:58:26,845 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 12:58:26,845 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 12:58:26,847 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 12:58:26,909 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 12:58:26,909 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 12:58:26,909 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2014-05-05 12:58:26,909 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2014-05-05 12:58:26,911 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 12:58:26,915 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 12:58:26,915 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 12:58:26,915 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 12:58:26,917 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 12:58:26,917 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 12:58:26,926 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 12:58:26,926 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 12:58:26,926 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2014-05-05 12:58:26,926 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2014-05-05 12:58:26,947 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 25671@ip-10-0-0-195
2014-05-05 12:58:27,037 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 12:58:27,040 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2014-05-05 12:58:27,055 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000 using no compression
2014-05-05 12:58:27,055 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 1
2014-05-05 12:58:27,062 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2014-05-05 12:58:27,063 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000 of size 198 bytes loaded in 0 seconds.
2014-05-05 12:58:27,063 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000
2014-05-05 12:58:27,070 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2014-05-05 12:58:27,191 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 12:58:27,191 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 262 msecs
2014-05-05 12:58:27,473 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 12:58:27,491 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 12:58:27,544 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 12:58:27,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 12:58:27,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 12:58:27,557 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2014-05-05 12:58:27,565 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2014-05-05 12:58:27,565 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2014-05-05 12:58:27,565 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2014-05-05 12:58:27,565 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2014-05-05 12:58:27,565 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2014-05-05 12:58:27,565 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2014-05-05 12:58:27,565 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2014-05-05 12:58:27,565 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2014-05-05 12:58:27,565 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2014-05-05 12:58:27,595 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 12:58:27,596 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 12:58:27,599 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 12:58:27,599 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 12:58:32,348 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-289703120-10.0.0.194-50010-1399294712058, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-289703120-10.0.0.194-50010-1399294712058
2014-05-05 12:58:32,351 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 12:58:32,352 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1004147253-10.0.0.195-50010-1399294712032, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-1004147253-10.0.0.195-50010-1399294712032
2014-05-05 12:58:32,360 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 12:58:32,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-445834928-10.0.0.193-50010-1399294712039, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-445834928-10.0.0.193-50010-1399294712039
2014-05-05 12:58:32,374 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 12:58:32,410 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-479534094-10.0.0.200-50010-1399294712104, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-479534094-10.0.0.200-50010-1399294712104
2014-05-05 12:58:32,410 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 12:58:32,475 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:58:32,475 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-289703120-10.0.0.194-50010-1399294712058, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 2 msecs
2014-05-05 12:58:32,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:58:32,477 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1004147253-10.0.0.195-50010-1399294712032, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:58:32,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:58:32,510 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-479534094-10.0.0.200-50010-1399294712104, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:58:32,531 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 12:58:32,531 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-445834928-10.0.0.193-50010-1399294712039, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 12:59:37,674 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 12:59:37,674 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 12:59:37,674 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2014-05-05 12:59:37,674 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 33 
2014-05-05 12:59:37,675 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 34 
2014-05-05 12:59:37,676 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000001 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000001-0000000000000000002
2014-05-05 12:59:37,676 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2014-05-05 12:59:38,383 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=2&storageInfo=-47:182241533:0:CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32
2014-05-05 12:59:38,567 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.18s at 0.00 KB/s
2014-05-05 12:59:38,567 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 198 bytes.
2014-05-05 12:59:38,576 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2014-05-05 13:00:24,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0001/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:00:25,194 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:00:25,197 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:00:25,200 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:00:25,205 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:00:25,217 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-2043780954_1
2014-05-05 13:00:25,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0001/job.jar
2014-05-05 13:00:25,258 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741825_1001 10.0.0.195:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.200:50010 
2014-05-05 13:00:27,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741825_1001]
2014-05-05 13:00:27,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741825_1001]
2014-05-05 13:00:30,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741825_1001]
2014-05-05 13:00:30,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741825_1001]
2014-05-05 13:00:44,413 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 17 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 10 SyncTimes(ms): 59 
2014-05-05 13:00:59,044 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:01:01,267 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:01:01,269 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:01:01,271 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:01:01,275 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:01:01,276 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741826_1002 size 134217728
2014-05-05 13:01:02,781 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:01:02,781 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:01:02,783 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:01:02,785 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:01:02,790 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:01:04,088 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:01:04,088 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:01:04,092 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:01:04,093 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:01:04,094 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741828_1004 size 134217728
2014-05-05 13:01:04,574 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:01:04,575 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:01:04,578 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:01:04,578 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:01:04,582 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /in1m/data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1662554258_1
2014-05-05 13:01:44,767 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 34 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 15 SyncTimes(ms): 4381 
2014-05-05 13:01:45,182 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:01:51,702 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:01:51,702 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:01:51,703 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:01:51,705 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:01:51,712 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job.jar is closed by DFSClient_NONMAPREDUCE_-41843139_1
2014-05-05 13:01:51,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job.jar
2014-05-05 13:01:51,807 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job.split
2014-05-05 13:01:51,818 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:01:51,831 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:01:51,832 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:01:51,833 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:01:51,834 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741831_1007{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:01:51,837 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job.split is closed by DFSClient_NONMAPREDUCE_-41843139_1
2014-05-05 13:01:51,846 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:01:51,859 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:01:51,864 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:01:51,864 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:01:51,865 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741832_1008{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:01:51,867 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-41843139_1
2014-05-05 13:01:52,123 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:01:52,147 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:01:52,147 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:01:52,149 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:01:52,150 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741833_1009{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:01:52,154 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job.xml is closed by DFSClient_NONMAPREDUCE_-41843139_1
2014-05-05 13:02:00,329 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job_1399294722688_0002_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:02:00,442 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:02:00,443 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:02:00,444 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:02:00,446 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741834_1010{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:02:00,455 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job_1399294722688_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_546488131_1
2014-05-05 13:02:26,012 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 4
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 13:02:26,013 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job_1399294722688_0002_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:02:26,029 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job_1399294722688_0002_1.jhist for DFSClient_NONMAPREDUCE_546488131_1
2014-05-05 13:05:31,825 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 76 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 38 SyncTimes(ms): 6098 
2014-05-05 13:05:31,831 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_546488131_1
2014-05-05 13:05:31,837 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_546488131_1
2014-05-05 13:05:31,862 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:05:31,864 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:05:31,865 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741835_1011{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:05:31,870 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0002/job_1399294722688_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_546488131_1
2014-05-05 13:05:31,876 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0002.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:05:31,889 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:05:31,889 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:05:31,890 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:05:31,891 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741836_1012{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:05:31,895 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_546488131_1
2014-05-05 13:05:31,927 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0002-1399294912369-ubuntu-base%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A4-1399295131838-4-4-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:05:31,948 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:05:31,948 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:05:31,949 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:05:31,951 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741837_1013{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:05:31,954 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0002-1399294912369-ubuntu-base%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A4-1399295131838-4-4-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_546488131_1
2014-05-05 13:05:31,971 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0002_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:05:31,983 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:05:31,984 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:05:31,985 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:05:31,986 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741838_1014{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:05:31,989 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_546488131_1
2014-05-05 13:05:33,047 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741830_1006 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 13:05:33,047 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741831_1007 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 13:05:33,047 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741832_1008 10.0.0.193:50010 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 13:05:33,048 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741833_1009 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 13:05:33,048 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741835_1011 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:05:33,048 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741834_1010 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 13:05:33,629 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741830_1006, blk_1073741831_1007, blk_1073741832_1008, blk_1073741833_1009, blk_1073741834_1010, blk_1073741835_1011]
2014-05-05 13:05:33,630 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741830_1006, blk_1073741831_1007, blk_1073741832_1008, blk_1073741833_1009, blk_1073741834_1010]
2014-05-05 13:05:36,630 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741830_1006, blk_1073741831_1007, blk_1073741832_1008, blk_1073741833_1009, blk_1073741834_1010, blk_1073741835_1011]
2014-05-05 13:05:36,630 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741830_1006, blk_1073741831_1007, blk_1073741832_1008, blk_1073741833_1009, blk_1073741834_1010, blk_1073741835_1011]
2014-05-05 13:07:47,917 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 103 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 56 SyncTimes(ms): 6129 
2014-05-05 13:07:59,536 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /100k/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:08:00,390 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:08:00,391 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:08:00,394 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:08:00,395 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741839_1015{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:08:00,400 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /100k/data._COPYING_ is closed by DFSClient_NONMAPREDUCE_1772400941_1
2014-05-05 13:08:36,645 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:08:37,224 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:08:37,359 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:08:37,360 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741840_1016{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:08:37,367 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741840_1016 size 39460499
2014-05-05 13:08:37,367 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job.jar is closed by DFSClient_NONMAPREDUCE_-127694902_1
2014-05-05 13:08:37,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job.jar
2014-05-05 13:08:37,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job.split
2014-05-05 13:08:37,436 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:08:37,456 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:08:37,457 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:08:37,458 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:08:37,459 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741841_1017{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:08:37,462 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job.split is closed by DFSClient_NONMAPREDUCE_-127694902_1
2014-05-05 13:08:37,470 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:08:37,481 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:08:37,482 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:08:37,483 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:08:37,484 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741842_1018{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:08:37,487 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-127694902_1
2014-05-05 13:08:37,748 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:08:37,767 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:08:37,768 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:08:37,769 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:08:37,770 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741843_1019{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:08:37,773 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job.xml is closed by DFSClient_NONMAPREDUCE_-127694902_1
2014-05-05 13:08:43,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job_1399294722688_0003_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:08:43,575 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:08:43,576 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:08:43,576 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:08:43,578 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741844_1020{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:08:43,594 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job_1399294722688_0003_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1086563804_1
2014-05-05 13:08:51,244 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job_1399294722688_0003_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:08:51,257 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job_1399294722688_0003_1.jhist for DFSClient_NONMAPREDUCE_1086563804_1
2014-05-05 13:08:51,258 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 147 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 0 Number of syncs: 79 SyncTimes(ms): 6158 
2014-05-05 13:09:15,223 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1086563804_1
2014-05-05 13:09:15,230 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1086563804_1
2014-05-05 13:09:15,258 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:09:15,259 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:09:15,261 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:09:15,262 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741845_1021{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:09:15,264 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0003/job_1399294722688_0003_1.jhist is closed by DFSClient_NONMAPREDUCE_1086563804_1
2014-05-05 13:09:15,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0003.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:09:15,281 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:09:15,283 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:09:15,284 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:09:15,285 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741846_1022{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:09:15,303 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0003.summary_tmp is closed by DFSClient_NONMAPREDUCE_1086563804_1
2014-05-05 13:09:15,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0003-1399295317958-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A4-1399295355230-1-4-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:09:15,350 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:09:15,351 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:09:15,351 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:09:15,352 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741847_1023{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:09:15,354 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0003-1399295317958-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A4-1399295355230-1-4-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1086563804_1
2014-05-05 13:09:15,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0003_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:09:15,380 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:09:15,381 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:09:15,382 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:09:15,383 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741848_1024{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:09:15,385 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0003_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1086563804_1
2014-05-05 13:09:16,414 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741840_1016 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.195:50010 
2014-05-05 13:09:16,414 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741841_1017 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:09:16,414 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741842_1018 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 13:09:16,415 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741843_1019 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:09:16,415 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741845_1021 10.0.0.193:50010 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 13:09:16,415 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741844_1020 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.195:50010 
2014-05-05 13:09:18,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741842_1018, blk_1073741843_1019, blk_1073741844_1020, blk_1073741845_1021]
2014-05-05 13:09:18,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741842_1018, blk_1073741843_1019, blk_1073741844_1020, blk_1073741845_1021]
2014-05-05 13:09:21,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741842_1018, blk_1073741843_1019, blk_1073741844_1020, blk_1073741845_1021]
2014-05-05 13:09:21,647 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741840_1016, blk_1073741841_1017, blk_1073741842_1018, blk_1073741843_1019, blk_1073741844_1020, blk_1073741845_1021]
2014-05-05 13:10:17,547 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 175 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 0 Number of syncs: 98 SyncTimes(ms): 6194 
2014-05-05 13:10:38,569 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741846_1022 10.0.0.193:50010 10.0.0.194:50010 10.0.0.195:50010 10.0.0.200:50010 
2014-05-05 13:10:38,571 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741836_1012 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 13:10:39,652 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741846_1022, blk_1073741836_1012]
2014-05-05 13:10:39,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741846_1022, blk_1073741836_1012]
2014-05-05 13:10:42,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741846_1022, blk_1073741836_1012]
2014-05-05 13:10:42,653 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741846_1022, blk_1073741836_1012]
2014-05-05 13:12:58,672 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 186 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 1 Number of syncs: 106 SyncTimes(ms): 6214 
2014-05-05 13:12:58,765 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0004/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741849_1025{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:13:33,368 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:13:34,000 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:13:34,001 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:13:34,003 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:13:34,004 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741850_1026{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:13:34,011 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job.jar is closed by DFSClient_NONMAPREDUCE_-1222243437_1
2014-05-05 13:13:34,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job.jar
2014-05-05 13:13:34,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job.split
2014-05-05 13:13:34,083 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:13:34,111 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:13:34,111 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:13:34,112 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:13:34,115 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741851_1027{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:13:34,117 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job.split is closed by DFSClient_NONMAPREDUCE_-1222243437_1
2014-05-05 13:13:34,127 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:13:34,139 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:13:34,140 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:13:34,140 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:13:34,141 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741852_1028{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:13:34,170 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1222243437_1
2014-05-05 13:13:34,425 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:13:34,470 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:13:34,471 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:13:34,472 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:13:34,473 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741853_1029{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:13:34,476 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job.xml is closed by DFSClient_NONMAPREDUCE_-1222243437_1
2014-05-05 13:13:40,649 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job_1399294722688_0005_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:13:40,789 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:13:40,790 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:13:40,790 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:13:40,792 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741854_1030{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:13:40,813 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job_1399294722688_0005_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1783533516_1
2014-05-05 13:13:48,312 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job_1399294722688_0005_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:13:48,328 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job_1399294722688_0005_1.jhist for DFSClient_NONMAPREDUCE_-1783533516_1
2014-05-05 13:14:10,129 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 230 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 1 Number of syncs: 129 SyncTimes(ms): 8133 
2014-05-05 13:14:10,402 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1783533516_1
2014-05-05 13:14:10,407 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1783533516_1
2014-05-05 13:14:10,427 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:14:10,428 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:14:10,430 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:14:10,432 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741855_1031{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:14:10,435 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0005/job_1399294722688_0005_1.jhist is closed by DFSClient_NONMAPREDUCE_-1783533516_1
2014-05-05 13:14:10,440 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0005.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:14:10,452 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:14:10,453 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:14:10,454 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:14:10,455 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741856_1032{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:14:10,532 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0005.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1783533516_1
2014-05-05 13:14:10,563 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0005-1399295614665-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A4-1399295650408-1-4-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:14:10,576 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:14:10,577 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:14:10,579 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:14:10,580 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741857_1033{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:14:10,583 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0005-1399295614665-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A4-1399295650408-1-4-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1783533516_1
2014-05-05 13:14:10,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0005_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:14:10,609 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:14:10,610 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:14:10,611 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:14:10,612 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741858_1034{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:14:10,615 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0005_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1783533516_1
2014-05-05 13:14:11,651 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741850_1026 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:14:11,652 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741851_1027 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 13:14:11,652 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741852_1028 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 13:14:11,652 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741853_1029 10.0.0.195:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.200:50010 
2014-05-05 13:14:11,652 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741855_1031 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 13:14:11,652 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741854_1030 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 13:14:12,668 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741850_1026, blk_1073741851_1027, blk_1073741852_1028, blk_1073741853_1029, blk_1073741854_1030, blk_1073741855_1031]
2014-05-05 13:14:12,669 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741850_1026, blk_1073741851_1027, blk_1073741852_1028, blk_1073741853_1029, blk_1073741854_1030, blk_1073741855_1031]
2014-05-05 13:14:15,669 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741850_1026, blk_1073741851_1027, blk_1073741852_1028, blk_1073741853_1029, blk_1073741854_1030, blk_1073741855_1031]
2014-05-05 13:14:16,070 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741850_1026, blk_1073741851_1027, blk_1073741852_1028, blk_1073741853_1029, blk_1073741854_1030, blk_1073741855_1031]
2014-05-05 13:16:17,724 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 257 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 1 Number of syncs: 147 SyncTimes(ms): 8488 
2014-05-05 13:16:17,726 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741856_1032 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:16:19,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741856_1032]
2014-05-05 13:16:19,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741856_1032]
2014-05-05 13:16:22,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741856_1032]
2014-05-05 13:16:22,078 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741856_1032]
2014-05-05 13:23:09,097 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 260 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 1 Number of syncs: 150 SyncTimes(ms): 8490 
2014-05-05 13:23:09,180 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:23:09,734 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:23:09,735 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:23:09,737 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741859_1035{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:23:09,743 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job.jar is closed by DFSClient_NONMAPREDUCE_1240066431_1
2014-05-05 13:23:09,757 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job.jar
2014-05-05 13:23:09,757 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741859_1035 size 39460499
2014-05-05 13:23:10,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job.split
2014-05-05 13:23:10,428 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:23:10,440 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:10,442 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:10,443 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:10,444 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741860_1036{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:10,447 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job.split is closed by DFSClient_NONMAPREDUCE_1240066431_1
2014-05-05 13:23:10,455 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:23:10,465 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:10,466 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:10,467 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:10,468 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741861_1037{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:10,475 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1240066431_1
2014-05-05 13:23:10,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741862_1038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:23:10,749 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741862_1038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:23:10,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741862_1038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:23:10,753 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741862_1038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:23:10,754 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741862_1038{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:23:10,757 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job.xml is closed by DFSClient_NONMAPREDUCE_1240066431_1
2014-05-05 13:23:17,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job_1399294722688_0006_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741863_1039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:23:17,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741863_1039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:17,752 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741863_1039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:17,753 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741863_1039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:17,754 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741863_1039{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:17,760 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job_1399294722688_0006_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-889237896_1
2014-05-05 13:23:24,877 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job_1399294722688_0006_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741864_1040{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:23:24,898 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job_1399294722688_0006_1.jhist for DFSClient_NONMAPREDUCE_-889237896_1
2014-05-05 13:23:51,900 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-889237896_1
2014-05-05 13:23:51,908 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-889237896_1
2014-05-05 13:23:51,928 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741864_1040{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:23:51,929 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741864_1040{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:23:51,930 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741864_1040{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:23:51,932 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741864_1040{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:23:51,963 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0006/job_1399294722688_0006_1.jhist is closed by DFSClient_NONMAPREDUCE_-889237896_1
2014-05-05 13:23:52,005 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0006.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741865_1041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:23:52,018 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741865_1041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:52,019 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741865_1041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:52,020 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741865_1041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:52,021 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741865_1041{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:52,024 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0006.summary_tmp is closed by DFSClient_NONMAPREDUCE_-889237896_1
2014-05-05 13:23:52,060 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0006-1399296190937-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399296231911-1-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:23:52,072 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:52,073 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:52,074 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:52,075 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741866_1042{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:23:52,078 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0006-1399296190937-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399296231911-1-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-889237896_1
2014-05-05 13:23:52,092 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0006_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:23:52,104 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:23:52,107 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:23:52,107 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:23:52,108 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741867_1043{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:23:52,109 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0006_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-889237896_1
2014-05-05 13:23:53,148 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741859_1035 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.195:50010 
2014-05-05 13:23:53,149 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741860_1036 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 13:23:53,149 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741861_1037 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 13:23:53,149 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741862_1038 10.0.0.194:50010 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 13:23:53,149 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741864_1040 10.0.0.194:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.195:50010 
2014-05-05 13:23:53,149 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741863_1039 10.0.0.194:50010 10.0.0.193:50010 10.0.0.195:50010 10.0.0.200:50010 
2014-05-05 13:23:55,110 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741859_1035, blk_1073741860_1036, blk_1073741861_1037, blk_1073741862_1038, blk_1073741863_1039, blk_1073741864_1040]
2014-05-05 13:23:55,110 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741859_1035, blk_1073741860_1036, blk_1073741861_1037, blk_1073741862_1038, blk_1073741863_1039, blk_1073741864_1040]
2014-05-05 13:23:58,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741859_1035, blk_1073741860_1036, blk_1073741861_1037, blk_1073741862_1038, blk_1073741863_1039, blk_1073741864_1040]
2014-05-05 13:23:58,111 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741859_1035, blk_1073741860_1036, blk_1073741861_1037, blk_1073741862_1038, blk_1073741863_1039, blk_1073741864_1040]
2014-05-05 13:24:58,868 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 325 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 1 Number of syncs: 188 SyncTimes(ms): 9212 
2014-05-05 13:24:58,973 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:24:59,585 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:24:59,586 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:24:59,588 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:24:59,588 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741868_1044{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:24:59,596 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job.jar is closed by DFSClient_NONMAPREDUCE_-619210831_1
2014-05-05 13:24:59,601 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job.jar
2014-05-05 13:24:59,682 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job.split
2014-05-05 13:24:59,698 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:24:59,711 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:24:59,712 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:24:59,713 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:24:59,714 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741869_1045{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:24:59,727 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job.split is closed by DFSClient_NONMAPREDUCE_-619210831_1
2014-05-05 13:24:59,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:24:59,746 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:24:59,749 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:24:59,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:24:59,752 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741870_1046{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:24:59,754 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-619210831_1
2014-05-05 13:25:00,011 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:25:00,030 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:00,033 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:00,034 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:00,037 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741871_1047{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:00,040 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job.xml is closed by DFSClient_NONMAPREDUCE_-619210831_1
2014-05-05 13:25:05,965 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job_1399294722688_0007_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:25:08,590 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:25:08,592 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:25:08,593 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:25:08,594 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741872_1048{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:25:08,598 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job_1399294722688_0007_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1322458701_1
2014-05-05 13:25:13,498 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job_1399294722688_0007_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741873_1049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:25:13,513 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job_1399294722688_0007_1.jhist for DFSClient_NONMAPREDUCE_1322458701_1
2014-05-05 13:25:17,739 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741865_1041 10.0.0.194:50010 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 
2014-05-05 13:25:19,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741865_1041]
2014-05-05 13:25:19,117 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741865_1041]
2014-05-05 13:25:22,118 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741865_1041]
2014-05-05 13:25:22,118 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741865_1041]
2014-05-05 13:25:38,911 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1322458701_1
2014-05-05 13:25:38,923 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1322458701_1
2014-05-05 13:25:38,940 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741873_1049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:38,942 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741873_1049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:38,944 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741873_1049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:38,945 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741873_1049{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:38,948 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0007/job_1399294722688_0007_1.jhist is closed by DFSClient_NONMAPREDUCE_1322458701_1
2014-05-05 13:25:38,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0007.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741874_1050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:25:38,965 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741874_1050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:25:38,966 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741874_1050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:25:38,967 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741874_1050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:25:38,968 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741874_1050{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:25:38,971 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0007.summary_tmp is closed by DFSClient_NONMAPREDUCE_1322458701_1
2014-05-05 13:25:39,027 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0007-1399296300219-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399296338925-1-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741875_1051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:25:39,040 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741875_1051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:39,041 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741875_1051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:39,042 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741875_1051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:39,043 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741875_1051{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:39,053 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0007-1399296300219-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399296338925-1-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1322458701_1
2014-05-05 13:25:39,103 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0007_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741876_1052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:25:39,116 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741876_1052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:39,117 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741876_1052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:39,118 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741876_1052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:39,119 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741876_1052{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:25:39,136 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0007_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1322458701_1
2014-05-05 13:25:40,170 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741868_1044 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 13:25:40,170 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741869_1045 10.0.0.195:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.200:50010 
2014-05-05 13:25:40,170 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741870_1046 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 13:25:40,170 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741871_1047 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 13:25:40,170 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741873_1049 10.0.0.194:50010 10.0.0.193:50010 10.0.0.195:50010 10.0.0.200:50010 
2014-05-05 13:25:40,170 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741872_1048 10.0.0.194:50010 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 13:25:43,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741872_1048, blk_1073741873_1049, blk_1073741868_1044, blk_1073741869_1045, blk_1073741870_1046, blk_1073741871_1047]
2014-05-05 13:25:43,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741872_1048, blk_1073741873_1049, blk_1073741868_1044, blk_1073741869_1045, blk_1073741870_1046, blk_1073741871_1047]
2014-05-05 13:25:46,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741872_1048, blk_1073741873_1049, blk_1073741868_1044, blk_1073741869_1045, blk_1073741870_1046, blk_1073741871_1047]
2014-05-05 13:25:46,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741872_1048, blk_1073741873_1049, blk_1073741868_1044, blk_1073741869_1045, blk_1073741870_1046, blk_1073741871_1047]
2014-05-05 13:28:17,718 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 393 Total time for transactions(ms): 24 Number of transactions batched in Syncs: 1 Number of syncs: 229 SyncTimes(ms): 9461 
2014-05-05 13:28:17,720 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741874_1050 10.0.0.194:50010 10.0.0.200:50010 10.0.0.195:50010 10.0.0.193:50010 
2014-05-05 13:28:19,131 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741874_1050]
2014-05-05 13:28:19,131 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741874_1050]
2014-05-05 13:28:22,131 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741874_1050]
2014-05-05 13:28:22,131 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741874_1050]
2014-05-05 13:28:32,181 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741877_1053{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:28:32,761 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741877_1053{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:28:32,762 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741877_1053{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:28:32,763 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741877_1053{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:28:32,764 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741877_1053{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:28:32,770 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job.jar is closed by DFSClient_NONMAPREDUCE_-1417549436_1
2014-05-05 13:28:32,777 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job.jar
2014-05-05 13:28:32,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job.split
2014-05-05 13:28:32,905 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741878_1054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:28:32,918 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741878_1054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:28:32,919 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741878_1054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:28:32,920 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741878_1054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:28:32,921 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741878_1054{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:28:32,924 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job.split is closed by DFSClient_NONMAPREDUCE_-1417549436_1
2014-05-05 13:28:32,931 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741879_1055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:28:32,942 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741879_1055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:28:32,943 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741879_1055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:28:32,945 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741879_1055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:28:32,946 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741879_1055{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:28:32,958 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1417549436_1
2014-05-05 13:28:33,213 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741880_1056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:28:33,234 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741880_1056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:28:33,235 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741880_1056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:28:33,235 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741880_1056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:28:33,237 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741880_1056{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:28:33,248 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job.xml is closed by DFSClient_NONMAPREDUCE_-1417549436_1
2014-05-05 13:28:46,346 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job_1399294722688_0008_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741881_1057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:28:46,453 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741881_1057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:28:46,454 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741881_1057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:28:46,455 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741881_1057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:28:46,456 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741881_1057{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:28:46,476 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job_1399294722688_0008_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1065598488_1
2014-05-05 13:28:53,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job_1399294722688_0008_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741882_1058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:28:53,874 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job_1399294722688_0008_1.jhist for DFSClient_NONMAPREDUCE_1065598488_1
2014-05-05 13:29:19,770 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 434 Total time for transactions(ms): 26 Number of transactions batched in Syncs: 1 Number of syncs: 252 SyncTimes(ms): 9604 
2014-05-05 13:29:19,833 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1065598488_1
2014-05-05 13:29:19,839 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1065598488_1
2014-05-05 13:29:19,857 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741882_1058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:29:19,858 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741882_1058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:29:19,859 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741882_1058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:29:19,860 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741882_1058{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:29:19,885 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0008/job_1399294722688_0008_1.jhist is closed by DFSClient_NONMAPREDUCE_1065598488_1
2014-05-05 13:29:19,891 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0008.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741883_1059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:29:19,908 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741883_1059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:29:19,916 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741883_1059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:29:19,916 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741883_1059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:29:19,917 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741883_1059{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:29:19,918 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0008.summary_tmp is closed by DFSClient_NONMAPREDUCE_1065598488_1
2014-05-05 13:29:19,947 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0008-1399296513437-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399296559838-1-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:29:19,960 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:29:19,961 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:29:19,962 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:29:19,963 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741884_1060{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:29:19,979 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0008-1399296513437-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399296559838-1-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1065598488_1
2014-05-05 13:29:19,996 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0008_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741885_1061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:29:20,010 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741885_1061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:29:20,011 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741885_1061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:29:20,011 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741885_1061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:29:20,012 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741885_1061{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:29:20,015 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0008_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1065598488_1
2014-05-05 13:29:21,274 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741877_1053 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 13:29:21,274 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741878_1054 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:29:21,274 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741879_1055 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:29:21,274 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741880_1056 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 13:29:21,274 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741882_1058 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.195:50010 
2014-05-05 13:29:21,274 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741881_1057 10.0.0.200:50010 10.0.0.194:50010 10.0.0.195:50010 10.0.0.193:50010 
2014-05-05 13:29:22,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741877_1053, blk_1073741878_1054, blk_1073741879_1055, blk_1073741880_1056, blk_1073741881_1057, blk_1073741882_1058]
2014-05-05 13:29:22,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741877_1053, blk_1073741878_1054, blk_1073741879_1055, blk_1073741880_1056, blk_1073741881_1057, blk_1073741882_1058]
2014-05-05 13:29:25,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741877_1053, blk_1073741878_1054, blk_1073741879_1055, blk_1073741880_1056, blk_1073741881_1057, blk_1073741882_1058]
2014-05-05 13:29:25,472 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741877_1053, blk_1073741878_1054, blk_1073741879_1055, blk_1073741880_1056, blk_1073741881_1057, blk_1073741882_1058]
2014-05-05 13:29:54,150 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741883_1059 10.0.0.200:50010 10.0.0.195:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 13:29:55,474 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741883_1059]
2014-05-05 13:29:55,474 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741883_1059]
2014-05-05 13:29:58,475 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741883_1059]
2014-05-05 13:29:58,475 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741883_1059]
2014-05-05 13:36:06,182 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 464 Total time for transactions(ms): 26 Number of transactions batched in Syncs: 1 Number of syncs: 273 SyncTimes(ms): 9822 
2014-05-05 13:36:06,273 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /100k/data2._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741886_1062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:36:07,594 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741886_1062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:36:07,595 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741886_1062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:36:07,597 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741886_1062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:36:07,598 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741886_1062{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:36:07,602 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /100k/data2._COPYING_ is closed by DFSClient_NONMAPREDUCE_2010749768_1
2014-05-05 13:36:28,365 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741887_1063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:36:28,965 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741887_1063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:36:28,968 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741887_1063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:36:28,970 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741887_1063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:36:28,970 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741887_1063{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:36:28,998 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job.jar is closed by DFSClient_NONMAPREDUCE_382511107_1
2014-05-05 13:36:29,004 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job.jar
2014-05-05 13:36:29,106 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job.split
2014-05-05 13:36:29,116 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741888_1064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:36:29,132 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741888_1064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:36:29,133 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741888_1064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:36:29,134 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741888_1064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:36:29,138 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741888_1064{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:36:29,141 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job.split is closed by DFSClient_NONMAPREDUCE_382511107_1
2014-05-05 13:36:29,152 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741889_1065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:36:29,165 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741889_1065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:36:29,166 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741889_1065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:36:29,166 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741889_1065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:36:29,168 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741889_1065{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:36:29,171 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_382511107_1
2014-05-05 13:36:29,528 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:36:29,548 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:36:29,549 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:36:29,549 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:36:29,551 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741890_1066{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:36:29,554 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job.xml is closed by DFSClient_NONMAPREDUCE_382511107_1
2014-05-05 13:36:35,172 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job_1399294722688_0009_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741891_1067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:36:35,269 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741891_1067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:36:35,270 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741891_1067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:36:35,271 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741891_1067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:36:35,272 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741891_1067{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:36:35,286 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job_1399294722688_0009_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1018471995_1
2014-05-05 13:36:46,981 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job_1399294722688_0009_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741892_1068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:36:46,997 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job_1399294722688_0009_1.jhist for DFSClient_NONMAPREDUCE_-1018471995_1
2014-05-05 13:37:15,977 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 508 Total time for transactions(ms): 29 Number of transactions batched in Syncs: 1 Number of syncs: 296 SyncTimes(ms): 10241 
2014-05-05 13:37:16,003 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1018471995_1
2014-05-05 13:37:16,009 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1018471995_1
2014-05-05 13:37:16,027 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741892_1068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:37:16,029 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741892_1068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:37:16,030 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741892_1068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:37:16,031 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741892_1068{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:37:16,033 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0009/job_1399294722688_0009_1.jhist is closed by DFSClient_NONMAPREDUCE_-1018471995_1
2014-05-05 13:37:16,039 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0009.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741893_1069{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:37:16,051 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741893_1069{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:37:16,052 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741893_1069{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:37:16,053 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741893_1069{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:37:16,054 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741893_1069{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:37:16,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0009.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1018471995_1
2014-05-05 13:37:16,087 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0009-1399296989738-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399297036009-2-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741894_1070{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:37:16,101 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741894_1070{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:37:16,102 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741894_1070{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:37:16,103 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741894_1070{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:37:16,104 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741894_1070{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:37:16,107 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0009-1399296989738-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399297036009-2-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1018471995_1
2014-05-05 13:37:16,123 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0009_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741895_1071{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:37:16,135 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741895_1071{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:37:16,136 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741895_1071{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:37:16,137 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741895_1071{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:37:16,138 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741895_1071{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:37:16,161 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0009_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1018471995_1
2014-05-05 13:37:17,195 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741887_1063 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 13:37:17,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741888_1064 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:37:17,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741889_1065 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 13:37:17,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741890_1066 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:37:17,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741892_1068 10.0.0.193:50010 10.0.0.200:50010 10.0.0.195:50010 10.0.0.194:50010 
2014-05-05 13:37:17,196 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741891_1067 10.0.0.193:50010 10.0.0.200:50010 10.0.0.195:50010 10.0.0.194:50010 
2014-05-05 13:37:17,733 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741893_1069 10.0.0.193:50010 10.0.0.200:50010 10.0.0.195:50010 10.0.0.194:50010 
2014-05-05 13:37:19,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741888_1064, blk_1073741889_1065, blk_1073741890_1066, blk_1073741891_1067, blk_1073741892_1068, blk_1073741893_1069, blk_1073741887_1063]
2014-05-05 13:37:19,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741888_1064, blk_1073741889_1065, blk_1073741890_1066, blk_1073741891_1067, blk_1073741892_1068, blk_1073741893_1069, blk_1073741887_1063]
2014-05-05 13:37:22,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741888_1064, blk_1073741889_1065, blk_1073741890_1066, blk_1073741891_1067, blk_1073741892_1068, blk_1073741893_1069, blk_1073741887_1063]
2014-05-05 13:37:22,506 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741888_1064, blk_1073741889_1065, blk_1073741890_1066, blk_1073741891_1067, blk_1073741892_1068, blk_1073741893_1069, blk_1073741887_1063]
2014-05-05 13:40:42,352 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 538 Total time for transactions(ms): 31 Number of transactions batched in Syncs: 1 Number of syncs: 317 SyncTimes(ms): 10352 
2014-05-05 13:40:42,434 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:40:42,996 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:40:42,997 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:40:42,998 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:40:43,000 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741896_1072{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:40:43,054 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job.jar is closed by DFSClient_NONMAPREDUCE_-2100488124_1
2014-05-05 13:40:43,059 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job.jar
2014-05-05 13:40:43,162 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job.split
2014-05-05 13:40:43,172 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741897_1073{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:40:43,184 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741897_1073{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:40:43,185 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741897_1073{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:40:43,186 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741897_1073{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:40:43,188 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741897_1073{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:40:43,190 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job.split is closed by DFSClient_NONMAPREDUCE_-2100488124_1
2014-05-05 13:40:43,199 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741898_1074{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:40:43,211 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741898_1074{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:40:43,211 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741898_1074{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:40:43,212 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741898_1074{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:40:43,213 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741898_1074{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:40:43,217 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-2100488124_1
2014-05-05 13:40:43,472 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741899_1075{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:40:43,493 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741899_1075{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:40:43,494 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741899_1075{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:40:43,495 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741899_1075{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:40:43,496 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741899_1075{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:40:43,544 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job.xml is closed by DFSClient_NONMAPREDUCE_-2100488124_1
2014-05-05 13:40:50,321 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job_1399294722688_0010_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:40:50,616 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:40:50,617 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:40:50,618 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:40:50,619 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741900_1076{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:40:50,624 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job_1399294722688_0010_1_conf.xml is closed by DFSClient_NONMAPREDUCE_122344810_1
2014-05-05 13:41:01,401 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job_1399294722688_0010_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741901_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:41:01,415 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job_1399294722688_0010_1.jhist for DFSClient_NONMAPREDUCE_122344810_1
2014-05-05 13:41:30,702 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_122344810_1
2014-05-05 13:41:30,708 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_122344810_1
2014-05-05 13:41:30,725 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741901_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:41:30,726 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741901_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:41:30,727 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741901_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:41:30,729 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741901_1077{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:41:30,732 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0010/job_1399294722688_0010_1.jhist is closed by DFSClient_NONMAPREDUCE_122344810_1
2014-05-05 13:41:30,737 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0010.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741902_1078{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:41:30,748 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741902_1078{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:41:30,749 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741902_1078{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:41:30,750 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741902_1078{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:41:30,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741902_1078{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:41:30,754 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0010.summary_tmp is closed by DFSClient_NONMAPREDUCE_122344810_1
2014-05-05 13:41:30,802 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0010-1399297243725-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399297290710-2-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741903_1079{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:41:30,815 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741903_1079{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:41:30,815 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741903_1079{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:41:30,816 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741903_1079{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:41:30,816 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741903_1079{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:41:30,819 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0010-1399297243725-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399297290710-2-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_122344810_1
2014-05-05 13:41:30,833 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0010_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741904_1080{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:41:30,846 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741904_1080{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:41:30,847 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741904_1080{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:41:30,848 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741904_1080{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:41:30,848 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741904_1080{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:41:30,851 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0010_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_122344810_1
2014-05-05 13:41:31,883 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741896_1072 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:41:31,883 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741897_1073 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 13:41:31,883 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741898_1074 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:41:31,883 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741899_1075 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 13:41:31,883 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741901_1077 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.195:50010 
2014-05-05 13:41:31,884 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741900_1076 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.195:50010 
2014-05-05 13:41:34,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741896_1072, blk_1073741897_1073, blk_1073741898_1074, blk_1073741899_1075, blk_1073741900_1076, blk_1073741901_1077]
2014-05-05 13:41:34,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741896_1072, blk_1073741897_1073, blk_1073741898_1074, blk_1073741899_1075, blk_1073741900_1076, blk_1073741901_1077]
2014-05-05 13:41:37,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741896_1072, blk_1073741897_1073, blk_1073741898_1074, blk_1073741899_1075, blk_1073741900_1076, blk_1073741901_1077]
2014-05-05 13:41:37,525 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741896_1072, blk_1073741897_1073, blk_1073741898_1074, blk_1073741899_1075, blk_1073741900_1076, blk_1073741901_1077]
2014-05-05 13:43:06,734 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 603 Total time for transactions(ms): 36 Number of transactions batched in Syncs: 1 Number of syncs: 355 SyncTimes(ms): 11705 
2014-05-05 13:43:06,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741905_1081{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:43:07,451 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741905_1081{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:43:07,452 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741905_1081{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:43:07,453 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741905_1081{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:43:07,454 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741905_1081{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:43:07,466 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job.jar is closed by DFSClient_NONMAPREDUCE_1934599173_1
2014-05-05 13:43:07,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job.jar
2014-05-05 13:43:07,548 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job.split
2014-05-05 13:43:07,559 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741906_1082{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:43:07,571 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741906_1082{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:43:07,572 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741906_1082{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:43:07,573 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741906_1082{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:43:07,575 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741906_1082{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:43:07,624 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job.split is closed by DFSClient_NONMAPREDUCE_1934599173_1
2014-05-05 13:43:07,709 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741907_1083{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:43:07,741 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741907_1083{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:43:07,742 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741907_1083{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:43:07,743 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741907_1083{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:43:07,744 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741907_1083{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:43:07,794 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1934599173_1
2014-05-05 13:43:08,050 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741908_1084{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:43:08,066 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741908_1084{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:43:08,067 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741908_1084{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:43:08,068 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741908_1084{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:43:08,069 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741908_1084{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:43:08,106 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job.xml is closed by DFSClient_NONMAPREDUCE_1934599173_1
2014-05-05 13:43:17,740 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741902_1078 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.195:50010 
2014-05-05 13:43:18,121 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job_1399294722688_0011_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741909_1085{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:43:18,628 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741909_1085{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:43:18,628 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741909_1085{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:43:18,629 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741909_1085{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:43:18,630 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741909_1085{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:43:18,797 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job_1399294722688_0011_1_conf.xml is closed by DFSClient_NONMAPREDUCE_125854843_1
2014-05-05 13:43:19,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741902_1078]
2014-05-05 13:43:19,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741902_1078]
2014-05-05 13:43:22,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741902_1078]
2014-05-05 13:43:22,533 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741902_1078]
2014-05-05 13:43:26,191 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job_1399294722688_0011_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741910_1086{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:43:26,205 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job_1399294722688_0011_1.jhist for DFSClient_NONMAPREDUCE_125854843_1
2014-05-05 13:43:58,430 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_125854843_1
2014-05-05 13:43:58,475 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_125854843_1
2014-05-05 13:43:58,496 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741910_1086{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:43:58,498 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741910_1086{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:43:58,499 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741910_1086{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:43:58,500 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741910_1086{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:43:58,503 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0011/job_1399294722688_0011_1.jhist is closed by DFSClient_NONMAPREDUCE_125854843_1
2014-05-05 13:43:58,508 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0011.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741911_1087{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:43:58,519 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741911_1087{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:43:58,520 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741911_1087{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:43:58,521 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741911_1087{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:43:58,522 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741911_1087{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:43:58,524 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0011.summary_tmp is closed by DFSClient_NONMAPREDUCE_125854843_1
2014-05-05 13:43:58,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0011-1399297388301-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399297438475-2-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741912_1088{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:43:58,591 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741912_1088{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:43:58,592 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741912_1088{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:43:58,593 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741912_1088{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:43:58,593 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741912_1088{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:43:58,596 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0011-1399297388301-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399297438475-2-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_125854843_1
2014-05-05 13:43:58,621 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0011_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741913_1089{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:43:58,635 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741913_1089{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:43:58,636 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741913_1089{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:43:58,637 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741913_1089{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:43:58,638 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741913_1089{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:43:58,641 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0011_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_125854843_1
2014-05-05 13:43:59,697 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741905_1081 10.0.0.194:50010 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 
2014-05-05 13:43:59,697 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741906_1082 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:43:59,697 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741907_1083 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 13:43:59,697 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741908_1084 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:43:59,698 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741910_1086 10.0.0.200:50010 10.0.0.194:50010 10.0.0.195:50010 10.0.0.193:50010 
2014-05-05 13:43:59,698 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741909_1085 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.195:50010 
2014-05-05 13:44:01,538 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741905_1081, blk_1073741906_1082, blk_1073741907_1083, blk_1073741908_1084, blk_1073741909_1085, blk_1073741910_1086]
2014-05-05 13:44:01,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741905_1081, blk_1073741906_1082, blk_1073741907_1083, blk_1073741908_1084, blk_1073741909_1085, blk_1073741910_1086]
2014-05-05 13:44:04,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741905_1081, blk_1073741906_1082, blk_1073741907_1083, blk_1073741908_1084, blk_1073741909_1085, blk_1073741910_1086]
2014-05-05 13:44:04,539 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741905_1081, blk_1073741906_1082, blk_1073741907_1083, blk_1073741908_1084, blk_1073741909_1085, blk_1073741910_1086]
2014-05-05 13:45:33,582 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 671 Total time for transactions(ms): 43 Number of transactions batched in Syncs: 1 Number of syncs: 396 SyncTimes(ms): 15330 
2014-05-05 13:45:33,641 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /100k/data33._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741914_1090{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:45:34,940 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741914_1090{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:45:34,941 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741914_1090{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:45:34,942 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741914_1090{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:45:34,944 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741914_1090{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:45:34,948 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /100k/data33._COPYING_ is closed by DFSClient_NONMAPREDUCE_-167163275_1
2014-05-05 13:46:17,721 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741911_1087 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.195:50010 
2014-05-05 13:46:19,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741911_1087]
2014-05-05 13:46:19,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741911_1087]
2014-05-05 13:46:22,576 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741911_1087]
2014-05-05 13:46:22,576 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741911_1087]
2014-05-05 13:46:32,026 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741915_1091{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:46:32,615 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741915_1091{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:46:32,615 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741915_1091{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:46:32,616 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741915_1091{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:46:32,618 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741915_1091{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:46:32,624 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job.jar is closed by DFSClient_NONMAPREDUCE_2135578493_1
2014-05-05 13:46:32,633 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job.jar
2014-05-05 13:46:32,718 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job.split
2014-05-05 13:46:32,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741916_1092{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:46:32,748 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741916_1092{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:46:32,749 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741916_1092{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:46:32,750 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741916_1092{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:46:32,751 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741916_1092{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:46:32,755 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job.split is closed by DFSClient_NONMAPREDUCE_2135578493_1
2014-05-05 13:46:32,766 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741917_1093{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:46:32,779 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741917_1093{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:46:32,780 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741917_1093{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:46:32,781 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741917_1093{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:46:32,782 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741917_1093{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:46:32,789 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_2135578493_1
2014-05-05 13:46:33,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741918_1094{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:46:33,088 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741918_1094{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:46:33,089 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741918_1094{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:46:33,090 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741918_1094{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:46:33,093 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741918_1094{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:46:33,124 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job.xml is closed by DFSClient_NONMAPREDUCE_2135578493_1
2014-05-05 13:46:38,647 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 708 Total time for transactions(ms): 44 Number of transactions batched in Syncs: 1 Number of syncs: 418 SyncTimes(ms): 15398 
2014-05-05 13:46:39,016 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job_1399294722688_0012_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741919_1095{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:46:39,205 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741919_1095{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:46:39,205 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741919_1095{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:46:39,206 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741919_1095{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:46:39,207 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741919_1095{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:46:39,212 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job_1399294722688_0012_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-224581165_1
2014-05-05 13:46:55,737 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 4
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 13:46:55,737 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job_1399294722688_0012_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741920_1096{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:46:55,764 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job_1399294722688_0012_1.jhist for DFSClient_NONMAPREDUCE_-224581165_1
2014-05-05 13:47:29,676 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-224581165_1
2014-05-05 13:47:29,684 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-224581165_1
2014-05-05 13:47:29,701 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741920_1096{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:47:29,702 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741920_1096{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:47:29,703 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741920_1096{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:47:29,713 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0012/job_1399294722688_0012_1.jhist is closed by DFSClient_NONMAPREDUCE_-224581165_1
2014-05-05 13:47:29,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0012.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741921_1097{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:47:29,731 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741921_1097{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:47:29,732 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741921_1097{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:47:29,733 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741921_1097{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:47:29,734 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741921_1097{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:47:29,760 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0012.summary_tmp is closed by DFSClient_NONMAPREDUCE_-224581165_1
2014-05-05 13:47:29,789 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0012-1399297593319-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399297649686-3-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741922_1098{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:47:29,802 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741922_1098{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:47:29,802 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741922_1098{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:47:29,804 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741922_1098{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:47:29,804 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741922_1098{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:47:29,806 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0012-1399297593319-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399297649686-3-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-224581165_1
2014-05-05 13:47:29,820 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0012_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741923_1099{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:47:29,832 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741923_1099{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:47:29,833 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741923_1099{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:47:29,833 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741923_1099{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:47:29,834 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741923_1099{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:47:29,836 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0012_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-224581165_1
2014-05-05 13:47:30,865 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741915_1091 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 13:47:30,865 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741916_1092 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:47:30,865 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741917_1093 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:47:30,865 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741918_1094 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:47:30,865 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741920_1096 10.0.0.194:50010 10.0.0.195:50010 10.0.0.200:50010 
2014-05-05 13:47:30,865 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741919_1095 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.195:50010 
2014-05-05 13:47:31,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741920_1096, blk_1073741915_1091, blk_1073741916_1092, blk_1073741917_1093, blk_1073741918_1094, blk_1073741919_1095]
2014-05-05 13:47:31,584 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741915_1091, blk_1073741916_1092, blk_1073741917_1093, blk_1073741918_1094, blk_1073741919_1095]
2014-05-05 13:47:34,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741920_1096, blk_1073741915_1091, blk_1073741916_1092, blk_1073741917_1093, blk_1073741918_1094, blk_1073741919_1095]
2014-05-05 13:47:34,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741920_1096, blk_1073741915_1091, blk_1073741916_1092, blk_1073741917_1093, blk_1073741918_1094, blk_1073741919_1095]
2014-05-05 13:49:04,767 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 745 Total time for transactions(ms): 45 Number of transactions batched in Syncs: 1 Number of syncs: 440 SyncTimes(ms): 15499 
2014-05-05 13:49:04,841 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741924_1100{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:49:05,408 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741924_1100{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:49:05,410 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741924_1100{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:49:05,412 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741924_1100{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:49:05,413 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741924_1100{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:49:05,420 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job.jar is closed by DFSClient_NONMAPREDUCE_-784423483_1
2014-05-05 13:49:05,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job.jar
2014-05-05 13:49:05,555 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job.split
2014-05-05 13:49:05,564 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741925_1101{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:49:05,576 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741925_1101{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:49:05,577 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741925_1101{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:49:05,578 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741925_1101{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:49:05,579 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741925_1101{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:49:05,582 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job.split is closed by DFSClient_NONMAPREDUCE_-784423483_1
2014-05-05 13:49:05,590 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741926_1102{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:49:05,601 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741926_1102{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:49:05,601 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741926_1102{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:49:05,602 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741926_1102{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:49:05,604 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741926_1102{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:49:05,606 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-784423483_1
2014-05-05 13:49:05,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741927_1103{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:49:05,885 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741927_1103{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:49:05,886 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741927_1103{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:49:05,886 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741927_1103{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:49:05,888 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741927_1103{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:49:05,890 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job.xml is closed by DFSClient_NONMAPREDUCE_-784423483_1
2014-05-05 13:49:11,745 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job_1399294722688_0013_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741928_1104{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:49:12,343 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741928_1104{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:49:12,344 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741928_1104{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:49:12,345 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741928_1104{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:49:12,346 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741928_1104{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:49:12,357 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job_1399294722688_0013_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-755870893_1
2014-05-05 13:49:17,719 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741921_1097 10.0.0.194:50010 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 13:49:19,592 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741921_1097]
2014-05-05 13:49:19,593 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741921_1097]
2014-05-05 13:49:22,610 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741921_1097]
2014-05-05 13:49:22,610 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741921_1097]
2014-05-05 13:49:29,625 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job_1399294722688_0013_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741929_1105{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:49:29,638 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job_1399294722688_0013_1.jhist for DFSClient_NONMAPREDUCE_-755870893_1
2014-05-05 13:50:00,096 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-755870893_1
2014-05-05 13:50:00,100 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-755870893_1
2014-05-05 13:50:00,122 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741929_1105{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:50:00,123 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741929_1105{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:50:00,124 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741929_1105{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:50:00,126 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741929_1105{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:50:00,128 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0013/job_1399294722688_0013_1.jhist is closed by DFSClient_NONMAPREDUCE_-755870893_1
2014-05-05 13:50:00,133 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0013.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741930_1106{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:50:00,144 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741930_1106{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:50:00,145 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741930_1106{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:50:00,146 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741930_1106{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:50:00,147 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741930_1106{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:50:00,149 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0013.summary_tmp is closed by DFSClient_NONMAPREDUCE_-755870893_1
2014-05-05 13:50:00,179 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0013-1399297746077-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399297800101-3-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741931_1107{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:50:00,196 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741931_1107{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:50:00,197 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741931_1107{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:50:00,197 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741931_1107{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:50:00,198 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741931_1107{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:50:00,201 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0013-1399297746077-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399297800101-3-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-755870893_1
2014-05-05 13:50:00,216 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0013_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741932_1108{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:50:00,228 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741932_1108{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:50:00,228 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741932_1108{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:50:00,229 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741932_1108{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:50:00,230 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741932_1108{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:50:00,233 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0013_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-755870893_1
2014-05-05 13:50:01,272 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741924_1100 10.0.0.193:50010 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 13:50:01,273 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741925_1101 10.0.0.195:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.200:50010 
2014-05-05 13:50:01,273 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741926_1102 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 13:50:01,273 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741927_1103 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 13:50:01,273 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741929_1105 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 13:50:01,273 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741928_1104 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 13:50:01,615 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741924_1100, blk_1073741925_1101, blk_1073741926_1102, blk_1073741927_1103, blk_1073741928_1104, blk_1073741929_1105]
2014-05-05 13:50:01,615 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741924_1100, blk_1073741925_1101, blk_1073741926_1102, blk_1073741927_1103, blk_1073741928_1104, blk_1073741929_1105]
2014-05-05 13:50:04,615 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741924_1100, blk_1073741925_1101, blk_1073741926_1102, blk_1073741927_1103, blk_1073741928_1104, blk_1073741929_1105]
2014-05-05 13:50:04,615 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741924_1100, blk_1073741925_1101, blk_1073741926_1102, blk_1073741927_1103, blk_1073741928_1104, blk_1073741929_1105]
2014-05-05 13:52:17,719 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 813 Total time for transactions(ms): 45 Number of transactions batched in Syncs: 1 Number of syncs: 481 SyncTimes(ms): 15682 
2014-05-05 13:52:17,721 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741930_1106 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:52:19,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741930_1106]
2014-05-05 13:52:19,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741930_1106]
2014-05-05 13:52:22,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741930_1106]
2014-05-05 13:52:22,624 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741930_1106]
2014-05-05 13:53:12,798 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741933_1109{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:53:13,360 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741933_1109{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:53:13,361 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741933_1109{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:53:13,362 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741933_1109{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:53:13,364 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741933_1109{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:53:13,369 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job.jar is closed by DFSClient_NONMAPREDUCE_739403376_1
2014-05-05 13:53:13,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job.jar
2014-05-05 13:53:13,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job.split
2014-05-05 13:53:13,470 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741934_1110{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:53:13,484 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741934_1110{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:53:13,484 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741934_1110{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:53:13,485 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741934_1110{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:53:13,487 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741934_1110{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:53:13,489 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job.split is closed by DFSClient_NONMAPREDUCE_739403376_1
2014-05-05 13:53:13,497 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741935_1111{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 13:53:13,508 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741935_1111{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:53:13,508 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741935_1111{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:53:13,509 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741935_1111{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:53:13,511 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741935_1111{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 13:53:13,513 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_739403376_1
2014-05-05 13:53:13,767 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741936_1112{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:53:13,789 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741936_1112{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:53:13,790 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741936_1112{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:53:13,791 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741936_1112{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:53:13,792 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741936_1112{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:53:13,794 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job.xml is closed by DFSClient_NONMAPREDUCE_739403376_1
2014-05-05 13:53:19,029 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 844 Total time for transactions(ms): 45 Number of transactions batched in Syncs: 1 Number of syncs: 500 SyncTimes(ms): 15709 
2014-05-05 13:53:19,899 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job_1399294722688_0014_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741937_1113{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 13:53:20,091 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741937_1113{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:53:20,091 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741937_1113{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:53:20,092 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741937_1113{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:53:20,093 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741937_1113{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 13:53:20,099 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job_1399294722688_0014_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1563216770_1
2014-05-05 13:53:37,056 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 4
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 13:53:37,057 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job_1399294722688_0014_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741938_1114{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:53:37,071 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job_1399294722688_0014_1.jhist for DFSClient_NONMAPREDUCE_1563216770_1
2014-05-05 13:54:05,374 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1563216770_1
2014-05-05 13:54:05,379 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1563216770_1
2014-05-05 13:54:05,397 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741938_1114{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:54:05,397 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741938_1114{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:54:05,398 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741938_1114{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:54:05,401 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0014/job_1399294722688_0014_1.jhist is closed by DFSClient_NONMAPREDUCE_1563216770_1
2014-05-05 13:54:05,406 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0014.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741939_1115{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 13:54:05,417 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741939_1115{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:54:05,418 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741939_1115{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:54:05,418 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741939_1115{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:54:05,419 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741939_1115{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 13:54:05,421 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0014.summary_tmp is closed by DFSClient_NONMAPREDUCE_1563216770_1
2014-05-05 13:54:05,453 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0014-1399297993971-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399298045382-3-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741940_1116{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:54:05,467 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741940_1116{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:54:05,468 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741940_1116{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:54:05,468 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741940_1116{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:54:05,469 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741940_1116{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:54:05,472 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0014-1399297993971-ubuntu-base%7C%7Cpath%3A%2F100k%7C%7Cnum+reduce%3A8-1399298045382-3-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1563216770_1
2014-05-05 13:54:05,486 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0014_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741941_1117{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 13:54:05,499 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741941_1117{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:54:05,500 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741941_1117{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:54:05,501 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741941_1117{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:54:05,502 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741941_1117{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 13:54:05,504 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0014_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1563216770_1
2014-05-05 13:54:06,558 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741933_1109 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:54:06,558 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741934_1110 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 13:54:06,558 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741935_1111 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 13:54:06,558 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741936_1112 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 13:54:06,558 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741938_1114 10.0.0.194:50010 10.0.0.200:50010 10.0.0.195:50010 
2014-05-05 13:54:06,558 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741937_1113 10.0.0.194:50010 10.0.0.200:50010 10.0.0.195:50010 10.0.0.193:50010 
2014-05-05 13:54:07,634 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741936_1112, blk_1073741937_1113, blk_1073741933_1109, blk_1073741934_1110, blk_1073741935_1111]
2014-05-05 13:54:07,634 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741936_1112, blk_1073741937_1113, blk_1073741938_1114, blk_1073741933_1109, blk_1073741934_1110, blk_1073741935_1111]
2014-05-05 13:54:10,634 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741936_1112, blk_1073741937_1113, blk_1073741938_1114, blk_1073741933_1109, blk_1073741934_1110, blk_1073741935_1111]
2014-05-05 13:54:10,634 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741936_1112, blk_1073741937_1113, blk_1073741938_1114, blk_1073741933_1109, blk_1073741934_1110, blk_1073741935_1111]
2014-05-05 13:55:17,717 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 881 Total time for transactions(ms): 46 Number of transactions batched in Syncs: 1 Number of syncs: 522 SyncTimes(ms): 16305 
2014-05-05 13:55:17,719 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741939_1115 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.195:50010 
2014-05-05 13:55:19,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741939_1115]
2014-05-05 13:55:19,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741939_1115]
2014-05-05 13:55:22,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741939_1115]
2014-05-05 13:55:22,639 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741939_1115]
2014-05-05 13:59:39,410 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 13:59:39,410 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 13:59:39,410 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 3
2014-05-05 13:59:39,410 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 884 Total time for transactions(ms): 46 Number of transactions batched in Syncs: 1 Number of syncs: 525 SyncTimes(ms): 16309 
2014-05-05 13:59:39,412 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 884 Total time for transactions(ms): 46 Number of transactions batched in Syncs: 1 Number of syncs: 526 SyncTimes(ms): 16311 
2014-05-05 13:59:39,412 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000003 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000003-0000000000000000886
2014-05-05 13:59:39,412 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 887
2014-05-05 13:59:39,685 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=886&storageInfo=-47:182241533:0:CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32
2014-05-05 13:59:39,695 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 600.00 KB/s
2014-05-05 13:59:39,695 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000886 size 6726 bytes.
2014-05-05 13:59:39,703 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2014-05-05 13:59:39,703 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2014-05-05 14:00:54,889 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 32 
2014-05-05 14:00:54,891 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741826_1002 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.195:50010 
2014-05-05 14:00:54,891 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741827_1003 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 14:00:54,891 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741828_1004 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 14:00:54,891 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741829_1005 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 14:00:55,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741826_1002, blk_1073741827_1003, blk_1073741828_1004, blk_1073741829_1005]
2014-05-05 14:00:55,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741826_1002, blk_1073741827_1003, blk_1073741828_1004, blk_1073741829_1005]
2014-05-05 14:00:58,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741826_1002, blk_1073741827_1003, blk_1073741828_1004, blk_1073741829_1005]
2014-05-05 14:00:58,660 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741826_1002, blk_1073741827_1003, blk_1073741828_1004, blk_1073741829_1005]
2014-05-05 14:01:07,729 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /in1m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741942_1118{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:01:08,128 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741942_1118{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:01:08,128 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741942_1118{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:01:08,129 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741942_1118{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:01:08,131 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741942_1118{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:01:08,136 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /in1m/data._COPYING_ is closed by DFSClient_NONMAPREDUCE_1359637865_1
2014-05-05 14:01:40,958 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741943_1119{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 14:01:41,495 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741943_1119{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:41,496 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741943_1119{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:41,497 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741943_1119{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:41,498 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741943_1119{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:41,507 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job.jar is closed by DFSClient_NONMAPREDUCE_-1213533149_1
2014-05-05 14:01:41,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job.jar
2014-05-05 14:01:41,574 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job.split
2014-05-05 14:01:41,585 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741944_1120{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 14:01:41,597 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741944_1120{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:41,597 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741944_1120{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:41,598 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741944_1120{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:41,599 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741944_1120{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:41,602 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job.split is closed by DFSClient_NONMAPREDUCE_-1213533149_1
2014-05-05 14:01:41,609 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741945_1121{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 14:01:41,619 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741945_1121{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:41,620 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741945_1121{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:41,621 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741945_1121{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:41,622 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741945_1121{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:41,624 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-1213533149_1
2014-05-05 14:01:41,880 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741946_1122{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 14:01:41,900 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741946_1122{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:01:41,900 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741946_1122{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:01:41,902 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741946_1122{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:01:41,902 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741946_1122{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:01:41,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job.xml is closed by DFSClient_NONMAPREDUCE_-1213533149_1
2014-05-05 14:01:48,316 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job_1399294722688_0015_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741947_1123{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 14:01:48,801 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741947_1123{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:48,802 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741947_1123{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:48,803 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741947_1123{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:48,805 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741947_1123{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:01:48,810 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job_1399294722688_0015_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1024044958_1
2014-05-05 14:01:56,973 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job_1399294722688_0015_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741948_1124{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 14:01:57,004 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job_1399294722688_0015_1.jhist for DFSClient_NONMAPREDUCE_1024044958_1
2014-05-05 14:01:57,004 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 46 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 25 SyncTimes(ms): 69 
2014-05-05 14:03:49,967 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 47 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 26 SyncTimes(ms): 71 
2014-05-05 14:03:50,006 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1024044958_1
2014-05-05 14:03:50,035 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1024044958_1
2014-05-05 14:03:50,050 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741948_1124{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:03:50,050 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741948_1124{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:03:50,052 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741948_1124{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:03:50,054 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741948_1124{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:03:50,056 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0015/job_1399294722688_0015_1.jhist is closed by DFSClient_NONMAPREDUCE_1024044958_1
2014-05-05 14:03:50,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0015.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741949_1125{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 14:03:50,071 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741949_1125{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:03:50,072 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741949_1125{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:03:50,072 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741949_1125{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:03:50,073 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741949_1125{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:03:50,076 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0015.summary_tmp is closed by DFSClient_NONMAPREDUCE_1024044958_1
2014-05-05 14:03:50,097 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0015-1399298502083-ubuntu-base%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399298630036-1-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741950_1126{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:03:50,118 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741950_1126{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:03:50,119 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741950_1126{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:03:50,120 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741950_1126{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:03:50,121 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741950_1126{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:03:50,125 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0015-1399298502083-ubuntu-base%7C%7Cpath%3A%2Fin1m%7C%7Cnum+reduce%3A8-1399298630036-1-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1024044958_1
2014-05-05 14:03:50,158 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0015_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741951_1127{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:03:50,170 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741951_1127{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:03:50,171 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741951_1127{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:03:50,172 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741951_1127{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:03:50,173 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741951_1127{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:03:50,176 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0015_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1024044958_1
2014-05-05 14:03:51,205 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741943_1119 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 14:03:51,205 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741944_1120 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 14:03:51,205 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741945_1121 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 14:03:51,205 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741946_1122 10.0.0.195:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.200:50010 
2014-05-05 14:03:51,205 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741948_1124 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 14:03:51,205 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741947_1123 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 14:03:52,678 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741943_1119, blk_1073741944_1120, blk_1073741945_1121, blk_1073741946_1122, blk_1073741947_1123, blk_1073741948_1124]
2014-05-05 14:03:52,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741943_1119, blk_1073741944_1120, blk_1073741945_1121, blk_1073741946_1122, blk_1073741947_1123, blk_1073741948_1124]
2014-05-05 14:03:55,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741943_1119, blk_1073741944_1120, blk_1073741945_1121, blk_1073741946_1122, blk_1073741947_1123, blk_1073741948_1124]
2014-05-05 14:03:55,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741943_1119, blk_1073741944_1120, blk_1073741945_1121, blk_1073741946_1122, blk_1073741947_1123, blk_1073741948_1124]
2014-05-05 14:04:17,719 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741949_1125 10.0.0.195:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.200:50010 
2014-05-05 14:04:19,681 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741949_1125]
2014-05-05 14:04:19,681 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741949_1125]
2014-05-05 14:04:22,681 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741949_1125]
2014-05-05 14:04:22,681 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741949_1125]
2014-05-05 14:05:21,161 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-289703120-10.0.0.194-50010-1399294712058, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 31, processing time: 1 msecs
2014-05-05 14:12:05,363 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 77 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 47 SyncTimes(ms): 120 
2014-05-05 14:12:28,918 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /50m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741952_1128{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:12:30,515 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741952_1128{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:12:30,516 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741952_1128{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:12:30,517 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741952_1128{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:12:30,518 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741952_1128{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:12:30,520 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /50m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741953_1129{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 14:12:31,579 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741953_1129{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:12:31,580 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741953_1129{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:12:31,580 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741953_1129{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:12:31,582 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741953_1129{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:12:31,583 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /50m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741954_1130{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 14:12:32,635 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741954_1130{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:12:32,636 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741954_1130{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:12:32,637 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741954_1130{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:12:32,651 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741954_1130{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:12:32,652 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /50m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741955_1131{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 14:12:32,887 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741955_1131{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:12:32,888 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741955_1131{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:12:32,889 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741955_1131{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:12:32,889 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741955_1131{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:12:32,901 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /50m/data._COPYING_ is closed by DFSClient_NONMAPREDUCE_-764275128_1
2014-05-05 14:12:59,419 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: [Lease.  Holder: DFSClient_NONMAPREDUCE_-1037182608_1, pendingcreates: 1] has expired hard limit
2014-05-05 14:12:59,419 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Recovering [Lease.  Holder: DFSClient_NONMAPREDUCE_-1037182608_1, pendingcreates: 1], src=/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0004/job.jar
2014-05-05 14:12:59,507 INFO BlockStateChange: BLOCK* blk_1073741849_1025{blockUCState=UNDER_RECOVERY, primaryNodeIndex=0, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} recovery started, primary=ReplicaUnderConstruction[10.0.0.195:50010|RBW]
2014-05-05 14:12:59,507 WARN org.apache.hadoop.hdfs.StateChange: DIR* NameSystem.internalReleaseLease: File /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0004/job.jar has not been closed. Lease recovery is in progress. RecoveryId = 1132 for block blk_1073741849_1025{blockUCState=UNDER_RECOVERY, primaryNodeIndex=0, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 14:13:05,337 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741849_1025{blockUCState=UNDER_RECOVERY, primaryNodeIndex=0, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:13:05,343 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741849_1025{blockUCState=UNDER_RECOVERY, primaryNodeIndex=0, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:13:05,353 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741849_1025{blockUCState=UNDER_RECOVERY, primaryNodeIndex=0, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:13:05,360 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741849_1025{blockUCState=UNDER_RECOVERY, primaryNodeIndex=0, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:13:05,687 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(lastblock=BP-899801483-10.0.0.195-1399294588764:blk_1073741849_1025, newgenerationstamp=1132, newlength=30366208, newtargets=[10.0.0.195:50010, 10.0.0.193:50010, 10.0.0.200:50010, 10.0.0.194:50010], closeFile=true, deleteBlock=false)
2014-05-05 14:13:05,848 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 95 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 52 SyncTimes(ms): 228 
2014-05-05 14:13:06,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: commitBlockSynchronization(newblock=BP-899801483-10.0.0.195-1399294588764:blk_1073741849_1025, file=/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0004/job.jar, newgenerationstamp=1132, newlength=30366208, newtargets=[10.0.0.195:50010, 10.0.0.193:50010, 10.0.0.200:50010, 10.0.0.194:50010]) successful
2014-05-05 14:13:58,319 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741956_1133{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:13:58,840 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741956_1133{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:13:58,841 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741956_1133{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:13:58,842 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741956_1133{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:13:58,844 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741956_1133{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:13:58,868 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job.jar is closed by DFSClient_NONMAPREDUCE_1755590080_1
2014-05-05 14:13:58,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job.jar
2014-05-05 14:13:58,972 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job.split
2014-05-05 14:13:58,992 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741957_1134{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 14:13:59,003 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741957_1134{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:13:59,004 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741957_1134{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:13:59,005 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741957_1134{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:13:59,006 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741957_1134{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:13:59,021 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job.split is closed by DFSClient_NONMAPREDUCE_1755590080_1
2014-05-05 14:13:59,029 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741958_1135{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 14:13:59,039 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741958_1135{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:13:59,040 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741958_1135{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:13:59,041 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741958_1135{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:13:59,042 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741958_1135{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:13:59,045 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1755590080_1
2014-05-05 14:13:59,427 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741959_1136{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:13:59,447 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741959_1136{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:13:59,448 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741959_1136{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:13:59,448 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741959_1136{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:13:59,450 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741959_1136{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:13:59,452 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job.xml is closed by DFSClient_NONMAPREDUCE_1755590080_1
2014-05-05 14:14:06,016 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 124 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 0 Number of syncs: 69 SyncTimes(ms): 942 
2014-05-05 14:14:06,366 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job_1399294722688_0016_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741960_1137{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 14:14:06,509 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741960_1137{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:14:06,509 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741960_1137{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:14:06,510 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741960_1137{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:14:06,512 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741960_1137{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:14:06,518 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job_1399294722688_0016_1_conf.xml is closed by DFSClient_NONMAPREDUCE_169955762_1
2014-05-05 14:15:16,365 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job_1399294722688_0016_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741961_1138{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:15:16,380 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job_1399294722688_0016_1.jhist for DFSClient_NONMAPREDUCE_169955762_1
2014-05-05 14:15:16,380 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 133 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 0 Number of syncs: 72 SyncTimes(ms): 947 
2014-05-05 14:19:17,025 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 134 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 0 Number of syncs: 73 SyncTimes(ms): 949 
2014-05-05 14:19:32,903 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /5m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741962_1139{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:19:36,436 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741962_1139{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:19:36,437 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741962_1139{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:19:36,437 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741962_1139{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:19:36,438 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741962_1139{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:19:36,445 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /5m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741963_1140{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 14:19:39,177 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741963_1140{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:19:39,178 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741963_1140{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:19:39,178 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741963_1140{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:19:39,179 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741963_1140{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:19:39,185 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /5m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741964_1141{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:19:40,844 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741964_1141{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:19:40,845 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741964_1141{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:19:40,847 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741964_1141{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:19:42,840 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /5m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741965_1142{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:19:44,292 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741964_1141 size 134217728
2014-05-05 14:19:50,694 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741965_1142{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:19:50,695 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741965_1142{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:19:50,697 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741965_1142{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:19:53,166 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741965_1142{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:19:53,177 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /5m/data._COPYING_ is closed by DFSClient_NONMAPREDUCE_1166791295_1
2014-05-05 14:20:10,333 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741961_1138{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:20:10,414 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741961_1138{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:20:10,415 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741961_1138{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:20:10,417 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741961_1138{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:20:10,645 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0016/job_1399294722688_0016_1.jhist is closed by DFSClient_NONMAPREDUCE_169955762_1
2014-05-05 14:20:12,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0016.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741966_1143{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 14:20:19,065 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741966_1143{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:20:19,066 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741966_1143{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:20:19,067 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741966_1143{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:20:19,069 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741966_1143{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:20:19,070 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 155 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 0 Number of syncs: 79 SyncTimes(ms): 3256 
2014-05-05 14:20:21,377 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0016.summary_tmp is closed by DFSClient_NONMAPREDUCE_169955762_1
2014-05-05 14:20:25,939 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0016-1399299239740-ubuntu-base%7C%7Cpath%3A%2F50m%7C%7Cnum+reduce%3A8-1399299608293-4-0-FAILED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741967_1144{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 14:20:26,841 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741967_1144{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:20:26,842 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741967_1144{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:20:26,843 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741967_1144{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:20:26,846 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741967_1144{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:20:26,848 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0016-1399299239740-ubuntu-base%7C%7Cpath%3A%2F50m%7C%7Cnum+reduce%3A8-1399299608293-4-0-FAILED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_169955762_1
2014-05-05 14:20:26,861 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0016_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741968_1145{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:20:26,873 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741968_1145{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:20:26,873 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741968_1145{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:20:26,874 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741968_1145{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:20:26,875 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741968_1145{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:20:26,878 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0016_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_169955762_1
2014-05-05 14:20:27,910 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741956_1133 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 14:20:27,910 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741957_1134 10.0.0.195:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.200:50010 
2014-05-05 14:20:27,910 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741958_1135 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 14:20:27,910 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741959_1136 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 14:20:27,910 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741961_1138 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 14:20:27,910 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741960_1137 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 14:20:29,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741956_1133, blk_1073741957_1134, blk_1073741958_1135, blk_1073741959_1136, blk_1073741960_1137, blk_1073741961_1138]
2014-05-05 14:20:29,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741956_1133, blk_1073741957_1134, blk_1073741958_1135, blk_1073741959_1136, blk_1073741960_1137, blk_1073741961_1138]
2014-05-05 14:20:32,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741956_1133, blk_1073741957_1134, blk_1073741958_1135, blk_1073741959_1136, blk_1073741960_1137, blk_1073741961_1138]
2014-05-05 14:20:32,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741956_1133, blk_1073741957_1134, blk_1073741958_1135, blk_1073741959_1136, blk_1073741960_1137, blk_1073741961_1138]
2014-05-05 14:21:00,066 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741962_1139 10.0.0.194:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.195:50010 
2014-05-05 14:21:00,066 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741963_1140 10.0.0.194:50010 10.0.0.193:50010 10.0.0.195:50010 10.0.0.200:50010 
2014-05-05 14:21:00,067 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741964_1141 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 14:21:00,067 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741965_1142 10.0.0.194:50010 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 
2014-05-05 14:21:02,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741962_1139, blk_1073741963_1140, blk_1073741964_1141, blk_1073741965_1142]
2014-05-05 14:21:02,560 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741962_1139, blk_1073741963_1140, blk_1073741964_1141, blk_1073741965_1142]
2014-05-05 14:21:05,565 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741962_1139, blk_1073741963_1140, blk_1073741964_1141, blk_1073741965_1142]
2014-05-05 14:21:05,565 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741962_1139, blk_1073741963_1140, blk_1073741964_1141, blk_1073741965_1142]
2014-05-05 14:21:10,042 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /5m/data._COPYING_. BP-899801483-10.0.0.195-1399294588764 blk_1073741969_1146{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 14:21:10,792 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741969_1146{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:21:10,792 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741969_1146{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:21:10,793 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741969_1146{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:21:10,794 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741969_1146{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:21:10,804 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /5m/data._COPYING_ is closed by DFSClient_NONMAPREDUCE_19648886_1
2014-05-05 14:21:28,547 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 180 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 95 SyncTimes(ms): 5598 
2014-05-05 14:21:28,640 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741970_1147{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:21:29,154 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741970_1147{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:21:29,155 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741970_1147{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:21:29,156 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741970_1147{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:21:29,157 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741970_1147{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:21:29,167 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job.jar is closed by DFSClient_NONMAPREDUCE_-2001797084_1
2014-05-05 14:21:29,173 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job.jar
2014-05-05 14:21:29,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job.split
2014-05-05 14:21:29,245 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741971_1148{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 14:21:29,264 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741971_1148{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:21:29,264 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741971_1148{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:21:29,265 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741971_1148{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:21:29,267 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741971_1148{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:21:29,270 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job.split is closed by DFSClient_NONMAPREDUCE_-2001797084_1
2014-05-05 14:21:29,285 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741972_1149{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:21:29,298 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741972_1149{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:21:29,299 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741972_1149{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:21:29,299 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741972_1149{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:21:29,301 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741972_1149{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:21:29,310 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-2001797084_1
2014-05-05 14:21:29,578 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741973_1150{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 14:21:29,592 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741973_1150{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:21:29,592 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741973_1150{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:21:29,593 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741973_1150{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:21:29,594 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741973_1150{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:21:29,611 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job.xml is closed by DFSClient_NONMAPREDUCE_-2001797084_1
2014-05-05 14:21:35,297 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job_1399294722688_0017_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741974_1151{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 14:21:35,397 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741974_1151{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:21:35,398 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741974_1151{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:21:35,399 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741974_1151{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:21:35,401 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741974_1151{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:21:35,427 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job_1399294722688_0017_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1500759036_1
2014-05-05 14:21:56,136 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job_1399294722688_0017_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741975_1152{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:21:56,150 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job_1399294722688_0017_1.jhist for DFSClient_NONMAPREDUCE_1500759036_1
2014-05-05 14:22:17,722 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741966_1143 10.0.0.195:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 
2014-05-05 14:22:20,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741966_1143]
2014-05-05 14:22:20,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741966_1143]
2014-05-05 14:22:23,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741966_1143]
2014-05-05 14:22:23,573 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741966_1143]
2014-05-05 14:30:17,157 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 221 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 118 SyncTimes(ms): 5759 
2014-05-05 14:30:17,170 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1500759036_1
2014-05-05 14:30:17,175 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1500759036_1
2014-05-05 14:30:17,193 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741975_1152{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:30:17,196 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741975_1152{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:30:17,199 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741975_1152{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:30:17,200 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741975_1152{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:30:17,203 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0017/job_1399294722688_0017_1.jhist is closed by DFSClient_NONMAPREDUCE_1500759036_1
2014-05-05 14:30:17,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0017.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741976_1153{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 14:30:17,219 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741976_1153{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:30:17,219 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741976_1153{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:30:17,220 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741976_1153{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:30:17,221 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741976_1153{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:30:17,224 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0017.summary_tmp is closed by DFSClient_NONMAPREDUCE_1500759036_1
2014-05-05 14:30:17,267 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0017-1399299689788-ubuntu-base%7C%7Cpath%3A%2F5m%7C%7Cnum+reduce%3A8-1399300217176-1-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741977_1154{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 14:30:17,278 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741977_1154{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:30:17,279 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741977_1154{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:30:17,280 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741977_1154{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:30:17,281 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741977_1154{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 14:30:17,284 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0017-1399299689788-ubuntu-base%7C%7Cpath%3A%2F5m%7C%7Cnum+reduce%3A8-1399300217176-1-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1500759036_1
2014-05-05 14:30:17,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0017_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741978_1155{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:30:17,413 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741978_1155{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:30:17,414 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741978_1155{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:30:17,414 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741978_1155{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:30:17,416 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741978_1155{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:30:17,421 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0017_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1500759036_1
2014-05-05 14:30:18,477 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741970_1147 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 14:30:18,477 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741971_1148 10.0.0.195:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 14:30:18,477 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741972_1149 10.0.0.195:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 14:30:18,477 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741973_1150 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 14:30:18,477 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741975_1152 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 14:30:18,477 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741974_1151 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 14:30:20,618 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741970_1147, blk_1073741971_1148, blk_1073741972_1149, blk_1073741973_1150, blk_1073741974_1151, blk_1073741975_1152]
2014-05-05 14:30:20,618 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741970_1147, blk_1073741971_1148, blk_1073741972_1149, blk_1073741973_1150, blk_1073741974_1151, blk_1073741975_1152]
2014-05-05 14:30:23,618 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741970_1147, blk_1073741971_1148, blk_1073741972_1149, blk_1073741973_1150, blk_1073741974_1151, blk_1073741975_1152]
2014-05-05 14:30:23,619 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741970_1147, blk_1073741971_1148, blk_1073741972_1149, blk_1073741973_1150, blk_1073741974_1151, blk_1073741975_1152]
2014-05-05 14:31:17,728 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 248 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 136 SyncTimes(ms): 5907 
2014-05-05 14:31:17,731 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741976_1153 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 14:31:20,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741976_1153]
2014-05-05 14:31:20,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741976_1153]
2014-05-05 14:31:23,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741976_1153]
2014-05-05 14:31:23,622 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741976_1153]
2014-05-05 14:31:36,734 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741979_1156{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 14:31:37,303 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741979_1156{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:31:37,304 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741979_1156{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:31:37,305 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741979_1156{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:31:37,306 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741979_1156{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 14:31:37,392 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job.jar is closed by DFSClient_NONMAPREDUCE_87138195_1
2014-05-05 14:31:37,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job.jar
2014-05-05 14:31:37,496 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job.split
2014-05-05 14:31:37,526 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741980_1157{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:31:37,538 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741980_1157{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:31:37,539 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741980_1157{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:31:37,540 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741980_1157{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:31:37,541 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741980_1157{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:31:37,548 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job.split is closed by DFSClient_NONMAPREDUCE_87138195_1
2014-05-05 14:31:37,557 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741981_1158{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:31:37,568 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741981_1158{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:31:37,568 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741981_1158{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:31:37,569 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741981_1158{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:31:37,570 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741981_1158{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:31:37,574 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_87138195_1
2014-05-05 14:31:37,846 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741982_1159{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:31:37,862 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741982_1159{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:31:37,863 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741982_1159{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:31:37,864 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741982_1159{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:31:37,865 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741982_1159{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:31:37,882 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job.xml is closed by DFSClient_NONMAPREDUCE_87138195_1
2014-05-05 14:31:44,791 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job_1399294722688_0018_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741983_1160{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 14:31:45,804 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741983_1160{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:31:45,804 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741983_1160{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:31:45,805 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741983_1160{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:31:45,806 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741983_1160{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:31:45,859 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job_1399294722688_0018_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1690179787_1
2014-05-05 14:32:05,873 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job_1399294722688_0018_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741984_1161{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 14:32:05,885 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job_1399294722688_0018_1.jhist for DFSClient_NONMAPREDUCE_1690179787_1
2014-05-05 14:41:22,170 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 289 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 0 Number of syncs: 159 SyncTimes(ms): 7501 
2014-05-05 14:41:22,195 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1690179787_1
2014-05-05 14:41:22,201 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1690179787_1
2014-05-05 14:41:22,215 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741984_1161{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:41:22,216 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741984_1161{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:41:22,217 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741984_1161{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:41:22,218 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741984_1161{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:41:22,221 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399294722688_0018/job_1399294722688_0018_1.jhist is closed by DFSClient_NONMAPREDUCE_1690179787_1
2014-05-05 14:41:22,247 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0018.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741985_1162{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:41:22,263 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741985_1162{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:41:22,271 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741985_1162{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:41:22,273 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741985_1162{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:41:22,274 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741985_1162{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:41:22,276 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0018.summary_tmp is closed by DFSClient_NONMAPREDUCE_1690179787_1
2014-05-05 14:41:22,298 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0018-1399300298057-ubuntu-base%7C%7Cpath%3A%2F5m%7C%7Cnum+reduce%3A8-1399300882201-1-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741986_1163{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 14:41:22,312 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741986_1163{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:41:22,313 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741986_1163{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:41:22,314 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741986_1163{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:41:22,315 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741986_1163{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 14:41:22,318 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0018-1399300298057-ubuntu-base%7C%7Cpath%3A%2F5m%7C%7Cnum+reduce%3A8-1399300882201-1-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1690179787_1
2014-05-05 14:41:22,363 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0018_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741987_1164{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 14:41:22,375 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741987_1164{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:41:22,376 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741987_1164{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:41:22,377 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741987_1164{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:41:22,378 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741987_1164{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 14:41:22,380 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399294722688_0018_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1690179787_1
2014-05-05 14:41:23,411 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741979_1156 10.0.0.195:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.194:50010 
2014-05-05 14:41:23,411 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741980_1157 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 14:41:23,411 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741981_1158 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 14:41:23,411 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741982_1159 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 14:41:23,411 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741984_1161 10.0.0.200:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.195:50010 
2014-05-05 14:41:23,411 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741983_1160 10.0.0.200:50010 10.0.0.193:50010 10.0.0.194:50010 10.0.0.195:50010 
2014-05-05 14:41:23,678 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741984_1161, blk_1073741979_1156, blk_1073741980_1157, blk_1073741981_1158, blk_1073741982_1159, blk_1073741983_1160]
2014-05-05 14:41:23,678 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741984_1161, blk_1073741979_1156, blk_1073741980_1157, blk_1073741981_1158, blk_1073741982_1159, blk_1073741983_1160]
2014-05-05 14:41:26,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741984_1161, blk_1073741979_1156, blk_1073741980_1157, blk_1073741981_1158, blk_1073741982_1159, blk_1073741983_1160]
2014-05-05 14:41:26,679 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741984_1161, blk_1073741979_1156, blk_1073741980_1157, blk_1073741981_1158, blk_1073741982_1159, blk_1073741983_1160]
2014-05-05 14:43:17,717 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 316 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 177 SyncTimes(ms): 7557 
2014-05-05 14:43:17,719 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741985_1162 10.0.0.200:50010 10.0.0.194:50010 10.0.0.195:50010 10.0.0.193:50010 
2014-05-05 14:43:20,685 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741985_1162]
2014-05-05 14:43:20,685 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741985_1162]
2014-05-05 14:43:23,686 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741985_1162]
2014-05-05 14:43:23,686 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741985_1162]
2014-05-05 14:59:43,803 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 14:59:43,804 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 14:59:43,804 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 887
2014-05-05 14:59:43,804 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 319 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 180 SyncTimes(ms): 7562 
2014-05-05 14:59:43,805 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 319 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 181 SyncTimes(ms): 7563 
2014-05-05 14:59:43,806 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000000887 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000000887-0000000000000001205
2014-05-05 14:59:43,807 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1206
2014-05-05 14:59:44,025 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=1205&storageInfo=-47:182241533:0:CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32
2014-05-05 14:59:44,037 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 727.27 KB/s
2014-05-05 14:59:44,037 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001205 size 8258 bytes.
2014-05-05 14:59:44,070 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 886
2014-05-05 14:59:44,070 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2014-05-05 15:59:44,453 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 15:59:44,453 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 15:59:44,453 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1206
2014-05-05 15:59:44,453 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 93 
2014-05-05 15:59:44,455 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 94 
2014-05-05 15:59:44,455 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000001206 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000001206-0000000000000001207
2014-05-05 15:59:44,455 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1208
2014-05-05 15:59:44,530 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=1207&storageInfo=-47:182241533:0:CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32
2014-05-05 15:59:44,538 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 1000.00 KB/s
2014-05-05 15:59:44,538 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001207 size 8258 bytes.
2014-05-05 15:59:44,547 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1205
2014-05-05 15:59:44,548 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/var/hadoop/tmp/dfs/name/current/fsimage_0000000000000000886, cpktTxId=0000000000000000886)
2014-05-05 16:59:44,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 16:59:44,934 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 16:59:44,934 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1208
2014-05-05 16:59:44,934 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 33 
2014-05-05 16:59:44,936 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 35 
2014-05-05 16:59:44,937 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000001208 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000001208-0000000000000001209
2014-05-05 16:59:44,937 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1210
2014-05-05 16:59:45,046 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=1209&storageInfo=-47:182241533:0:CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32
2014-05-05 16:59:45,057 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 800.00 KB/s
2014-05-05 16:59:45,057 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001209 size 8258 bytes.
2014-05-05 16:59:45,065 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1207
2014-05-05 16:59:45,065 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/var/hadoop/tmp/dfs/name/current/fsimage_0000000000000001205, cpktTxId=0000000000000001205)
2014-05-05 17:27:56,740 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.37, storageID=DS-1569457213-10.0.0.37-50010-1399310876546, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-1569457213-10.0.0.37-50010-1399310876546
2014-05-05 17:27:56,740 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.37:50010
2014-05-05 17:27:56,787 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.37:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 17:27:56,787 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.37, storageID=DS-1569457213-10.0.0.37-50010-1399310876546, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 17:27:57,620 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.36, storageID=DS-116851507-10.0.0.36-50010-1399310877416, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-116851507-10.0.0.36-50010-1399310877416
2014-05-05 17:27:57,620 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.36:50010
2014-05-05 17:27:57,694 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.36:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 17:27:57,694 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.36, storageID=DS-116851507-10.0.0.36-50010-1399310877416, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 17:27:57,762 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.38, storageID=DS-455312272-10.0.0.38-50010-1399310877553, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-455312272-10.0.0.38-50010-1399310877553
2014-05-05 17:27:57,762 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.38:50010
2014-05-05 17:27:57,805 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.38:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 17:27:57,805 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.38, storageID=DS-455312272-10.0.0.38-50010-1399310877553, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 17:28:02,330 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.35, storageID=DS-1901755127-10.0.0.35-50010-1399310882118, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-1901755127-10.0.0.35-50010-1399310882118
2014-05-05 17:28:02,330 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.35:50010
2014-05-05 17:28:02,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.35:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 17:28:02,375 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.35, storageID=DS-1901755127-10.0.0.35-50010-1399310882118, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 17:28:03,147 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 17:28:03,149 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
2014-05-05 17:31:35,512 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = ip-10-0-0-195/10.0.0.195
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.2.0
STARTUP_MSG:   classpath = /home/ubuntu/PatchedDistro/hadoop-2.2.0/etc/hadoop:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/zookeeper-3.4.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/junit-4.8.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/hadoop-auth-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/hadoop-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/hadoop-common-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/common/hadoop-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/hadoop-hdfs-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/hadoop-hdfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-site-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-client-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-api-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/junit-4.10.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.2.0-tests.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.2.0.jar:/home/ubuntu/PatchedDistro/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.2.0.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'Joey' on 2014-03-24T00:00Z
STARTUP_MSG:   java = 1.7.0_51
************************************************************/
2014-05-05 17:31:35,521 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2014-05-05 17:31:35,821 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-05-05 17:31:35,936 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-05-05 17:31:35,936 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2014-05-05 17:31:36,556 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-05-05 17:31:36,640 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-05-05 17:31:36,643 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2014-05-05 17:31:36,643 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-05-05 17:31:36,643 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2014-05-05 17:31:36,678 INFO org.apache.hadoop.http.HttpServer: dfs.webhdfs.enabled = false
2014-05-05 17:31:36,717 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50070
2014-05-05 17:31:36,717 INFO org.mortbay.log: jetty-6.1.26
2014-05-05 17:31:37,140 INFO org.mortbay.log: Started SelectChannelConnector@ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 17:31:37,141 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Web-server up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com:50070
2014-05-05 17:31:37,214 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 17:31:37,214 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2014-05-05 17:31:37,299 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2014-05-05 17:31:37,299 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2014-05-05 17:31:37,302 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2014-05-05 17:31:37,306 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2014-05-05 17:31:37,306 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 17:31:37,307 INFO org.apache.hadoop.util.GSet: 2.0% max memory = 889 MB
2014-05-05 17:31:37,307 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2014-05-05 17:31:37,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2014-05-05 17:31:37,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 4
2014-05-05 17:31:37,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2014-05-05 17:31:37,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2014-05-05 17:31:37,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2014-05-05 17:31:37,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2014-05-05 17:31:37,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2014-05-05 17:31:37,314 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2014-05-05 17:31:37,324 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = ubuntu (auth:SIMPLE)
2014-05-05 17:31:37,324 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2014-05-05 17:31:37,324 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2014-05-05 17:31:37,324 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2014-05-05 17:31:37,325 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2014-05-05 17:31:37,381 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2014-05-05 17:31:37,381 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 17:31:37,381 INFO org.apache.hadoop.util.GSet: 1.0% max memory = 889 MB
2014-05-05 17:31:37,381 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2014-05-05 17:31:37,383 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2014-05-05 17:31:37,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2014-05-05 17:31:37,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2014-05-05 17:31:37,386 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2014-05-05 17:31:37,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2014-05-05 17:31:37,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2014-05-05 17:31:37,389 INFO org.apache.hadoop.util.GSet: Computing capacity for map Namenode Retry Cache
2014-05-05 17:31:37,389 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2014-05-05 17:31:37,389 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory = 889 MB
2014-05-05 17:31:37,389 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2014-05-05 17:31:37,405 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/hadoop/tmp/dfs/name/in_use.lock acquired by nodename 4152@ip-10-0-0-195
2014-05-05 17:31:37,507 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /var/hadoop/tmp/dfs/name/current
2014-05-05 17:31:37,591 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000001210 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000001210-0000000000000001210
2014-05-05 17:31:37,612 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loading image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000001209 using no compression
2014-05-05 17:31:37,612 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files = 58
2014-05-05 17:31:37,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Number of files under construction = 0
2014-05-05 17:31:37,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Image file /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000001209 of size 8258 bytes loaded in 0 seconds.
2014-05-05 17:31:37,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 1209 from /var/hadoop/tmp/dfs/name/current/fsimage_0000000000000001209
2014-05-05 17:31:37,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@49ebe0fd expecting start txid #1210
2014-05-05 17:31:37,652 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000001210-0000000000000001210
2014-05-05 17:31:37,654 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream '/var/hadoop/tmp/dfs/name/current/edits_0000000000000001210-0000000000000001210' to transaction ID 1210
2014-05-05 17:31:37,661 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /var/hadoop/tmp/dfs/name/current/edits_0000000000000001210-0000000000000001210 of size 1048576 edits # 1 loaded in 0 seconds
2014-05-05 17:31:37,668 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1211
2014-05-05 17:31:37,792 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2014-05-05 17:31:37,792 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 401 msecs
2014-05-05 17:31:38,074 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to ec2-54-186-230-200.us-west-2.compute.amazonaws.com:54310
2014-05-05 17:31:38,092 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2014-05-05 17:31:38,145 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2014-05-05 17:31:38,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 17:31:38,177 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2014-05-05 17:31:38,179 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 42 blocks to reach the threshold 0.9990 of total blocks 42.
Safe mode will be turned off automatically
2014-05-05 17:31:38,210 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-05-05 17:31:38,211 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2014-05-05 17:31:38,214 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: ec2-54-186-230-200.us-west-2.compute.amazonaws.com/10.0.0.195:54310
2014-05-05 17:31:38,214 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2014-05-05 17:31:42,669 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.194, storageID=DS-289703120-10.0.0.194-50010-1399294712058, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-289703120-10.0.0.194-50010-1399294712058
2014-05-05 17:31:42,680 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.194:50010
2014-05-05 17:31:42,686 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.38, storageID=DS-455312272-10.0.0.38-50010-1399310877553, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-455312272-10.0.0.38-50010-1399310877553
2014-05-05 17:31:42,687 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.38:50010
2014-05-05 17:31:42,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.193, storageID=DS-445834928-10.0.0.193-50010-1399294712039, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-445834928-10.0.0.193-50010-1399294712039
2014-05-05 17:31:42,721 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.193:50010
2014-05-05 17:31:42,786 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.36, storageID=DS-116851507-10.0.0.36-50010-1399310877416, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-116851507-10.0.0.36-50010-1399310877416
2014-05-05 17:31:42,787 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.36:50010
2014-05-05 17:31:42,807 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.37, storageID=DS-1569457213-10.0.0.37-50010-1399310876546, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-1569457213-10.0.0.37-50010-1399310876546
2014-05-05 17:31:42,818 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.37:50010
2014-05-05 17:31:42,857 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.35, storageID=DS-1901755127-10.0.0.35-50010-1399310882118, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-1901755127-10.0.0.35-50010-1399310882118
2014-05-05 17:31:42,858 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.35:50010
2014-05-05 17:31:42,876 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.195, storageID=DS-1004147253-10.0.0.195-50010-1399294712032, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-1004147253-10.0.0.195-50010-1399294712032
2014-05-05 17:31:42,876 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.195:50010
2014-05-05 17:31:42,900 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.38:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 17:31:42,900 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.38, storageID=DS-455312272-10.0.0.38-50010-1399310877553, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 1 msecs
2014-05-05 17:31:42,901 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.36:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 17:31:42,901 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.36, storageID=DS-116851507-10.0.0.36-50010-1399310877416, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 17:31:42,936 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 41 has reached the threshold 0.9990 of total blocks 42. The number of live datanodes 7 has reached the minimum number 0. Safe mode will be turned off automatically in 29 seconds.
2014-05-05 17:31:42,936 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2014-05-05 17:31:42,951 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 42
2014-05-05 17:31:42,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2014-05-05 17:31:42,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 42
2014-05-05 17:31:42,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2014-05-05 17:31:42,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2014-05-05 17:31:42,952 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2014-05-05 17:31:42,952 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.193:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 17:31:42,952 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.193, storageID=DS-445834928-10.0.0.193-50010-1399294712039, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 42, processing time: 48 msecs
2014-05-05 17:31:42,953 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.37:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 17:31:42,953 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.37, storageID=DS-1569457213-10.0.0.37-50010-1399310876546, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 17:31:42,955 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.194:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 17:31:42,955 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.194, storageID=DS-289703120-10.0.0.194-50010-1399294712058, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 42, processing time: 2 msecs
2014-05-05 17:31:42,960 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.0.200, storageID=DS-479534094-10.0.0.200-50010-1399294712104, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0) storage DS-479534094-10.0.0.200-50010-1399294712104
2014-05-05 17:31:42,960 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.0.200:50010
2014-05-05 17:31:42,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.35:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 17:31:42,979 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.35, storageID=DS-1901755127-10.0.0.35-50010-1399310882118, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 0, processing time: 0 msecs
2014-05-05 17:31:43,011 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.200:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 17:31:43,011 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.200, storageID=DS-479534094-10.0.0.200-50010-1399294712104, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 42, processing time: 2 msecs
2014-05-05 17:31:43,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 10.0.0.195:50010 after starting up or becoming active. Its block contents are no longer considered stale
2014-05-05 17:31:43,031 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(10.0.0.195, storageID=DS-1004147253-10.0.0.195-50010-1399294712032, infoPort=50075, ipcPort=50020, storageInfo=lv=-47;cid=CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32;nsid=182241533;c=0), blocks: 42, processing time: 2 msecs
2014-05-05 17:32:02,959 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 42 has reached the threshold 0.9990 of total blocks 42. The number of live datanodes 8 has reached the minimum number 0. Safe mode will be turned off automatically in 9 seconds.
2014-05-05 17:32:12,961 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 35 secs
2014-05-05 17:32:12,961 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2014-05-05 17:32:12,961 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 8 datanodes
2014-05-05 17:32:12,961 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2014-05-05 17:32:48,465 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 17:32:48,465 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 17:32:48,465 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1211
2014-05-05 17:32:48,465 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 42 
2014-05-05 17:32:48,467 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 44 
2014-05-05 17:32:48,468 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000001211 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000001211-0000000000000001212
2014-05-05 17:32:48,468 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1213
2014-05-05 17:32:49,144 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=1212&storageInfo=-47:182241533:0:CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32
2014-05-05 17:32:49,307 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.16s at 49.08 KB/s
2014-05-05 17:32:49,307 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001212 size 8258 bytes.
2014-05-05 17:32:49,317 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1209
2014-05-05 17:32:49,317 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/var/hadoop/tmp/dfs/name/current/fsimage_0000000000000001207, cpktTxId=0000000000000001207)
2014-05-05 17:51:46,184 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 35 
2014-05-05 17:51:46,306 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741988_1165{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 17:51:47,349 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741988_1165{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 17:51:47,351 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741988_1165{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 17:51:47,353 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741988_1165{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 17:51:47,356 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741988_1165{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 17:51:47,368 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-976401553_1
2014-05-05 17:51:47,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job.jar
2014-05-05 17:51:47,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job.split
2014-05-05 17:51:47,461 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:51:47,461 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741989_1166{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 17:51:47,873 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741989_1166{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 17:51:47,874 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741989_1166{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 17:51:47,877 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741989_1166{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 17:51:47,879 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741989_1166{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 17:51:47,881 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741989_1166{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 17:51:47,884 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741989_1166{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 17:51:47,885 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741989_1166{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 17:51:47,907 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job.split is closed by DFSClient_NONMAPREDUCE_-976401553_1
2014-05-05 17:51:47,917 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741990_1167{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]}
2014-05-05 17:51:47,932 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741990_1167{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 17:51:47,933 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741990_1167{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 17:51:47,935 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741990_1167{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 17:51:47,935 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741990_1167{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 17:51:47,938 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-976401553_1
2014-05-05 17:51:48,197 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741991_1168{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]}
2014-05-05 17:51:48,350 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741991_1168{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 17:51:48,350 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741991_1168{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 17:51:48,352 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741991_1168{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 17:51:48,353 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741991_1168{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 17:51:48,358 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-976401553_1
2014-05-05 17:51:50,271 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:51:50,271 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:51:50,273 INFO BlockStateChange: BLOCK* ask 10.0.0.200:50010 to replicate blk_1073741988_1165 to datanode(s) 10.0.0.193:50010 10.0.0.36:50010 10.0.0.37:50010
2014-05-05 17:51:53,573 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741988_1165 size 39460499
2014-05-05 17:51:53,574 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741988_1165 size 39460499
2014-05-05 17:51:53,574 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741988_1165 size 39460499
2014-05-05 17:51:56,274 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:51:56,274 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:51:56,439 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job_1399311113324_0001_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073741992_1169{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 17:51:56,643 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741992_1169{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 17:51:56,644 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741992_1169{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 17:51:56,645 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741992_1169{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 17:51:56,652 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741992_1169{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 17:51:56,662 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job_1399311113324_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1451532405_1
2014-05-05 17:52:02,275 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:02,275 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:08,276 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:08,276 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:14,277 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:14,278 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:20,278 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:20,279 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:20,548 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job_1399311113324_0001_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073741993_1170{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]}
2014-05-05 17:52:20,568 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job_1399311113324_0001_1.jhist for DFSClient_NONMAPREDUCE_1451532405_1
2014-05-05 17:52:26,281 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:26,282 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:32,283 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:32,284 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:38,285 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:38,285 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:44,286 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:44,287 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:50,287 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:50,288 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:56,289 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:52:56,289 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:02,290 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:02,290 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:08,291 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:08,291 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:14,292 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:14,292 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:20,293 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:20,294 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:26,294 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:26,295 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:32,296 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:32,296 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:38,297 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:38,297 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:44,298 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:44,298 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:50,299 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:50,300 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:56,300 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:53:56,301 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:02,302 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:02,302 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:08,303 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:08,303 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:14,304 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:14,304 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:20,305 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:20,305 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:26,306 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:26,306 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:32,307 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:32,308 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:38,309 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:38,309 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:44,310 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:44,310 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:50,311 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:50,311 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:56,312 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:54:56,313 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:02,314 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:02,314 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:08,315 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:08,315 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:14,316 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:14,316 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:20,317 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:20,317 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:26,318 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:26,318 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:32,319 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:32,320 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:38,321 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:38,321 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:44,322 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:44,322 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:50,323 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:50,323 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:56,324 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:55:56,324 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:02,325 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:02,326 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:08,326 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:08,327 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:14,328 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:14,328 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:20,329 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:20,329 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:26,330 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:26,330 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:32,331 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:32,332 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:38,333 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:38,333 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:44,334 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:44,334 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:50,335 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:50,335 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:56,336 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:56:56,336 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:02,337 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:02,338 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:08,339 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:08,339 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:14,340 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:14,340 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:20,341 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:20,341 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:26,342 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:26,342 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:32,343 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:32,343 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:38,344 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:38,344 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:44,345 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:44,346 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:50,346 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:50,347 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:56,348 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:57:56,348 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:02,349 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:02,349 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:08,350 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:08,350 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:14,351 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:14,351 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:20,352 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:20,352 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:26,353 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:26,354 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:32,354 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:32,355 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:38,355 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:38,356 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:44,357 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:44,357 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:50,358 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:50,358 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:56,359 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:58:56,360 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:02,361 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:02,361 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:08,362 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:08,362 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:14,363 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:14,363 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:20,364 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:20,364 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:26,365 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:26,365 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:32,366 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:32,367 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:38,368 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:38,368 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:44,369 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:44,369 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:50,370 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:50,370 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:56,371 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 17:59:56,372 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:02,373 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:02,373 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:08,374 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:08,374 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:14,375 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:14,375 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:20,376 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:20,376 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:26,377 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:26,377 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:32,378 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:32,379 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:38,379 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:38,380 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:44,381 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:44,381 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:50,382 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:50,382 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:56,383 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:00:56,383 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:01:02,384 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:01:02,384 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:01:08,385 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:01:08,385 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:01:14,386 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:01:14,386 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:01:16,209 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 41 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 0 Number of syncs: 22 SyncTimes(ms): 94 
2014-05-05 18:01:16,213 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1451532405_1
2014-05-05 18:01:16,218 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1451532405_1
2014-05-05 18:01:16,234 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741993_1170{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:01:16,235 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741993_1170{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:01:16,237 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741993_1170{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:01:16,239 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741993_1170{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:01:16,242 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0001/job_1399311113324_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_1451532405_1
2014-05-05 18:01:16,270 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0001.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741994_1171{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]}
2014-05-05 18:01:16,285 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741994_1171{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:01:16,286 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741994_1171{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:01:16,287 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741994_1171{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:01:16,289 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741994_1171{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:01:16,292 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_1451532405_1
2014-05-05 18:01:16,320 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0001-1399312308562-ubuntu-base%7C%7Cpath%3A%2F5m%7C%7Cnum+reduce%3A8-1399312876219-1-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741995_1172{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 18:01:16,336 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741995_1172{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:01:16,342 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741995_1172{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:01:16,343 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741995_1172{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:01:16,344 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741995_1172 size 85479
2014-05-05 18:01:16,345 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0001-1399312308562-ubuntu-base%7C%7Cpath%3A%2F5m%7C%7Cnum+reduce%3A8-1399312876219-1-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1451532405_1
2014-05-05 18:01:16,359 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0001_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073741996_1173{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 18:01:16,377 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741996_1173{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:01:16,378 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741996_1173{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:01:16,379 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741996_1173{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:01:16,382 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741996_1173{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:01:16,384 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1451532405_1
2014-05-05 18:01:17,432 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741988_1165 10.0.0.195:50010 10.0.0.38:50010 10.0.0.194:50010 10.0.0.200:50010 10.0.0.193:50010 10.0.0.36:50010 10.0.0.37:50010 
2014-05-05 18:01:17,432 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741989_1166 10.0.0.195:50010 10.0.0.194:50010 10.0.0.37:50010 10.0.0.200:50010 10.0.0.36:50010 10.0.0.38:50010 10.0.0.193:50010 
2014-05-05 18:01:17,432 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741990_1167 10.0.0.195:50010 10.0.0.200:50010 10.0.0.36:50010 10.0.0.38:50010 
2014-05-05 18:01:17,432 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741991_1168 10.0.0.195:50010 10.0.0.200:50010 10.0.0.194:50010 10.0.0.36:50010 
2014-05-05 18:01:17,433 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741993_1170 10.0.0.195:50010 10.0.0.193:50010 10.0.0.37:50010 10.0.0.38:50010 
2014-05-05 18:01:17,433 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741992_1169 10.0.0.195:50010 10.0.0.36:50010 10.0.0.194:50010 10.0.0.200:50010 
2014-05-05 18:01:17,720 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741994_1171 10.0.0.195:50010 10.0.0.38:50010 10.0.0.36:50010 10.0.0.37:50010 
2014-05-05 18:01:20,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073741988_1165, blk_1073741989_1166, blk_1073741991_1168, blk_1073741992_1169]
2014-05-05 18:01:20,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.38:50010 to delete [blk_1073741988_1165, blk_1073741989_1166, blk_1073741990_1167, blk_1073741993_1170, blk_1073741994_1171]
2014-05-05 18:01:20,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073741988_1165, blk_1073741989_1166, blk_1073741993_1170]
2014-05-05 18:01:23,387 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741988_1165, blk_1073741989_1166, blk_1073741990_1167, blk_1073741991_1168, blk_1073741992_1169]
2014-05-05 18:01:23,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.36:50010 to delete [blk_1073741988_1165, blk_1073741989_1166, blk_1073741990_1167, blk_1073741991_1168, blk_1073741992_1169, blk_1073741994_1171]
2014-05-05 18:01:23,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.37:50010 to delete [blk_1073741988_1165, blk_1073741989_1166, blk_1073741993_1170, blk_1073741994_1171]
2014-05-05 18:01:26,388 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073741988_1165, blk_1073741989_1166, blk_1073741990_1167, blk_1073741991_1168, blk_1073741992_1169, blk_1073741993_1170, blk_1073741994_1171]
2014-05-05 18:04:22,453 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 71 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 43 SyncTimes(ms): 118 
2014-05-05 18:04:22,559 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073741997_1174{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]}
2014-05-05 18:04:23,290 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741997_1174{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:04:23,292 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741997_1174{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:04:23,293 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741997_1174{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:04:23,295 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741997_1174{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW]]} size 0
2014-05-05 18:04:23,301 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job.jar is closed by DFSClient_NONMAPREDUCE_955185658_1
2014-05-05 18:04:23,307 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job.jar
2014-05-05 18:04:23,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job.split
2014-05-05 18:04:23,384 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:23,385 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073741998_1175{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]}
2014-05-05 18:04:23,400 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:23,400 INFO BlockStateChange: BLOCK* ask 10.0.0.36:50010 to replicate blk_1073741997_1174 to datanode(s) 10.0.0.38:50010 10.0.0.194:50010 10.0.0.193:50010
2014-05-05 18:04:23,409 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741998_1175{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:04:23,410 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073741998_1175{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:04:23,411 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073741998_1175{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:04:23,412 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741998_1175{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:04:23,414 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741998_1175{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:04:23,415 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741998_1175{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:04:23,417 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741998_1175{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:04:23,426 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job.split is closed by DFSClient_NONMAPREDUCE_955185658_1
2014-05-05 18:04:23,438 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073741999_1176{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]}
2014-05-05 18:04:23,451 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073741999_1176{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:04:23,452 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741999_1176{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:04:23,453 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741999_1176{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:04:23,454 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073741999_1176{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:04:23,457 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_955185658_1
2014-05-05 18:04:23,719 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073742000_1177{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 18:04:23,754 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742000_1177{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:04:23,755 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073742000_1177{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:04:23,756 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073742000_1177{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:04:23,757 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073742000_1177{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:04:23,760 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job.xml is closed by DFSClient_NONMAPREDUCE_955185658_1
2014-05-05 18:04:26,400 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:27,899 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073741997_1174 size 39460499
2014-05-05 18:04:27,904 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073741997_1174 size 39460499
2014-05-05 18:04:27,906 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073741997_1174 size 39460499
2014-05-05 18:04:29,401 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:29,401 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:29,987 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job_1399311113324_0002_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073742001_1178{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 18:04:30,185 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073742001_1178{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:04:30,186 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742001_1178{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:04:30,187 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073742001_1178{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:04:30,190 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073742001_1178{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:04:30,214 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job_1399311113324_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1343608966_1
2014-05-05 18:04:35,402 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:35,402 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:41,403 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:41,403 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:47,404 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:47,404 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:51,061 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job_1399311113324_0002_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073742002_1179{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 18:04:51,075 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job_1399311113324_0002_1.jhist for DFSClient_NONMAPREDUCE_-1343608966_1
2014-05-05 18:04:53,405 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:53,405 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:59,406 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:04:59,406 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:05,407 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:05,408 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:11,409 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:11,409 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:17,410 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:17,410 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:23,411 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:23,411 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:29,412 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:29,412 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:35,413 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:35,413 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:41,414 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:41,415 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:47,415 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:47,416 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:53,417 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:53,417 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:59,417 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:05:59,418 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:05,419 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:05,419 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:11,420 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:11,420 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:17,421 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:17,421 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:23,422 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:23,422 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:29,423 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:29,423 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:35,424 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:35,424 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:41,425 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:41,426 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:47,427 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:47,427 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:53,428 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:53,428 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:59,429 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:06:59,430 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:05,430 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:05,431 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:11,432 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:11,432 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:17,433 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:17,433 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:23,434 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:23,434 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:29,435 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:29,435 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:35,436 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:35,436 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:41,437 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:41,438 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:47,438 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:47,439 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:53,439 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:53,440 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:59,440 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:07:59,441 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:05,441 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:05,442 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:11,443 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:11,443 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:17,444 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:17,444 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:23,445 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:23,445 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:29,446 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:29,447 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:35,447 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:35,448 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:41,448 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:41,449 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:47,449 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:47,450 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:53,450 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:53,451 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:59,451 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:08:59,452 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:05,452 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:05,453 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:11,453 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:11,454 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:17,455 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:17,455 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:23,456 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:23,456 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:29,457 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:29,457 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:35,458 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:35,458 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:41,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:41,459 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:47,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:47,460 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:53,461 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:53,461 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:59,462 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:09:59,462 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:05,463 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:05,463 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:11,464 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:11,464 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:17,465 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:17,465 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:23,466 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:23,466 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:29,467 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:29,467 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:35,468 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:35,468 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:41,469 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:41,469 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:47,470 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:47,470 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:53,471 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:53,471 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:59,472 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:10:59,472 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:05,473 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:05,474 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:11,474 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:11,475 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:17,475 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:17,476 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:23,476 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:23,477 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:29,478 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:29,478 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:35,479 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:35,479 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:41,480 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:41,480 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:47,481 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:47,481 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:53,482 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:53,482 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:59,483 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:11:59,483 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:05,484 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:05,484 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:11,485 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:11,485 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:17,486 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:17,486 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:23,487 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:23,488 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:29,488 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:29,488 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:35,489 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:35,490 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:41,491 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:41,491 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:47,492 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:47,492 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:53,493 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:53,493 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:59,494 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:12:59,494 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:05,495 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:05,495 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:11,496 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:11,496 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:17,497 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:17,497 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:23,498 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:23,498 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:29,499 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:29,499 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:35,500 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:35,500 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:41,501 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:41,501 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:47,502 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:47,502 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:53,503 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:53,503 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:13:56,845 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 109 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 63 SyncTimes(ms): 563 
2014-05-05 18:13:56,849 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1343608966_1
2014-05-05 18:13:56,854 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1343608966_1
2014-05-05 18:13:56,870 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073742002_1179{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 18:13:56,871 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073742002_1179{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 18:13:56,873 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742002_1179{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 18:13:56,874 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073742002_1179{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 18:13:56,877 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0002/job_1399311113324_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_-1343608966_1
2014-05-05 18:13:56,882 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0002.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073742003_1180{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]}
2014-05-05 18:13:56,894 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742003_1180{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:13:56,900 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073742003_1180{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:13:56,902 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073742003_1180{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:13:56,903 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073742003_1180{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:13:56,905 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1343608966_1
2014-05-05 18:13:56,926 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0002-1399313063938-ubuntu-base%7C%7Cpath%3A%2F5m%7C%7Cnum+reduce%3A8-1399313636854-1-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073742004_1181{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]}
2014-05-05 18:13:56,946 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742004_1181{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:13:56,947 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073742004_1181{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:13:56,950 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073742004_1181{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:13:56,950 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073742004_1181{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:13:56,968 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0002-1399313063938-ubuntu-base%7C%7Cpath%3A%2F5m%7C%7Cnum+reduce%3A8-1399313636854-1-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1343608966_1
2014-05-05 18:13:57,044 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0002_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073742005_1182{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]}
2014-05-05 18:13:57,060 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742005_1182{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:13:57,061 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073742005_1182{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:13:57,063 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073742005_1182{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:13:57,064 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073742005_1182{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW]]} size 0
2014-05-05 18:13:57,067 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1343608966_1
2014-05-05 18:13:58,121 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741997_1174 10.0.0.195:50010 10.0.0.36:50010 10.0.0.37:50010 10.0.0.200:50010 10.0.0.38:50010 10.0.0.194:50010 10.0.0.193:50010 
2014-05-05 18:13:58,121 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741998_1175 10.0.0.195:50010 10.0.0.194:50010 10.0.0.38:50010 10.0.0.193:50010 10.0.0.36:50010 10.0.0.200:50010 10.0.0.37:50010 
2014-05-05 18:13:58,122 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741999_1176 10.0.0.195:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.37:50010 
2014-05-05 18:13:58,122 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742000_1177 10.0.0.195:50010 10.0.0.36:50010 10.0.0.194:50010 10.0.0.37:50010 
2014-05-05 18:13:58,122 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742002_1179 10.0.0.193:50010 10.0.0.37:50010 10.0.0.36:50010 10.0.0.195:50010 
2014-05-05 18:13:58,122 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742001_1178 10.0.0.193:50010 10.0.0.36:50010 10.0.0.37:50010 10.0.0.194:50010 
2014-05-05 18:13:59,504 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073741997_1174, blk_1073741998_1175]
2014-05-05 18:13:59,504 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.36:50010 to delete [blk_1073742000_1177, blk_1073742001_1178, blk_1073742002_1179, blk_1073741997_1174, blk_1073741998_1175]
2014-05-05 18:13:59,504 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073742001_1178, blk_1073742002_1179, blk_1073741997_1174, blk_1073741998_1175, blk_1073741999_1176]
2014-05-05 18:14:02,504 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.38:50010 to delete [blk_1073741997_1174, blk_1073741998_1175]
2014-05-05 18:14:02,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073742000_1177, blk_1073742001_1178, blk_1073741997_1174, blk_1073741998_1175, blk_1073741999_1176]
2014-05-05 18:14:02,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.37:50010 to delete [blk_1073742000_1177, blk_1073742001_1178, blk_1073742002_1179, blk_1073741997_1174, blk_1073741998_1175, blk_1073741999_1176]
2014-05-05 18:14:05,505 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073742000_1177, blk_1073742002_1179, blk_1073741997_1174, blk_1073741998_1175, blk_1073741999_1176]
2014-05-05 18:16:17,717 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 136 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 81 SyncTimes(ms): 625 
2014-05-05 18:16:17,719 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742003_1180 10.0.0.193:50010 10.0.0.195:50010 10.0.0.36:50010 10.0.0.37:50010 
2014-05-05 18:16:20,514 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.37:50010 to delete [blk_1073742003_1180]
2014-05-05 18:16:20,514 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073742003_1180]
2014-05-05 18:16:20,514 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.36:50010 to delete [blk_1073742003_1180]
2014-05-05 18:16:23,514 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073742003_1180]
2014-05-05 18:18:32,206 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 139 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 84 SyncTimes(ms): 628 
2014-05-05 18:18:32,289 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job.jar. BP-899801483-10.0.0.195-1399294588764 blk_1073742006_1183{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 18:18:32,958 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073742006_1183{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:18:32,959 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742006_1183{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:18:32,961 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073742006_1183{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:18:32,964 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073742006_1183{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:18:33,258 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job.jar is closed by DFSClient_NONMAPREDUCE_-870307119_1
2014-05-05 18:18:33,263 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job.jar
2014-05-05 18:18:33,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Increasing replication from 4 to 10 for /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job.split
2014-05-05 18:18:33,330 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:18:33,330 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job.split. BP-899801483-10.0.0.195-1399294588764 blk_1073742007_1184{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]}
2014-05-05 18:18:33,357 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073742007_1184{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 18:18:33,358 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073742007_1184{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 18:18:33,359 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073742007_1184{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 18:18:33,360 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073742007_1184{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 18:18:33,361 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073742007_1184{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 18:18:33,362 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742007_1184{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 18:18:33,364 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073742007_1184{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW]]} size 0
2014-05-05 18:18:33,367 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job.split is closed by DFSClient_NONMAPREDUCE_-870307119_1
2014-05-05 18:18:33,381 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job.splitmetainfo. BP-899801483-10.0.0.195-1399294588764 blk_1073742008_1185{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]}
2014-05-05 18:18:33,397 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073742008_1185{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:18:33,398 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073742008_1185{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:18:33,399 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073742008_1185{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:18:33,401 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073742008_1185{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:18:33,411 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-870307119_1
2014-05-05 18:18:33,668 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073742009_1186{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 18:18:33,685 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073742009_1186{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:18:33,687 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073742009_1186{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:18:33,688 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742009_1186{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:18:33,690 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073742009_1186{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:18:33,692 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job.xml is closed by DFSClient_NONMAPREDUCE_-870307119_1
2014-05-05 18:18:35,523 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:18:35,523 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:18:35,523 INFO BlockStateChange: BLOCK* ask 10.0.0.193:50010 to replicate blk_1073742006_1183 to datanode(s) 10.0.0.200:50010 10.0.0.36:50010 10.0.0.194:50010
2014-05-05 18:18:40,323 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job_1399311113324_0003_1_conf.xml. BP-899801483-10.0.0.195-1399294588764 blk_1073742010_1187{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]}
2014-05-05 18:18:40,504 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073742010_1187{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:18:40,506 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073742010_1187{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:18:40,510 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073742010_1187{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:18:40,513 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742010_1187{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:18:40,524 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job_1399311113324_0003_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1643940180_1
2014-05-05 18:18:40,813 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073742006_1183 size 39460499
2014-05-05 18:18:40,814 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073742006_1183 size 39460499
2014-05-05 18:18:40,814 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073742006_1183 size 39460499
2014-05-05 18:18:41,524 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:18:41,524 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:18:47,525 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:18:47,525 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:18:53,526 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:18:53,526 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:18:59,527 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:18:59,527 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:00,912 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job_1399311113324_0003_1.jhist. BP-899801483-10.0.0.195-1399294588764 blk_1073742011_1188{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]}
2014-05-05 18:19:00,930 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job_1399311113324_0003_1.jhist for DFSClient_NONMAPREDUCE_1643940180_1
2014-05-05 18:19:05,528 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:05,528 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:11,529 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:11,529 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:17,530 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:17,530 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:23,531 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:23,531 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:29,532 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:29,532 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:35,533 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:35,533 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:41,534 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:41,534 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:47,535 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:47,535 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:53,535 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:53,536 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:59,537 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:19:59,537 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:05,538 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:05,538 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:11,539 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:11,539 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:17,540 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:17,540 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:23,541 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:23,541 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:29,542 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:29,542 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:35,543 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:35,543 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:41,544 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:41,544 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:47,544 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:47,545 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:53,546 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:53,546 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:59,547 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:20:59,547 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:05,548 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:05,548 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:11,549 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:11,549 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:17,550 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:17,550 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:23,551 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:23,551 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:29,552 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:29,552 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:35,553 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:35,553 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:41,554 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:41,554 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:47,555 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:47,555 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:53,556 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:53,556 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:59,557 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:21:59,557 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:05,558 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:05,558 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:11,559 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:11,559 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:17,560 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:17,560 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:23,561 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:23,561 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:29,562 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:29,562 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:35,563 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:35,563 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:41,564 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:41,564 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:47,565 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:47,565 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:53,566 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:53,566 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:59,567 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:22:59,567 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:05,568 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:05,568 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:11,569 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:11,569 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:17,570 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:17,570 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:23,571 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:23,571 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:29,572 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:29,572 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:35,572 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:35,573 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:41,573 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:41,574 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:47,574 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:47,575 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:53,575 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:53,576 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:59,576 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:23:59,577 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:05,577 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:05,577 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:11,578 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:11,578 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:17,579 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:17,579 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:23,580 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:23,580 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:29,581 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:29,582 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:35,582 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:35,582 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:41,583 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:41,583 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:47,584 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:47,584 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:53,585 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:53,585 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:59,586 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:24:59,586 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:05,587 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:05,587 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:11,588 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:11,588 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:17,589 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:17,589 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:23,590 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:23,590 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:29,591 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:29,591 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:35,592 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:35,592 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:41,593 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:41,593 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:47,594 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:47,594 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:53,595 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:53,595 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:59,596 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:25:59,596 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:05,597 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:05,597 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:11,598 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:11,598 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:17,599 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:17,599 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:23,600 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:23,600 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:29,601 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:29,601 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:35,602 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:35,602 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:41,603 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:41,603 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:47,604 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:47,604 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:53,605 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:53,605 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:59,606 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:26:59,606 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:05,607 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:05,607 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:11,607 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:11,608 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:17,609 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:17,609 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:23,610 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:23,610 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:29,611 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:29,611 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:35,612 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:35,612 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:41,613 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:41,613 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:47,613 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:47,614 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:53,614 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:53,615 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:59,615 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:27:59,615 WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy: Not able to place enough replicas, still in need of 1 to reach 8
For more information, please enable DEBUG log level on org.apache.commons.logging.impl.Log4JLogger
2014-05-05 18:28:01,717 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 177 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 104 SyncTimes(ms): 1388 
2014-05-05 18:28:01,725 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1643940180_1
2014-05-05 18:28:01,730 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1643940180_1
2014-05-05 18:28:01,744 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073742011_1188{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 18:28:01,746 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073742011_1188{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 18:28:01,747 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073742011_1188{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 18:28:01,749 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742011_1188{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW]]} size 0
2014-05-05 18:28:01,771 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/ubuntu/.staging/job_1399311113324_0003/job_1399311113324_0003_1.jhist is closed by DFSClient_NONMAPREDUCE_1643940180_1
2014-05-05 18:28:01,776 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0003.summary_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073742012_1189{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]}
2014-05-05 18:28:01,789 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073742012_1189{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:28:01,791 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073742012_1189{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:28:01,791 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742012_1189{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:28:01,792 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.195:50010 is added to blk_1073742012_1189{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.195:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW]]} size 0
2014-05-05 18:28:01,794 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0003.summary_tmp is closed by DFSClient_NONMAPREDUCE_1643940180_1
2014-05-05 18:28:01,816 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0003-1399313913880-ubuntu-base%7C%7Cpath%3A%2F5m%7C%7Cnum+reduce%3A8-1399314481812-1-8-SUCCEEDED-default.jhist_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073742013_1190{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]}
2014-05-05 18:28:01,830 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.38:50010 is added to blk_1073742013_1190{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:28:01,831 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.193:50010 is added to blk_1073742013_1190{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:28:01,832 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073742013_1190{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:28:01,833 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742013_1190{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW], ReplicaUnderConstruction[10.0.0.193:50010|RBW], ReplicaUnderConstruction[10.0.0.38:50010|RBW]]} size 0
2014-05-05 18:28:01,846 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0003-1399313913880-ubuntu-base%7C%7Cpath%3A%2F5m%7C%7Cnum+reduce%3A8-1399314481812-1-8-SUCCEEDED-default.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1643940180_1
2014-05-05 18:28:01,877 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0003_conf.xml_tmp. BP-899801483-10.0.0.195-1399294588764 blk_1073742014_1191{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]}
2014-05-05 18:28:01,893 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.194:50010 is added to blk_1073742014_1191{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:28:01,894 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.36:50010 is added to blk_1073742014_1191{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:28:01,895 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.200:50010 is added to blk_1073742014_1191{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:28:01,896 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.0.37:50010 is added to blk_1073742014_1191{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[10.0.0.37:50010|RBW], ReplicaUnderConstruction[10.0.0.200:50010|RBW], ReplicaUnderConstruction[10.0.0.36:50010|RBW], ReplicaUnderConstruction[10.0.0.194:50010|RBW]]} size 0
2014-05-05 18:28:01,898 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1399311113324_0003_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1643940180_1
2014-05-05 18:28:02,946 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742006_1183 10.0.0.195:50010 10.0.0.38:50010 10.0.0.37:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.36:50010 10.0.0.194:50010 
2014-05-05 18:28:02,946 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742007_1184 10.0.0.195:50010 10.0.0.37:50010 10.0.0.194:50010 10.0.0.193:50010 10.0.0.200:50010 10.0.0.38:50010 10.0.0.36:50010 
2014-05-05 18:28:02,946 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742008_1185 10.0.0.195:50010 10.0.0.36:50010 10.0.0.194:50010 10.0.0.38:50010 
2014-05-05 18:28:02,946 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742009_1186 10.0.0.195:50010 10.0.0.37:50010 10.0.0.200:50010 10.0.0.193:50010 
2014-05-05 18:28:02,946 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742011_1188 10.0.0.37:50010 10.0.0.193:50010 10.0.0.38:50010 10.0.0.195:50010 
2014-05-05 18:28:02,946 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742010_1187 10.0.0.37:50010 10.0.0.200:50010 10.0.0.195:50010 10.0.0.38:50010 
2014-05-05 18:28:05,616 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.36:50010 to delete [blk_1073742006_1183, blk_1073742007_1184, blk_1073742008_1185]
2014-05-05 18:28:05,616 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.194:50010 to delete [blk_1073742006_1183, blk_1073742007_1184, blk_1073742008_1185]
2014-05-05 18:28:05,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.37:50010 to delete [blk_1073742006_1183, blk_1073742007_1184, blk_1073742009_1186, blk_1073742010_1187, blk_1073742011_1188]
2014-05-05 18:28:08,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073742006_1183, blk_1073742007_1184, blk_1073742009_1186, blk_1073742011_1188]
2014-05-05 18:28:08,784 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.200:50010 to delete [blk_1073742006_1183, blk_1073742007_1184, blk_1073742009_1186, blk_1073742010_1187]
2014-05-05 18:28:08,785 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073742006_1183, blk_1073742007_1184, blk_1073742008_1185, blk_1073742009_1186, blk_1073742010_1187, blk_1073742011_1188]
2014-05-05 18:28:11,785 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.38:50010 to delete [blk_1073742006_1183, blk_1073742007_1184, blk_1073742008_1185, blk_1073742010_1187, blk_1073742011_1188]
2014-05-05 18:28:17,718 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742012_1189 10.0.0.195:50010 10.0.0.37:50010 10.0.0.36:50010 10.0.0.193:50010 
2014-05-05 18:28:17,785 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.37:50010 to delete [blk_1073742012_1189]
2014-05-05 18:28:17,785 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.36:50010 to delete [blk_1073742012_1189]
2014-05-05 18:28:17,785 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.193:50010 to delete [blk_1073742012_1189]
2014-05-05 18:28:20,786 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 10.0.0.195:50010 to delete [blk_1073742012_1189]
2014-05-05 18:32:49,672 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.0.195
2014-05-05 18:32:49,672 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2014-05-05 18:32:49,672 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1213
2014-05-05 18:32:49,672 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 207 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 125 SyncTimes(ms): 1463 
2014-05-05 18:32:49,675 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 207 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 126 SyncTimes(ms): 1466 
2014-05-05 18:32:49,675 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /var/hadoop/tmp/dfs/name/current/edits_inprogress_0000000000000001213 -> /var/hadoop/tmp/dfs/name/current/edits_0000000000000001213-0000000000000001419
2014-05-05 18:32:49,675 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1420
2014-05-05 18:32:49,818 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://nodea:50090/getimage?getimage=1&txid=1419&storageInfo=-47:182241533:0:CID-8c4732c4-578b-4cb5-9118-7c3d84e15c32
2014-05-05 18:32:49,828 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.01s at 1000.00 KB/s
2014-05-05 18:32:49,828 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000001419 size 9263 bytes.
2014-05-05 18:32:49,834 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 1212
2014-05-05 18:32:49,834 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/var/hadoop/tmp/dfs/name/current/fsimage_0000000000000001209, cpktTxId=0000000000000001209)
2014-05-05 18:42:52,821 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2014-05-05 18:42:52,823 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at ip-10-0-0-195/10.0.0.195
************************************************************/
